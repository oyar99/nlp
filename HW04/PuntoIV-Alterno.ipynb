{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8106be9e-1ac4-480d-a51c-31b668cc8551",
   "metadata": {},
   "source": [
    "# Clasificación de Texto Usando Embeddings Pre-entrenados\n",
    "\n",
    "Este notebook realiza la clasificación de texto para identificar al autor de un texto entre tres autores posibles, utilizando embeddings pre-entrenados de GloVe y redes neuronales feed-forward (FFNN). Procesa los datos de texto, entrena múltiples arquitecturas de redes neuronales y evalúa su rendimiento en base a la precisión, exactitud y recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28627c2b-b3cb-47bb-8da6-931210036e7a",
   "metadata": {},
   "source": [
    "## 0. Importación de Librerias y Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e39d8cea-a6a5-4a7c-9000-ffb853378af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import (\n",
    "    utils,\n",
    "    layers,\n",
    "    models,\n",
    "    callbacks\n",
    ")\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eb33b39-6ff6-4dc5-a579-87a35dec93c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings de 50 dimensiones cargados exitosamente.\n",
      "Embeddings de 100 dimensiones cargados exitosamente.\n",
      "Embeddings de 300 dimensiones cargados exitosamente.\n"
     ]
    }
   ],
   "source": [
    "def download_glove(url: str, zip_path: str):\n",
    "    \"\"\"\n",
    "    Descarga el archivo GloVe si no está presente localmente.\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL de descarga del archivo GloVe.\n",
    "        zip_path (str): Ruta donde se almacenará el archivo descargado.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(zip_path):\n",
    "        print(f\"Descargando embeddings desde {url}...\")\n",
    "        response = requests.get(url)\n",
    "        with open(zip_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "def extract_glove(zip_path: str, glove_dir: str, glove_file: str):\n",
    "    \"\"\"\n",
    "    Extrae los archivos GloVe del archivo zip si no están ya extraídos.\n",
    "    \n",
    "    Args:\n",
    "        zip_path (str): Ruta del archivo zip de GloVe.\n",
    "        glove_dir (str): Directorio de destino de los archivos extraídos.\n",
    "        glove_file (str): Nombre del archivo GloVe específico a extraer.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(os.path.join(glove_dir, glove_file)):\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extract(glove_file, glove_dir)\n",
    "\n",
    "def load_embeddings(dim: int) -> dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Carga los embeddings preentrenados de GloVe y los devuelve en un diccionario.\n",
    "    \n",
    "    Args:\n",
    "        dim (int): Dimensión de los embeddings a cargar.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Diccionario con palabras como claves y vectores como valores.\n",
    "    \"\"\"\n",
    "    # Definir las rutas y nombres relevantes.\n",
    "    glove_download_url = \"https://nlp.stanford.edu/data/glove.6B.zip\"\n",
    "    glove_zip_path = \"glove.6B.zip\"\n",
    "    glove_dir = \"data/glove/\"\n",
    "    glove_file = f'glove.6B.{dim}d.txt'\n",
    "\n",
    "    # Descargar y extraer GloVe si es necesario.\n",
    "    os.makedirs(glove_dir, exist_ok=True)\n",
    "    download_glove(glove_download_url, glove_zip_path)\n",
    "    extract_glove(glove_zip_path, glove_dir, glove_file)\n",
    "\n",
    "    # Cargar los embeddings en un diccionario.\n",
    "    embeddings_index = {}\n",
    "    with open(os.path.join(glove_dir, glove_file), 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            values = line.split()\n",
    "            word = values[0]  # La primera palabra es la clave.\n",
    "            coefs = np.asarray(values[1:], dtype='float32')    # Los valores restantes son el vector.\n",
    "            embeddings_index[word] = coefs\n",
    "\n",
    "    print(f\"Embeddings de {dim} dimensiones cargados exitosamente.\")\n",
    "    return embeddings_index\n",
    "\n",
    "# Cargar los embeddings de GloVe con 50, 100 y 300 dimensiones.\n",
    "glove_50 = load_embeddings(50)\n",
    "glove_100 = load_embeddings(100)\n",
    "glove_300 = load_embeddings(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc6ca357-f440-4969-86cd-12f378858a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>The family of Dashwood had long been settled i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>The old gentleman died: his will was read, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>No sooner was his father’s funeral over, than ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>“Certainly not; but if you observe, people alw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>Edward Ferrars was not recommended to their go...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author                                           sentence\n",
       "0  Jane Austen  The family of Dashwood had long been settled i...\n",
       "1  Jane Austen  The old gentleman died: his will was read, and...\n",
       "2  Jane Austen  No sooner was his father’s funeral over, than ...\n",
       "3  Jane Austen  “Certainly not; but if you observe, people alw...\n",
       "4  Jane Austen  Edward Ferrars was not recommended to their go..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el dataset\n",
    "df = pd.read_csv('data/classifier/sentences.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc4fd5e7-b230-414b-8988-b14bebfc3617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>num_training_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leo Tolstoy</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>James Joyce</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author  num_training_data\n",
       "0  Leo Tolstoy                866\n",
       "1  Jane Austen                426\n",
       "2  James Joyce                321"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contar el número de datos por autor\n",
    "author_counts = df['author'].value_counts()\n",
    "\n",
    "# Crear DataFrame resumen\n",
    "summary_df = author_counts.reset_index()\n",
    "summary_df.columns = ['author', 'num_training_data']\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9dbf6b-e4df-4054-8bef-50ec2fc29463",
   "metadata": {},
   "source": [
    "## 1. Preprocesamiento de los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "319c6c34-8a01-4f5c-99f2-c43cb780f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en conjunto de entrenamiento, validación y prueba\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(df['sentence'], df['author'], train_size=0.7, random_state=42)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, train_size=0.5, random_state=42)\n",
    "\n",
    "# Tokenización usando Keras\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "# Convertir el texto en secuencias de enteros\n",
    "x_train_seq = tokenizer.texts_to_sequences(x_train)\n",
    "x_val_seq = tokenizer.texts_to_sequences(x_val)\n",
    "x_test_seq = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "# Rellenar las secuencias para que tengan la misma longitud\n",
    "max_length = max([len(seq) for seq in x_train_seq])\n",
    "x_train_pad = pad_sequences(x_train_seq, maxlen=max_length, padding='post')\n",
    "x_val_pad = pad_sequences(x_val_seq, maxlen=max_length, padding='post')\n",
    "x_test_pad = pad_sequences(x_test_seq, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d2ff3a-2f45-4ed3-b274-f09a39bcbd19",
   "metadata": {},
   "source": [
    "## 2. Definición de los Modelos de Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c004b6c-65b4-44ee-b6f5-6c02171a1b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_glove_embedding_layer(embeddings, tokenizer, max_length):\n",
    "    \"\"\"\n",
    "    Crea una capa de embeddings a partir de los embeddings GloVe.\n",
    "    \n",
    "    Args:\n",
    "        embeddings (dict): Diccionario con los embeddings de GloVe.\n",
    "        tokenizer (Tokenizer): Tokenizador de Keras con el índice de palabras.\n",
    "        max_length (int): Longitud máxima de las secuencias de entrada.\n",
    "    \n",
    "    Returns:\n",
    "        Embedding: Capa de embeddings de Keras con pesos pre-entrenados.\n",
    "    \"\"\"\n",
    "    # Inicializar la matriz de embeddings con ceros\n",
    "    embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, len(next(iter(embeddings.values())))))\n",
    "\n",
    "    # Llenar la matriz de embeddings con los vectores de GloVe\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        vector = embeddings.get(word)\n",
    "        if vector is not None:\n",
    "            embedding_matrix[i] = vector\n",
    "\n",
    "    # Crear y devolver la capa de embeddings\n",
    "    return layers.Embedding(\n",
    "        input_dim=len(tokenizer.word_index) + 1,\n",
    "        output_dim=embedding_matrix.shape[1],\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=max_length,\n",
    "        trainable=False\n",
    "    )\n",
    "\n",
    "# Crear capas de embeddings con GloVe\n",
    "embedding_layer_50 = create_glove_embedding_layer(glove_50, tokenizer, max_length)\n",
    "embedding_layer_100 = create_glove_embedding_layer(glove_100, tokenizer, max_length)\n",
    "embedding_layer_300 = create_glove_embedding_layer(glove_300, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19b7e358-638c-42c8-bba6-0740483e259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitectura 1: Modelo sencillo\n",
    "def create_ffnn_model_1(embedding_layer):\n",
    "    \"\"\"\n",
    "    Crea un modelo de red neuronal feedforward simple.\n",
    "\n",
    "    Args:\n",
    "    embedding_layer: Capa de embeddings de Keras utilizada como entrada.\n",
    "\n",
    "    Returns:\n",
    "    Sequential: Modelo de red neuronal compilado.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "            layers.Input(shape=(max_length,)),\n",
    "            embedding_layer,\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(3, activation='softmax')\n",
    "        ])\n",
    "    return model\n",
    "\n",
    "# Arquitectura 2: Modelo con más capas\n",
    "def create_ffnn_model_2(embedding_layer):\n",
    "    \"\"\"\n",
    "    Crea un modelo de red neuronal feedforward con más capas.\n",
    "\n",
    "    Args:\n",
    "    embedding_layer: Capa de embeddings de Keras utilizada como entrada.\n",
    "\n",
    "    Returns:\n",
    "    Sequential: Modelo de red neuronal compilado.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "            layers.Input(shape=(max_length,)),\n",
    "            embedding_layer,\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(3, activation='softmax')\n",
    "        ])\n",
    "    return model\n",
    "\n",
    "# Arquitectura 3: Modelo con más unidades\n",
    "def create_ffnn_model_3(embedding_layer):\n",
    "    \"\"\"\n",
    "    Crea un modelo de red neuronal feedforward con más unidades.\n",
    "\n",
    "    Args:\n",
    "    embedding_layer: Capa de embeddings de Keras utilizada como entrada.\n",
    "\n",
    "    Returns:\n",
    "    Sequential: Modelo de red neuronal compilado.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "            layers.Input(shape=(max_length,)),\n",
    "            embedding_layer,\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(512, activation='relu'),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(3, activation='softmax')\n",
    "        ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1571b8-d028-414e-90b6-315ca0bd3620",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento y Evaluación de los Modelos de Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc3dae8-3c89-4d19-bb77-f73219b4dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación de etiquetas (autores)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = utils.to_categorical(label_encoder.fit_transform(y_train))\n",
    "y_val_encoded = utils.to_categorical(label_encoder.transform(y_val))\n",
    "y_test_encoded = utils.to_categorical(label_encoder.transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ecea28c-48ff-457b-b320-1e26e69c2467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test_pad, y_test_encoded):\n",
    "    \"\"\"\n",
    "    Evalúa el rendimiento de un modelo entrenado calculando accuracy, precision y recall.\n",
    "    \n",
    "    Args:\n",
    "    model (keras.models.Model): El modelo entrenado.\n",
    "    x_test_pad (numpy.ndarray): Conjunto de datos de prueba preprocesados y tokenizados.\n",
    "    y_test_encoded (numpy.ndarray): Etiquetas de prueba codificadas en formato one-hot.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Un tupla que contiene:\n",
    "        - accuracy (float): La proporción de predicciones correctas.\n",
    "        - precision (float): La proporción de predicciones positivas correctas (precisión macro).\n",
    "        - recall (float): La proporción de verdaderos positivos detectados (recall macro).\n",
    "    \"\"\"\n",
    "    # Obtener predicciones del modelo\n",
    "    y_pred = model.predict(x_test_pad)\n",
    "    \n",
    "    # Convertir las predicciones y etiquetas de one-hot a clases\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test_encoded, axis=1)\n",
    "    \n",
    "    # Calcular accuracy\n",
    "    accuracy = np.mean(y_pred_classes == y_test_classes)\n",
    "    \n",
    "    # Calcular precisión y recall usando la métrica macro (promedio entre todas las clases)\n",
    "    precision = precision_score(y_test_classes, y_pred_classes, average='macro')\n",
    "    recall = recall_score(y_test_classes, y_pred_classes, average='macro')\n",
    "    \n",
    "    return accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1009cb4-0684-432b-a34f-c3a089ffe15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando Modelo 1 con 50 dimensiones...\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 254, 50)           851050    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12700)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1625728   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,477,165\n",
      "Trainable params: 1,626,115\n",
      "Non-trainable params: 851,050\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 2s 18ms/step - loss: 1.0675 - accuracy: 0.5173 - val_loss: 0.8250 - val_accuracy: 0.6198\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4211 - accuracy: 0.8503 - val_loss: 0.7578 - val_accuracy: 0.6570\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1773 - accuracy: 0.9814 - val_loss: 0.8437 - val_accuracy: 0.6570\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.8190 - val_accuracy: 0.6570\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.8819 - val_accuracy: 0.6570\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.9269 - val_accuracy: 0.6653\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.9519 - val_accuracy: 0.6653\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.9511 - val_accuracy: 0.6653\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.0124 - val_accuracy: 0.6694\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.9411 - val_accuracy: 0.6612\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "\n",
      "Evaluación del Modelo 1 con embeddings de 50 dimensiones - Accuracy: 0.7355371900826446, Precision: 0.7788371993065605, Recall: 0.6224484381685923 \n",
      "\n",
      "\n",
      "Entrenando Modelo 2 con 50 dimensiones...\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 254, 50)           851050    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 12700)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               3251456   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,135,789\n",
      "Trainable params: 3,284,739\n",
      "Non-trainable params: 851,050\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 1.0805 - accuracy: 0.5314 - val_loss: 0.7713 - val_accuracy: 0.6405\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.3348 - accuracy: 0.8875 - val_loss: 1.0035 - val_accuracy: 0.6653\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0832 - accuracy: 0.9903 - val_loss: 0.9313 - val_accuracy: 0.6983\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.8924 - val_accuracy: 0.6860\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.9908 - val_accuracy: 0.6901\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.0255 - val_accuracy: 0.6860\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.0036 - val_accuracy: 0.6818\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.0448 - val_accuracy: 0.6818\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 9.5255e-04 - accuracy: 1.0000 - val_loss: 1.0716 - val_accuracy: 0.6777\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.5901e-04 - accuracy: 1.0000 - val_loss: 1.0996 - val_accuracy: 0.6860\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "\n",
      "Evaluación del Modelo 2 con embeddings de 50 dimensiones - Accuracy: 0.71900826446281, Precision: 0.7702599904912043, Recall: 0.6049045785194694 \n",
      "\n",
      "\n",
      "Entrenando Modelo 3 con 50 dimensiones...\n",
      "\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 254, 50)           851050    \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 12700)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               6502912   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,518,573\n",
      "Trainable params: 6,667,523\n",
      "Non-trainable params: 851,050\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 2s 30ms/step - loss: 1.1885 - accuracy: 0.5120 - val_loss: 0.8051 - val_accuracy: 0.6322\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.3668 - accuracy: 0.8707 - val_loss: 1.5585 - val_accuracy: 0.5702\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.1039 - accuracy: 0.9681 - val_loss: 0.8761 - val_accuracy: 0.6694\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.0210 - accuracy: 0.9973 - val_loss: 1.0388 - val_accuracy: 0.6570\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1017 - val_accuracy: 0.6653\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.2269 - val_accuracy: 0.6818\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 5.1296e-04 - accuracy: 1.0000 - val_loss: 1.2387 - val_accuracy: 0.6694\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 2.9531e-04 - accuracy: 1.0000 - val_loss: 1.2635 - val_accuracy: 0.6777\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 1.6441e-04 - accuracy: 1.0000 - val_loss: 1.3527 - val_accuracy: 0.6736\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 1.0683e-04 - accuracy: 1.0000 - val_loss: 1.4174 - val_accuracy: 0.6694\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "\n",
      "Evaluación del Modelo 3 con embeddings de 50 dimensiones - Accuracy: 0.7066115702479339, Precision: 0.7523577954612438, Recall: 0.5972100984167737 \n",
      "\n",
      "\n",
      "Entrenando Modelo 1 con 100 dimensiones...\n",
      "\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 254, 100)          1702100   \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 25400)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               3251328   \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,953,815\n",
      "Trainable params: 3,251,715\n",
      "Non-trainable params: 1,702,100\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 2s 25ms/step - loss: 1.7319 - accuracy: 0.4748 - val_loss: 0.9676 - val_accuracy: 0.5579\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.6041 - accuracy: 0.7830 - val_loss: 0.8292 - val_accuracy: 0.6116\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2952 - accuracy: 0.9221 - val_loss: 0.7914 - val_accuracy: 0.6322\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1074 - accuracy: 0.9956 - val_loss: 0.8571 - val_accuracy: 0.6322\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.8397 - val_accuracy: 0.6570\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.8261 - val_accuracy: 0.6446\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.8717 - val_accuracy: 0.6612\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.8989 - val_accuracy: 0.6653\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.9450 - val_accuracy: 0.6529\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.9511 - val_accuracy: 0.6488\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "\n",
      "Evaluación del Modelo 1 con embeddings de 100 dimensiones - Accuracy: 0.7107438016528925, Precision: 0.742528735632184, Recall: 0.6053401797175867 \n",
      "\n",
      "\n",
      "Entrenando Modelo 2 con 100 dimensiones...\n",
      "\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 254, 100)          1702100   \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 25400)             0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 256)               6502656   \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,238,039\n",
      "Trainable params: 6,535,939\n",
      "Non-trainable params: 1,702,100\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 2s 32ms/step - loss: 1.5618 - accuracy: 0.4668 - val_loss: 1.0949 - val_accuracy: 0.5083\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.5009 - accuracy: 0.8034 - val_loss: 1.0304 - val_accuracy: 0.6281\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.1905 - accuracy: 0.9584 - val_loss: 0.8237 - val_accuracy: 0.6322\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.0516 - accuracy: 0.9965 - val_loss: 0.9812 - val_accuracy: 0.6281\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.9277 - val_accuracy: 0.6488\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.0199 - val_accuracy: 0.6405\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.0480 - val_accuracy: 0.6446\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.0769 - val_accuracy: 0.6446\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0921 - val_accuracy: 0.6488\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.0883 - val_accuracy: 0.6446\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "\n",
      "Evaluación del Modelo 2 con embeddings de 100 dimensiones - Accuracy: 0.6983471074380165, Precision: 0.8001247472792189, Recall: 0.5706341463414634 \n",
      "\n",
      "\n",
      "Entrenando Modelo 3 con 100 dimensiones...\n",
      "\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 254, 100)          1702100   \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 25400)             0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 512)               13005312  \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,872,023\n",
      "Trainable params: 13,169,923\n",
      "Non-trainable params: 1,702,100\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 4s 80ms/step - loss: 1.6635 - accuracy: 0.5164 - val_loss: 0.8398 - val_accuracy: 0.6116\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 0.4720 - accuracy: 0.8043 - val_loss: 0.8578 - val_accuracy: 0.6653\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 2s 48ms/step - loss: 0.0901 - accuracy: 0.9823 - val_loss: 0.7883 - val_accuracy: 0.6818\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 2s 47ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.9521 - val_accuracy: 0.6736\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.0353 - val_accuracy: 0.6653\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.0465 - val_accuracy: 0.6653\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.0534 - val_accuracy: 0.6736\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1310 - val_accuracy: 0.6612\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 2s 48ms/step - loss: 9.2803e-04 - accuracy: 1.0000 - val_loss: 1.1491 - val_accuracy: 0.6694\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 6.8326e-04 - accuracy: 1.0000 - val_loss: 1.2086 - val_accuracy: 0.6612\n",
      "8/8 [==============================] - 0s 10ms/step\n",
      "\n",
      "Evaluación del Modelo 3 con embeddings de 100 dimensiones - Accuracy: 0.6983471074380165, Precision: 0.7790458937198067, Recall: 0.5683038083012409 \n",
      "\n",
      "\n",
      "Entrenando Modelo 1 con 300 dimensiones...\n",
      "\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 254, 300)          5106300   \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 76200)             0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               9753728   \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,860,415\n",
      "Trainable params: 9,754,115\n",
      "Non-trainable params: 5,106,300\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 1.5293 - accuracy: 0.5306 - val_loss: 0.8890 - val_accuracy: 0.6364\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 0.1534 - accuracy: 0.9584 - val_loss: 0.8761 - val_accuracy: 0.6446\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.8929 - val_accuracy: 0.6529\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.9465 - val_accuracy: 0.6364\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.0192 - val_accuracy: 0.6405\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.0184 - val_accuracy: 0.6570\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.0752 - val_accuracy: 0.6364\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1167 - val_accuracy: 0.6322\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.1713 - val_accuracy: 0.6322\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1870 - val_accuracy: 0.6240\n",
      "8/8 [==============================] - 0s 8ms/step\n",
      "\n",
      "Evaluación del Modelo 1 con embeddings de 300 dimensiones - Accuracy: 0.6859504132231405, Precision: 0.8739635157545605, Recall: 0.5281343602909714 \n",
      "\n",
      "\n",
      "Entrenando Modelo 2 con 300 dimensiones...\n",
      "\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 254, 300)          5106300   \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 76200)             0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 256)               19507456  \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,647,039\n",
      "Trainable params: 19,540,739\n",
      "Non-trainable params: 5,106,300\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 4s 83ms/step - loss: 1.6300 - accuracy: 0.5190 - val_loss: 0.7949 - val_accuracy: 0.6446\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 3s 71ms/step - loss: 0.1657 - accuracy: 0.9513 - val_loss: 0.7801 - val_accuracy: 0.6818\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 2s 62ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.8680 - val_accuracy: 0.6694\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 2s 66ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.9311 - val_accuracy: 0.6777\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 2s 62ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9876 - val_accuracy: 0.6860\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 2s 65ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.0167 - val_accuracy: 0.6818\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 7.2966e-04 - accuracy: 1.0000 - val_loss: 1.0062 - val_accuracy: 0.6777\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 2s 62ms/step - loss: 5.4998e-04 - accuracy: 1.0000 - val_loss: 1.0652 - val_accuracy: 0.6818\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 2s 63ms/step - loss: 4.3239e-04 - accuracy: 1.0000 - val_loss: 1.0706 - val_accuracy: 0.6818\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 2s 63ms/step - loss: 3.4916e-04 - accuracy: 1.0000 - val_loss: 1.1036 - val_accuracy: 0.6818\n",
      "8/8 [==============================] - 0s 13ms/step\n",
      "\n",
      "Evaluación del Modelo 2 con embeddings de 300 dimensiones - Accuracy: 0.7024793388429752, Precision: 0.7549665452478752, Recall: 0.561762943945229 \n",
      "\n",
      "\n",
      "Entrenando Modelo 3 con 300 dimensiones...\n",
      "\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 254, 300)          5106300   \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 76200)             0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 512)               39014912  \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,285,823\n",
      "Trainable params: 39,179,523\n",
      "Non-trainable params: 5,106,300\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 9s 203ms/step - loss: 1.5108 - accuracy: 0.4756 - val_loss: 1.1922 - val_accuracy: 0.4298\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 5s 135ms/step - loss: 0.2176 - accuracy: 0.9247 - val_loss: 0.7832 - val_accuracy: 0.6860\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 5s 138ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.2086 - val_accuracy: 0.6570\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 5s 132ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.0563 - val_accuracy: 0.6942\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 5s 125ms/step - loss: 4.0689e-04 - accuracy: 1.0000 - val_loss: 1.1663 - val_accuracy: 0.6777\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 4s 124ms/step - loss: 2.3503e-04 - accuracy: 1.0000 - val_loss: 1.2050 - val_accuracy: 0.6860\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 5s 126ms/step - loss: 1.5003e-04 - accuracy: 1.0000 - val_loss: 1.2099 - val_accuracy: 0.6983\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 5s 127ms/step - loss: 1.0619e-04 - accuracy: 1.0000 - val_loss: 1.2717 - val_accuracy: 0.6901\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 5s 126ms/step - loss: 7.9778e-05 - accuracy: 1.0000 - val_loss: 1.2553 - val_accuracy: 0.6983\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 5s 126ms/step - loss: 6.2229e-05 - accuracy: 1.0000 - val_loss: 1.2917 - val_accuracy: 0.6942\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "\n",
      "Evaluación del Modelo 3 con embeddings de 300 dimensiones - Accuracy: 0.731404958677686, Precision: 0.8568376068376068, Recall: 0.6074411638853231 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterar sobre las capas de embeddings y las dimensiones de los modelos Word2Vec (50, 100, 300 dimensiones)\n",
    "for embedding_layer, dimensions in [(embedding_layer_50, 50), (embedding_layer_100, 100), (embedding_layer_300, 300)]:\n",
    "    \n",
    "    # Iterar sobre las funciones de creación de modelos FFNN (modelos 1, 2 y 3)\n",
    "    for i, model_fn in enumerate([create_ffnn_model_1, create_ffnn_model_2, create_ffnn_model_3], 1):\n",
    "        \n",
    "        # Crear el modelo usando la capa de embeddings actual\n",
    "        print(f\"\\nEntrenando Modelo {i} con {dimensions} dimensiones...\" \"\\n\")\n",
    "        model = model_fn(embedding_layer)\n",
    "        \n",
    "        # Mostrar el resumen del modelo (capas y dimensiones)\n",
    "        model.summary()\n",
    "\n",
    "        # Compilar y entrenar el modelo\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "        history = model.fit(x_train_pad, y_train_encoded, \n",
    "                            epochs=10, batch_size=32, \n",
    "                            validation_data=(x_val_pad, y_val_encoded), \n",
    "                            verbose=1)\n",
    "        \n",
    "        # Evaluar el modelo en el conjunto de prueba\n",
    "        accuracy, precision, recall = evaluate_model(model, x_test_pad, y_test_encoded)\n",
    "\n",
    "        # Mostrar los resultados finales de la evaluación (accuracy, precision y recall)\n",
    "        print(f\"\\nEvaluación del Modelo {i} con embeddings de {dimensions} dimensiones - Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\", \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
