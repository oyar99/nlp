{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de Texto Usando Embeddings Personalizados\n",
    "\n",
    "Este notebook realiza la clasificación de texto para identificar al autor de un texto entre tres autores posibles, utilizando embeddings personalizados y redes neuronales feed-forward (FFNN). Procesa los datos de texto, entrena múltiples arquitecturas de redes neuronales y evalúa su rendimiento en base a la precisión, exactitud y recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import (\n",
    "    utils,\n",
    "    layers,\n",
    "    models,\n",
    "    callbacks\n",
    ")\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creación del Dataset\n",
    "\n",
    "Primero, creamos el dataset de oraciones etiquetadas según el autor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Carga el texto crudo a partir de un archivo de texto\n",
    "    \n",
    "    Args:\n",
    "    file_path (str): Ruta del archivo de texto.\n",
    "    \n",
    "    Returns:\n",
    "    str: Texto crudo.\n",
    "    \"\"\"\n",
    "    # Leer el texto crudo\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    return text\n",
    "\n",
    "def extract_sentences(book: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Extrae extractos de un libro asegurando que cumplan con ciertas condiciones de tamaño\n",
    "    \n",
    "    Args:\n",
    "    book (str): Texto crudo.\n",
    "    \n",
    "    Returns:\n",
    "    list[str]: Lista de extractos del libro.\n",
    "    \"\"\"\n",
    "    # Separar el texto en bloques usando líneas completamente vacías como delimitadores\n",
    "    lines = book.split('***')[2].split('\\n\\n')\n",
    "\n",
    "    # Eliminar espacios en blanco al inicio y al final de cada línea\n",
    "    lines = [line.strip() for line in lines]\n",
    "\n",
    "    # Eliminar lineas vacias y títulos no relevantes\n",
    "    lines = [line for line in lines if line and not line.startswith('CHAPTER') and not line.startswith('[Illustration]')]\n",
    "\n",
    "    # Eliminar saltos de líneas de las oraciones\n",
    "    lines = [line.replace('\\n', ' ') for line in lines]\n",
    "\n",
    "    # Usar word count para extraer las oraciones\n",
    "    sentences = []\n",
    "    for sentence in lines:\n",
    "        if len(sentence.split()) > 250:\n",
    "            sentences.extend(sent_tokenize(sentence))  # Dividir en oraciones si es demasiado largo\n",
    "        else:\n",
    "            sentences.append(sentence)\n",
    "\n",
    "    # Filtrar por oraciones que tienen entre 150 y 250 palabras\n",
    "    sentences = [sentence for sentence in sentences if 150 <= len(sentence.split()) <= 250]\n",
    "\n",
    "    # Eliminar espacios en blanco al inicio y al final de cada línea nuevamente\n",
    "    sentences = [sentence.strip() for sentence in sentences]\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta a los libros originales junto con su autor\n",
    "raw_books = {\n",
    "    'austen_sense-and-sensibility': {\n",
    "        'file_path': 'data/raw/austen_sense-and-sensibility.txt',\n",
    "        'author': 'Jane Austen',\n",
    "    },\n",
    "    'austen_pride-and-prejudice': {\n",
    "        'file_path': 'data/raw/austen_pride-and-prejudice.txt',\n",
    "        'author': 'Jane Austen',\n",
    "    },\n",
    "    'austen_emma': {\n",
    "        'file_path': 'data/raw/austen_emma.txt',\n",
    "        'author': 'Jane Austen',\n",
    "    },\n",
    "    'tolstoy_youth': {\n",
    "        'file_path': 'data/raw/tolstoy_youth.txt',\n",
    "        'author': 'Leo Tolstoy',\n",
    "    },\n",
    "    'tolstoy_war-and-peace': {\n",
    "        'file_path': 'data/raw/tolstoy_war-and-peace.txt',\n",
    "        'author': 'Leo Tolstoy',\n",
    "    },\n",
    "    'tolstoy_anna-karenina': {\n",
    "        'file_path': 'data/raw/tolstoy_anna-karenina.txt',\n",
    "        'author': 'Leo Tolstoy',\n",
    "    },\n",
    "    'joyce_dubliners': {\n",
    "        'file_path': 'data/raw/joyce_dubliners.txt',\n",
    "        'author': 'James Joyce',\n",
    "    },\n",
    "    'joyce_a-portrait-of-the-artist-as-a-young-man': {\n",
    "        'file_path': 'data/raw/joyce_a-portrait-of-the-artist-as-a-young-man.txt',\n",
    "        'author': 'James Joyce',\n",
    "    },\n",
    "    'joyce_ulysses': {\n",
    "        'file_path': 'data/raw/joyce_ulysses.txt',\n",
    "        'author': 'James Joyce',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>The family of Dashwood had long been settled i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>The old gentleman died: his will was read, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>No sooner was his father’s funeral over, than ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>“Certainly not; but if you observe, people alw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>Edward Ferrars was not recommended to their go...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author                                           sentence\n",
       "0  Jane Austen  The family of Dashwood had long been settled i...\n",
       "1  Jane Austen  The old gentleman died: his will was read, and...\n",
       "2  Jane Austen  No sooner was his father’s funeral over, than ...\n",
       "3  Jane Austen  “Certainly not; but if you observe, people alw...\n",
       "4  Jane Austen  Edward Ferrars was not recommended to their go..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear dataframe con las oraciones extraídas de los libros\n",
    "df = pd.DataFrame(columns=['author', 'sentence'])\n",
    "\n",
    "# Extraer oraciones para cada libro y concatenarlas en el dataframe\n",
    "for book in raw_books.values():\n",
    "    corpus = load_raw_data(book['file_path'])\n",
    "    author = book['author']\n",
    "    \n",
    "    # Extraer oraciones\n",
    "    sentences = extract_sentences(corpus)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame({'author': author, 'sentence': sentences})], ignore_index=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar dataset como archivo CSV\n",
    "df.to_csv('data/classifier/sentences.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>num_training_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leo Tolstoy</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>James Joyce</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author  num_training_data\n",
       "0  Leo Tolstoy                866\n",
       "1  Jane Austen                426\n",
       "2  James Joyce                321"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contar el número de datos por autor\n",
    "author_counts = df['author'].value_counts()\n",
    "\n",
    "# Crear DataFrame resumen\n",
    "summary_df = author_counts.reset_index()\n",
    "summary_df.columns = ['author', 'num_training_data']\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocesamiento del Dataset\n",
    "\n",
    "Preprocesamos el dataset separandolo en entrenamiento y prueba. Adicionalmente, tokenizamos el texto para poder mapear las palabras a los embeddings construidos y usarlos como la capa de entrada de los modelos de redes neuronales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en conjunto de entrenamiento, validación y prueba\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(df['sentence'], df['author'], train_size=0.7, random_state=42)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, train_size=0.5, random_state=42)\n",
    "\n",
    "# Tokenización usando Keras\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "# Convertir el texto en secuencias de enteros\n",
    "x_train_seq = tokenizer.texts_to_sequences(x_train)\n",
    "x_val_seq = tokenizer.texts_to_sequences(x_val)\n",
    "x_test_seq = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "# Rellenar las secuencias para que tengan la misma longitud\n",
    "max_length = max([len(seq) for seq in x_train_seq])\n",
    "x_train_pad = pad_sequences(x_train_seq, maxlen=max_length, padding='post')\n",
    "x_val_pad = pad_sequences(x_val_seq, maxlen=max_length, padding='post')\n",
    "x_test_pad = pad_sequences(x_test_seq, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Definición de los Modelos de Redes Neuronales\n",
    "\n",
    "Cargamos los los embeddings de Word2Vec pre-entrenados, creamos las capas de embeddings a partir de ellos, y definimos los tres tipos de arquitecturas de redes neuronales que usaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta a los modelos Word2Vec combinados con diferentes tamaños de vectores\n",
    "books_models = [\n",
    "    'data/models/Books_50_CarlosRaulDeLaRosaPeredoJhonStewarRayoMosqueraMarioGarridoCordoba.model',\n",
    "    'data/models/Books_100_CarlosRaulDeLaRosaPeredoJhonStewarRayoMosqueraMarioGarridoCordoba.model',\n",
    "    'data/models/Books_300_CarlosRaulDeLaRosaPeredoJhonStewarRayoMosqueraMarioGarridoCordoba.model'\n",
    "]\n",
    "\n",
    "# Cargar los embeddings de Word2Vec pre-entrenados\n",
    "word2vec_model_50 = gensim.models.Word2Vec.load(books_models[0])\n",
    "word2vec_model_100 = gensim.models.Word2Vec.load(books_models[1])\n",
    "word2vec_model_300 = gensim.models.Word2Vec.load(books_models[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_layer(word2vec_model, tokenizer, max_length):\n",
    "    \"\"\"\n",
    "    Crea una capa de embeddings a partir de un modelo Word2Vec y un tokenizer.\n",
    "\n",
    "    Args:\n",
    "    word2vec_model: Modelo Word2Vec preentrenado.\n",
    "    tokenizer: Tokenizer que contiene el índice de palabras.\n",
    "    max_length (int): Longitud máxima de las secuencias de entrada.\n",
    "\n",
    "    Returns:\n",
    "    Embedding: Capa de embedding de Keras que utiliza la matriz de embeddings generada.\n",
    "    \"\"\"\n",
    "    # Crear la matriz de embeddings para el modelo Word2Vec\n",
    "    embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, word2vec_model.vector_size))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if word in word2vec_model.wv:\n",
    "            embedding_matrix[i] = word2vec_model.wv[word]\n",
    "\n",
    "    # Definir la capa de embedding en Keras\n",
    "    embedding_layer = layers.Embedding(input_dim=len(tokenizer.word_index) + 1,\n",
    "                                output_dim=word2vec_model.vector_size,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=max_length,\n",
    "                                trainable=False)\n",
    "    \n",
    "    return embedding_layer\n",
    "\n",
    "# Crear las capas de embeddings a partir de los modelos Word2Vec\n",
    "embedding_layer_50 = create_embedding_layer(word2vec_model_50, tokenizer, max_length)\n",
    "embedding_layer_100 = create_embedding_layer(word2vec_model_100, tokenizer, max_length)\n",
    "embedding_layer_300 = create_embedding_layer(word2vec_model_300, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitectura 1: Modelo sencillo\n",
    "def create_ffnn_model_1(embedding_layer):\n",
    "    \"\"\"\n",
    "    Crea un modelo de red neuronal feedforward simple.\n",
    "\n",
    "    Args:\n",
    "    embedding_layer: Capa de embeddings de Keras utilizada como entrada.\n",
    "\n",
    "    Returns:\n",
    "    Sequential: Modelo de red neuronal compilado.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "            layers.Input(shape=(max_length,)),\n",
    "            embedding_layer,\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(3, activation='softmax')\n",
    "        ])\n",
    "    return model\n",
    "\n",
    "# Arquitectura 2: Modelo con más capas\n",
    "def create_ffnn_model_2(embedding_layer):\n",
    "    \"\"\"\n",
    "    Crea un modelo de red neuronal feedforward con más capas.\n",
    "\n",
    "    Args:\n",
    "    embedding_layer: Capa de embeddings de Keras utilizada como entrada.\n",
    "\n",
    "    Returns:\n",
    "    Sequential: Modelo de red neuronal compilado.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "            layers.Input(shape=(max_length,)),\n",
    "            embedding_layer,\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(3, activation='softmax')\n",
    "        ])\n",
    "    return model\n",
    "\n",
    "# Arquitectura 3: Modelo con más unidades\n",
    "def create_ffnn_model_3(embedding_layer):\n",
    "    \"\"\"\n",
    "    Crea un modelo de red neuronal feedforward con más unidades.\n",
    "\n",
    "    Args:\n",
    "    embedding_layer: Capa de embeddings de Keras utilizada como entrada.\n",
    "\n",
    "    Returns:\n",
    "    Sequential: Modelo de red neuronal compilado.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "            layers.Input(shape=(max_length,)),\n",
    "            embedding_layer,\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(512, activation='relu'),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(3, activation='softmax')\n",
    "        ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creación y Evaluación de los Modelos de Redes Neuronales\n",
    "\n",
    "Creamos un modelo con cada tipo de arquitectura y capa de embeddings y evaluamos su accuracy, precision y recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación de etiquetas (autores)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = utils.to_categorical(label_encoder.fit_transform(y_train))\n",
    "y_val_encoded = utils.to_categorical(label_encoder.transform(y_val))\n",
    "y_test_encoded = utils.to_categorical(label_encoder.transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test_pad, y_test_encoded):\n",
    "    \"\"\"\n",
    "    Evalúa el rendimiento de un modelo entrenado calculando accuracy, precision y recall.\n",
    "    \n",
    "    Args:\n",
    "    model (keras.models.Model): El modelo entrenado.\n",
    "    x_test_pad (numpy.ndarray): Conjunto de datos de prueba preprocesados y tokenizados.\n",
    "    y_test_encoded (numpy.ndarray): Etiquetas de prueba codificadas en formato one-hot.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Un tupla que contiene:\n",
    "        - accuracy (float): La proporción de predicciones correctas.\n",
    "        - precision (float): La proporción de predicciones positivas correctas (precisión macro).\n",
    "        - recall (float): La proporción de verdaderos positivos detectados (recall macro).\n",
    "    \"\"\"\n",
    "    # Obtener predicciones del modelo\n",
    "    y_pred = model.predict(x_test_pad)\n",
    "    \n",
    "    # Convertir las predicciones y etiquetas de one-hot a clases\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test_encoded, axis=1)\n",
    "    \n",
    "    # Calcular accuracy\n",
    "    accuracy = np.mean(y_pred_classes == y_test_classes)\n",
    "    \n",
    "    # Calcular precisión y recall usando la métrica macro (promedio entre todas las clases)\n",
    "    precision = precision_score(y_test_classes, y_pred_classes, average='macro')\n",
    "    recall = recall_score(y_test_classes, y_pred_classes, average='macro')\n",
    "    \n",
    "    return accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando Modelo 1 con 50 dimensiones...\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 254, 50)           851050    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12700)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1625728   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,477,165\n",
      "Trainable params: 1,626,115\n",
      "Non-trainable params: 851,050\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 3s 30ms/step - loss: 0.5309 - accuracy: 0.7777 - val_loss: 0.4820 - val_accuracy: 0.8058\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0379 - accuracy: 0.9894 - val_loss: 0.4359 - val_accuracy: 0.8388\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4175 - val_accuracy: 0.8471\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4527 - val_accuracy: 0.8512\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4539 - val_accuracy: 0.8430\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4615 - val_accuracy: 0.8430\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 9.9170e-04 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.8471\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 8.0914e-04 - accuracy: 1.0000 - val_loss: 0.4698 - val_accuracy: 0.8388\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 6.7726e-04 - accuracy: 1.0000 - val_loss: 0.4737 - val_accuracy: 0.8388\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.7642e-04 - accuracy: 1.0000 - val_loss: 0.4768 - val_accuracy: 0.8430\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "\n",
      "Evaluación del Modelo 1 con embeddings de 50 dimensiones - Accuracy: 0.8842975206611571, Precision: 0.8711834765566109, Recall: 0.836504920838682 \n",
      "\n",
      "\n",
      "Entrenando Modelo 2 con 50 dimensiones...\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 254, 50)           851050    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 12700)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               3251456   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,135,789\n",
      "Trainable params: 3,284,739\n",
      "Non-trainable params: 851,050\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 3s 32ms/step - loss: 0.5643 - accuracy: 0.7591 - val_loss: 0.4204 - val_accuracy: 0.8264\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0433 - accuracy: 0.9920 - val_loss: 0.3635 - val_accuracy: 0.8719\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.4136 - val_accuracy: 0.8760\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4209 - val_accuracy: 0.8760\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 7.4991e-04 - accuracy: 1.0000 - val_loss: 0.4476 - val_accuracy: 0.8719\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 5.0702e-04 - accuracy: 1.0000 - val_loss: 0.4476 - val_accuracy: 0.8760\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 3.8708e-04 - accuracy: 1.0000 - val_loss: 0.4572 - val_accuracy: 0.8719\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 3.0619e-04 - accuracy: 1.0000 - val_loss: 0.4647 - val_accuracy: 0.8719\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 2.4818e-04 - accuracy: 1.0000 - val_loss: 0.4684 - val_accuracy: 0.8719\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 2.0638e-04 - accuracy: 1.0000 - val_loss: 0.4722 - val_accuracy: 0.8719\n",
      "8/8 [==============================] - 0s 7ms/step\n",
      "\n",
      "Evaluación del Modelo 2 con embeddings de 50 dimensiones - Accuracy: 0.9173553719008265, Precision: 0.9080086580086579, Recall: 0.8739229781771503 \n",
      "\n",
      "\n",
      "Entrenando Modelo 3 con 50 dimensiones...\n",
      "\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 254, 50)           851050    \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 12700)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               6502912   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,518,573\n",
      "Trainable params: 6,667,523\n",
      "Non-trainable params: 851,050\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 3s 46ms/step - loss: 0.5543 - accuracy: 0.7653 - val_loss: 0.4240 - val_accuracy: 0.8388\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0220 - accuracy: 0.9947 - val_loss: 0.4412 - val_accuracy: 0.8388\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5048 - val_accuracy: 0.8719\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 3.1749e-04 - accuracy: 1.0000 - val_loss: 0.5378 - val_accuracy: 0.8678\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 1.2511e-04 - accuracy: 1.0000 - val_loss: 0.5370 - val_accuracy: 0.8678\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 8.6585e-05 - accuracy: 1.0000 - val_loss: 0.5479 - val_accuracy: 0.8678\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 6.6520e-05 - accuracy: 1.0000 - val_loss: 0.5586 - val_accuracy: 0.8678\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 5.2816e-05 - accuracy: 1.0000 - val_loss: 0.5631 - val_accuracy: 0.8678\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 4.0815e-05 - accuracy: 1.0000 - val_loss: 0.5685 - val_accuracy: 0.8678\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 3.1022e-05 - accuracy: 1.0000 - val_loss: 0.5800 - val_accuracy: 0.8678\n",
      "8/8 [==============================] - 0s 9ms/step\n",
      "\n",
      "Evaluación del Modelo 3 con embeddings de 50 dimensiones - Accuracy: 0.9008264462809917, Precision: 0.8892227564102564, Recall: 0.8707445442875481 \n",
      "\n",
      "\n",
      "Entrenando Modelo 1 con 100 dimensiones...\n",
      "\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 254, 100)          1702100   \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 25400)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               3251328   \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,953,815\n",
      "Trainable params: 3,251,715\n",
      "Non-trainable params: 1,702,100\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 3s 39ms/step - loss: 0.5549 - accuracy: 0.7626 - val_loss: 0.3269 - val_accuracy: 0.8636\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0175 - accuracy: 0.9991 - val_loss: 0.3277 - val_accuracy: 0.8760\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.3305 - val_accuracy: 0.8678\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3355 - val_accuracy: 0.8719\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3375 - val_accuracy: 0.8678\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3410 - val_accuracy: 0.8719\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 9.5952e-04 - accuracy: 1.0000 - val_loss: 0.3432 - val_accuracy: 0.8802\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 7.6709e-04 - accuracy: 1.0000 - val_loss: 0.3453 - val_accuracy: 0.8760\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 6.3138e-04 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.8802\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 5.2913e-04 - accuracy: 1.0000 - val_loss: 0.3485 - val_accuracy: 0.8719\n",
      "8/8 [==============================] - 0s 7ms/step\n",
      "\n",
      "Evaluación del Modelo 1 con embeddings de 100 dimensiones - Accuracy: 0.9049586776859504, Precision: 0.8906728866270851, Recall: 0.8679477963200685 \n",
      "\n",
      "\n",
      "Entrenando Modelo 2 con 100 dimensiones...\n",
      "\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 254, 100)          1702100   \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 25400)             0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 256)               6502656   \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,238,039\n",
      "Trainable params: 6,535,939\n",
      "Non-trainable params: 1,702,100\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 3s 43ms/step - loss: 0.5225 - accuracy: 0.7573 - val_loss: 0.4604 - val_accuracy: 0.8512\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 0.0230 - accuracy: 0.9965 - val_loss: 0.4050 - val_accuracy: 0.8512\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3827 - val_accuracy: 0.8678\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 6.1297e-04 - accuracy: 1.0000 - val_loss: 0.3871 - val_accuracy: 0.8595\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 2.7229e-04 - accuracy: 1.0000 - val_loss: 0.4196 - val_accuracy: 0.8595\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 1.4691e-04 - accuracy: 1.0000 - val_loss: 0.4414 - val_accuracy: 0.8595\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 9.8632e-05 - accuracy: 1.0000 - val_loss: 0.4552 - val_accuracy: 0.8636\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.4909e-05 - accuracy: 1.0000 - val_loss: 0.4677 - val_accuracy: 0.8636\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 5.9066e-05 - accuracy: 1.0000 - val_loss: 0.4768 - val_accuracy: 0.8636\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 4.8824e-05 - accuracy: 1.0000 - val_loss: 0.4862 - val_accuracy: 0.8636\n",
      "8/8 [==============================] - 0s 10ms/step\n",
      "\n",
      "Evaluación del Modelo 2 con embeddings de 100 dimensiones - Accuracy: 0.8966942148760331, Precision: 0.8803155174758602, Recall: 0.8663585793752674 \n",
      "\n",
      "\n",
      "Entrenando Modelo 3 con 100 dimensiones...\n",
      "\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 254, 100)          1702100   \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 25400)             0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 512)               13005312  \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,872,023\n",
      "Trainable params: 13,169,923\n",
      "Non-trainable params: 1,702,100\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 4s 70ms/step - loss: 0.6514 - accuracy: 0.6953 - val_loss: 0.3400 - val_accuracy: 0.8719\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 2s 52ms/step - loss: 0.0633 - accuracy: 0.9761 - val_loss: 0.3490 - val_accuracy: 0.8719\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 0.0148 - accuracy: 0.9938 - val_loss: 0.5049 - val_accuracy: 0.8554\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.5231 - val_accuracy: 0.8802\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 3.2352e-04 - accuracy: 1.0000 - val_loss: 0.5535 - val_accuracy: 0.8802\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 2s 50ms/step - loss: 1.3961e-04 - accuracy: 1.0000 - val_loss: 0.5824 - val_accuracy: 0.8760\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 2s 52ms/step - loss: 8.3421e-05 - accuracy: 1.0000 - val_loss: 0.6057 - val_accuracy: 0.8719\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 2s 50ms/step - loss: 5.8933e-05 - accuracy: 1.0000 - val_loss: 0.6239 - val_accuracy: 0.8760\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 2s 50ms/step - loss: 4.5348e-05 - accuracy: 1.0000 - val_loss: 0.6402 - val_accuracy: 0.8760\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 2s 50ms/step - loss: 3.5972e-05 - accuracy: 1.0000 - val_loss: 0.6524 - val_accuracy: 0.8760\n",
      "8/8 [==============================] - 0s 11ms/step\n",
      "\n",
      "Evaluación del Modelo 3 con embeddings de 100 dimensiones - Accuracy: 0.9132231404958677, Precision: 0.9045864045864046, Recall: 0.8787445442875481 \n",
      "\n",
      "\n",
      "Entrenando Modelo 1 con 300 dimensiones...\n",
      "\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 254, 300)          5106300   \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 76200)             0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               9753728   \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,860,415\n",
      "Trainable params: 9,754,115\n",
      "Non-trainable params: 5,106,300\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 3s 56ms/step - loss: 0.5986 - accuracy: 0.7387 - val_loss: 0.4097 - val_accuracy: 0.8264\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.0287 - accuracy: 0.9965 - val_loss: 0.4051 - val_accuracy: 0.8388\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.8223\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4270 - val_accuracy: 0.8388\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4299 - val_accuracy: 0.8388\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4355 - val_accuracy: 0.8388\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4397 - val_accuracy: 0.8388\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4478 - val_accuracy: 0.8388\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 9.0586e-04 - accuracy: 1.0000 - val_loss: 0.4478 - val_accuracy: 0.8430\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 7.5769e-04 - accuracy: 1.0000 - val_loss: 0.4540 - val_accuracy: 0.8430\n",
      "8/8 [==============================] - 0s 11ms/step\n",
      "\n",
      "Evaluación del Modelo 1 con embeddings de 300 dimensiones - Accuracy: 0.8966942148760331, Precision: 0.8856925143409202, Recall: 0.8571510483525887 \n",
      "\n",
      "\n",
      "Entrenando Modelo 2 con 300 dimensiones...\n",
      "\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 254, 300)          5106300   \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 76200)             0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 256)               19507456  \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,647,039\n",
      "Trainable params: 19,540,739\n",
      "Non-trainable params: 5,106,300\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 5s 97ms/step - loss: 0.5637 - accuracy: 0.7626 - val_loss: 0.3857 - val_accuracy: 0.8636\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 0.0177 - accuracy: 0.9965 - val_loss: 0.3631 - val_accuracy: 0.8636\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 3s 71ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3942 - val_accuracy: 0.8595\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 5.3875e-04 - accuracy: 1.0000 - val_loss: 0.3999 - val_accuracy: 0.8554\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 3s 71ms/step - loss: 3.3032e-04 - accuracy: 1.0000 - val_loss: 0.4078 - val_accuracy: 0.8554\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 2.2327e-04 - accuracy: 1.0000 - val_loss: 0.4150 - val_accuracy: 0.8636\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 3s 70ms/step - loss: 1.6321e-04 - accuracy: 1.0000 - val_loss: 0.4210 - val_accuracy: 0.8719\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 3s 73ms/step - loss: 1.2488e-04 - accuracy: 1.0000 - val_loss: 0.4278 - val_accuracy: 0.8760\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 3s 70ms/step - loss: 9.6802e-05 - accuracy: 1.0000 - val_loss: 0.4339 - val_accuracy: 0.8760\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 3s 73ms/step - loss: 7.7210e-05 - accuracy: 1.0000 - val_loss: 0.4394 - val_accuracy: 0.8760\n",
      "8/8 [==============================] - 0s 14ms/step\n",
      "\n",
      "Evaluación del Modelo 2 con embeddings de 300 dimensiones - Accuracy: 0.8925619834710744, Precision: 0.8969939499475365, Recall: 0.8380941377834831 \n",
      "\n",
      "\n",
      "Entrenando Modelo 3 con 300 dimensiones...\n",
      "\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 254, 300)          5106300   \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 76200)             0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 512)               39014912  \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,285,823\n",
      "Trainable params: 39,179,523\n",
      "Non-trainable params: 5,106,300\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 7s 152ms/step - loss: 0.5430 - accuracy: 0.7591 - val_loss: 0.5357 - val_accuracy: 0.8017\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 5s 134ms/step - loss: 0.0237 - accuracy: 0.9876 - val_loss: 0.4968 - val_accuracy: 0.8512\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 5s 136ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6911 - val_accuracy: 0.8512\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 5s 141ms/step - loss: 3.1124e-04 - accuracy: 1.0000 - val_loss: 0.6185 - val_accuracy: 0.8554\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 5s 138ms/step - loss: 8.9210e-05 - accuracy: 1.0000 - val_loss: 0.6425 - val_accuracy: 0.8595\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 5.0077e-05 - accuracy: 1.0000 - val_loss: 0.6542 - val_accuracy: 0.8512\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 5s 137ms/step - loss: 3.9224e-05 - accuracy: 1.0000 - val_loss: 0.6582 - val_accuracy: 0.8636\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 5s 135ms/step - loss: 3.2462e-05 - accuracy: 1.0000 - val_loss: 0.6641 - val_accuracy: 0.8595\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 5s 136ms/step - loss: 2.7064e-05 - accuracy: 1.0000 - val_loss: 0.6704 - val_accuracy: 0.8595\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 5s 135ms/step - loss: 2.2925e-05 - accuracy: 1.0000 - val_loss: 0.6766 - val_accuracy: 0.8595\n",
      "8/8 [==============================] - 0s 33ms/step\n",
      "\n",
      "Evaluación del Modelo 3 con embeddings de 300 dimensiones - Accuracy: 0.8636363636363636, Precision: 0.8473833659880171, Recall: 0.826915703893881 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterar sobre las capas de embeddings y las dimensiones de los modelos Word2Vec (50, 100, 300 dimensiones)\n",
    "for embedding_layer, dimensions in [(embedding_layer_50, 50), (embedding_layer_100, 100), (embedding_layer_300, 300)]:\n",
    "    \n",
    "    # Iterar sobre las funciones de creación de modelos FFNN (modelos 1, 2 y 3)\n",
    "    for i, model_fn in enumerate([create_ffnn_model_1, create_ffnn_model_2, create_ffnn_model_3], 1):\n",
    "        \n",
    "        # Crear el modelo usando la capa de embeddings actual\n",
    "        print(f\"\\nEntrenando Modelo {i} con {dimensions} dimensiones...\" \"\\n\")\n",
    "        model = model_fn(embedding_layer)\n",
    "        \n",
    "        # Mostrar el resumen del modelo (capas y dimensiones)\n",
    "        model.summary()\n",
    "\n",
    "        # Compilar y entrenar el modelo\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "        history = model.fit(x_train_pad, y_train_encoded, \n",
    "                            epochs=10, batch_size=32, \n",
    "                            validation_data=(x_val_pad, y_val_encoded), \n",
    "                            verbose=1)\n",
    "        \n",
    "        # Evaluar el modelo en el conjunto de prueba\n",
    "        accuracy, precision, recall = evaluate_model(model, x_test_pad, y_test_encoded)\n",
    "\n",
    "        # Mostrar los resultados finales de la evaluación (accuracy, precision y recall)\n",
    "        print(f\"\\nEvaluación del Modelo {i} con embeddings de {dimensions} dimensiones - Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\", \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
