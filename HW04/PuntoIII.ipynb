{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de Texto Usando Embeddings Personalizados\n",
    "\n",
    "Este notebook realiza la clasificación de texto para identificar al autor de un texto entre tres autores posibles, utilizando embeddings personalizados y redes neuronales feed-forward (FFNN). Procesa los datos de texto, entrena múltiples arquitecturas de redes neuronales y evalúa su rendimiento en base a la precisión, exactitud y recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import (\n",
    "    utils,\n",
    "    layers,\n",
    "    models,\n",
    "    callbacks\n",
    ")\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creación del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Carga el texto crudo a partir de un archivo de texto\n",
    "    \n",
    "    Args:\n",
    "    file_path (str): Ruta del archivo de texto.\n",
    "    \n",
    "    Returns:\n",
    "    str: Texto crudo.\n",
    "    \"\"\"\n",
    "    # Leer el texto crudo\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    return text\n",
    "\n",
    "def extract_sentences(book: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Extrae extractos de un libro asegurando que cumplan con ciertas condiciones de tamaño\n",
    "    \n",
    "    Args:\n",
    "    book (str): Texto crudo.\n",
    "    \n",
    "    Returns:\n",
    "    list[str]: Lista de extractos del libro.\n",
    "    \"\"\"\n",
    "    # Separar el texto en bloques usando líneas completamente vacías como delimitadores\n",
    "    lines = book.split('***')[2].split('\\n\\n')\n",
    "\n",
    "    # Eliminar espacios en blanco al inicio y al final de cada línea\n",
    "    lines = [line.strip() for line in lines]\n",
    "\n",
    "    # Eliminar lineas vacias y títulos no relevantes\n",
    "    lines = [line for line in lines if line and not line.startswith('CHAPTER') and not line.startswith('[Illustration]')]\n",
    "\n",
    "    # Eliminar saltos de líneas de las oraciones\n",
    "    lines = [line.replace('\\n', ' ') for line in lines]\n",
    "\n",
    "    # Usar word count para extraer las oraciones\n",
    "    sentences = []\n",
    "    for sentence in lines:\n",
    "        if len(sentence.split()) > 250:\n",
    "            sentences.extend(sent_tokenize(sentence))  # Dividir en oraciones si es demasiado largo\n",
    "        else:\n",
    "            sentences.append(sentence)\n",
    "\n",
    "    # Filtrar por oraciones que tienen entre 150 y 250 palabras\n",
    "    sentences = [sentence for sentence in sentences if 150 <= len(sentence.split()) <= 250]\n",
    "\n",
    "    # Eliminar espacios en blanco al inicio y al final de cada línea nuevamente\n",
    "    sentences = [sentence.strip() for sentence in sentences]\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta a los libros originales junto con su autor\n",
    "raw_books = {\n",
    "    'austen_sense-and-sensibility': {\n",
    "        'file_path': 'data/raw/austen_sense-and-sensibility.txt',\n",
    "        'author': 'Jane Austen',\n",
    "    },\n",
    "    'austen_pride-and-prejudice': {\n",
    "        'file_path': 'data/raw/austen_pride-and-prejudice.txt',\n",
    "        'author': 'Jane Austen',\n",
    "    },\n",
    "    'austen_emma': {\n",
    "        'file_path': 'data/raw/austen_emma.txt',\n",
    "        'author': 'Jane Austen',\n",
    "    },\n",
    "    'tolstoy_youth': {\n",
    "        'file_path': 'data/raw/tolstoy_youth.txt',\n",
    "        'author': 'Leo Tolstoy',\n",
    "    },\n",
    "    'tolstoy_war-and-peace': {\n",
    "        'file_path': 'data/raw/tolstoy_war-and-peace.txt',\n",
    "        'author': 'Leo Tolstoy',\n",
    "    },\n",
    "    'tolstoy_anna-karenina': {\n",
    "        'file_path': 'data/raw/tolstoy_anna-karenina.txt',\n",
    "        'author': 'Leo Tolstoy',\n",
    "    },\n",
    "    'joyce_dubliners': {\n",
    "        'file_path': 'data/raw/joyce_dubliners.txt',\n",
    "        'author': 'James Joyce',\n",
    "    },\n",
    "    'joyce_a-portrait-of-the-artist-as-a-young-man': {\n",
    "        'file_path': 'data/raw/joyce_a-portrait-of-the-artist-as-a-young-man.txt',\n",
    "        'author': 'James Joyce',\n",
    "    },\n",
    "    'joyce_ulysses': {\n",
    "        'file_path': 'data/raw/joyce_ulysses.txt',\n",
    "        'author': 'James Joyce',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>The family of Dashwood had long been settled i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>The old gentleman died: his will was read, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>No sooner was his father’s funeral over, than ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>“Certainly not; but if you observe, people alw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>Edward Ferrars was not recommended to their go...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author                                           sentence\n",
       "0  Jane Austen  The family of Dashwood had long been settled i...\n",
       "1  Jane Austen  The old gentleman died: his will was read, and...\n",
       "2  Jane Austen  No sooner was his father’s funeral over, than ...\n",
       "3  Jane Austen  “Certainly not; but if you observe, people alw...\n",
       "4  Jane Austen  Edward Ferrars was not recommended to their go..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear dataframe con las oraciones extraídas de los libros\n",
    "df = pd.DataFrame(columns=['author', 'sentence'])\n",
    "\n",
    "# Extraer oraciones para cada libro y concatenarlas en el dataframe\n",
    "for book in raw_books.values():\n",
    "    corpus = load_raw_data(book['file_path'])\n",
    "    author = book['author']\n",
    "    \n",
    "    # Extraer oraciones\n",
    "    sentences = extract_sentences(corpus)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame({'author': author, 'sentence': sentences})], ignore_index=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar dataset como archivo CSV\n",
    "df.to_csv('data/classifier/sentences.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>num_training_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leo Tolstoy</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>James Joyce</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author  num_training_data\n",
       "0  Leo Tolstoy                866\n",
       "1  Jane Austen                426\n",
       "2  James Joyce                321"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contar el número de datos por autor\n",
    "author_counts = df['author'].value_counts()\n",
    "\n",
    "# Crear DataFrame resumen\n",
    "summary_df = author_counts.reset_index()\n",
    "summary_df.columns = ['author', 'num_training_data']\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocesamiento de los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en conjunto de entrenamiento, validación y prueba\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(df['sentence'], df['author'], train_size=0.7, random_state=42)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, train_size=0.5, random_state=42)\n",
    "\n",
    "# Tokenización usando Keras\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "# Convertir el texto en secuencias de enteros\n",
    "x_train_seq = tokenizer.texts_to_sequences(x_train)\n",
    "x_val_seq = tokenizer.texts_to_sequences(x_val)\n",
    "x_test_seq = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "# Rellenar las secuencias para que tengan la misma longitud\n",
    "max_length = max([len(seq) for seq in x_train_seq])\n",
    "x_train_pad = pad_sequences(x_train_seq, maxlen=max_length, padding='post')\n",
    "x_val_pad = pad_sequences(x_val_seq, maxlen=max_length, padding='post')\n",
    "x_test_pad = pad_sequences(x_test_seq, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Definición de los Modelos de Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta a los modelos Word2Vec combinados con diferentes tamaños de vectores\n",
    "books_models = [\n",
    "    'data/models/Books_50_CarlosRaulDeLaRosaPeredoJhonStewarRayoMosqueraMarioGarridoCordoba.model',\n",
    "    'data/models/Books_100_CarlosRaulDeLaRosaPeredoJhonStewarRayoMosqueraMarioGarridoCordoba.model',\n",
    "    'data/models/Books_300_CarlosRaulDeLaRosaPeredoJhonStewarRayoMosqueraMarioGarridoCordoba.model'\n",
    "]\n",
    "\n",
    "# Cargar los embeddings de Word2Vec pre-entrenados\n",
    "word2vec_model_50 = gensim.models.Word2Vec.load(books_models[0])\n",
    "word2vec_model_100 = gensim.models.Word2Vec.load(books_models[1])\n",
    "word2vec_model_300 = gensim.models.Word2Vec.load(books_models[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_layer(word2vec_model, tokenizer, max_length):\n",
    "    \"\"\"\n",
    "    Crea una capa de embeddings a partir de un modelo Word2Vec y un tokenizer.\n",
    "\n",
    "    Args:\n",
    "    word2vec_model: Modelo Word2Vec preentrenado.\n",
    "    tokenizer: Tokenizer que contiene el índice de palabras.\n",
    "    max_length (int): Longitud máxima de las secuencias de entrada.\n",
    "\n",
    "    Returns:\n",
    "    Embedding: Capa de embedding de Keras que utiliza la matriz de embeddings generada.\n",
    "    \"\"\"\n",
    "    # Crear la matriz de embeddings para el modelo Word2Vec\n",
    "    embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, word2vec_model.vector_size))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if word in word2vec_model.wv:\n",
    "            embedding_matrix[i] = word2vec_model.wv[word]\n",
    "\n",
    "    # Definir la capa de embedding en Keras\n",
    "    embedding_layer = layers.Embedding(input_dim=len(tokenizer.word_index) + 1,\n",
    "                                output_dim=word2vec_model.vector_size,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=max_length,\n",
    "                                trainable=False)\n",
    "    \n",
    "    return embedding_layer\n",
    "\n",
    "# Crear las capas de embeddings a partir de los modelos Word2Vec\n",
    "embedding_layer_50 = create_embedding_layer(word2vec_model_50, tokenizer, max_length)\n",
    "embedding_layer_100 = create_embedding_layer(word2vec_model_100, tokenizer, max_length)\n",
    "embedding_layer_300 = create_embedding_layer(word2vec_model_300, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitectura 1: Modelo sencillo\n",
    "def create_ffnn_model_1(embedding_layer):\n",
    "    \"\"\"\n",
    "    Crea un modelo de red neuronal feedforward simple.\n",
    "\n",
    "    Args:\n",
    "    embedding_layer: Capa de embeddings de Keras utilizada como entrada.\n",
    "\n",
    "    Returns:\n",
    "    Sequential: Modelo de red neuronal compilado.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "            layers.Input(shape=(max_length,)),\n",
    "            embedding_layer,\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(3, activation='softmax')\n",
    "        ])\n",
    "    return model\n",
    "\n",
    "# Arquitectura 2: Modelo con más capas\n",
    "def create_ffnn_model_2(embedding_layer):\n",
    "    \"\"\"\n",
    "    Crea un modelo de red neuronal feedforward con más capas.\n",
    "\n",
    "    Args:\n",
    "    embedding_layer: Capa de embeddings de Keras utilizada como entrada.\n",
    "\n",
    "    Returns:\n",
    "    Sequential: Modelo de red neuronal compilado.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "            layers.Input(shape=(max_length,)),\n",
    "            embedding_layer,\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(3, activation='softmax')\n",
    "        ])\n",
    "    return model\n",
    "\n",
    "# Arquitectura 3: Modelo con más unidades\n",
    "def create_ffnn_model_3(embedding_layer):\n",
    "    \"\"\"\n",
    "    Crea un modelo de red neuronal feedforward con más unidades.\n",
    "\n",
    "    Args:\n",
    "    embedding_layer: Capa de embeddings de Keras utilizada como entrada.\n",
    "\n",
    "    Returns:\n",
    "    Sequential: Modelo de red neuronal compilado.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "            layers.Input(shape=(max_length,)),\n",
    "            embedding_layer,\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(512, activation='relu'),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(3, activation='softmax')\n",
    "        ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento y Evaluación de los Modelos de Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación de etiquetas (autores)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = utils.to_categorical(label_encoder.fit_transform(y_train))\n",
    "y_val_encoded = utils.to_categorical(label_encoder.transform(y_val))\n",
    "y_test_encoded = utils.to_categorical(label_encoder.transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test_pad, y_test_encoded):\n",
    "    \"\"\"\n",
    "    Evalúa el rendimiento de un modelo entrenado calculando accuracy, precision y recall.\n",
    "    \n",
    "    Args:\n",
    "    model (keras.models.Model): El modelo entrenado.\n",
    "    x_test_pad (numpy.ndarray): Conjunto de datos de prueba preprocesados y tokenizados.\n",
    "    y_test_encoded (numpy.ndarray): Etiquetas de prueba codificadas en formato one-hot.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Un tupla que contiene:\n",
    "        - accuracy (float): La proporción de predicciones correctas.\n",
    "        - precision (float): La proporción de predicciones positivas correctas (precisión macro).\n",
    "        - recall (float): La proporción de verdaderos positivos detectados (recall macro).\n",
    "    \"\"\"\n",
    "    # Obtener predicciones del modelo\n",
    "    y_pred = model.predict(x_test_pad)\n",
    "    \n",
    "    # Convertir las predicciones y etiquetas de one-hot a clases\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test_encoded, axis=1)\n",
    "    \n",
    "    # Calcular accuracy\n",
    "    accuracy = np.mean(y_pred_classes == y_test_classes)\n",
    "    \n",
    "    # Calcular precisión y recall usando la métrica macro (promedio entre todas las clases)\n",
    "    precision = precision_score(y_test_classes, y_pred_classes, average='macro')\n",
    "    recall = recall_score(y_test_classes, y_pred_classes, average='macro')\n",
    "    \n",
    "    return accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando Modelo 1 con 50 dimensiones...\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 254, 50)           851050    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12700)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1625728   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,477,165\n",
      "Trainable params: 1,626,115\n",
      "Non-trainable params: 851,050\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.6074 - accuracy: 0.7148 - val_loss: 0.3698 - val_accuracy: 0.8554\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0328 - accuracy: 0.9965 - val_loss: 0.3736 - val_accuracy: 0.8554\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.3723 - val_accuracy: 0.8719\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3867 - val_accuracy: 0.8719\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3927 - val_accuracy: 0.8843\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4029 - val_accuracy: 0.8719\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3984 - val_accuracy: 0.8719\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4019 - val_accuracy: 0.8719\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 8.6753e-04 - accuracy: 1.0000 - val_loss: 0.4080 - val_accuracy: 0.8719\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 7.2593e-04 - accuracy: 1.0000 - val_loss: 0.4084 - val_accuracy: 0.8719\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "\n",
      "Evaluación del Modelo 1 con embeddings de 50 dimensiones - Accuracy: 0.9132231404958677, Precision: 0.9049144987627251, Recall: 0.8750004278990158 \n",
      "\n",
      "\n",
      "Entrenando Modelo 2 con 50 dimensiones...\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 254, 50)           851050    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 12700)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               3251456   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,135,789\n",
      "Trainable params: 3,284,739\n",
      "Non-trainable params: 851,050\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.5656 - accuracy: 0.7626 - val_loss: 0.3957 - val_accuracy: 0.8388\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0313 - accuracy: 0.9947 - val_loss: 0.3975 - val_accuracy: 0.8678\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4052 - val_accuracy: 0.8636\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4084 - val_accuracy: 0.8719\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 6.3793e-04 - accuracy: 1.0000 - val_loss: 0.4216 - val_accuracy: 0.8636\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 4.4776e-04 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 0.8636\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 3.3672e-04 - accuracy: 1.0000 - val_loss: 0.4345 - val_accuracy: 0.8678\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 2.6215e-04 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.8678\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 2.1126e-04 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.8678\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 1.7221e-04 - accuracy: 1.0000 - val_loss: 0.4501 - val_accuracy: 0.8678\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "\n",
      "Evaluación del Modelo 2 con embeddings de 50 dimensiones - Accuracy: 0.9132231404958677, Precision: 0.902267871017871, Recall: 0.8657928968763372 \n",
      "\n",
      "\n",
      "Entrenando Modelo 3 con 50 dimensiones...\n",
      "\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 254, 50)           851050    \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 12700)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               6502912   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,518,573\n",
      "Trainable params: 6,667,523\n",
      "Non-trainable params: 851,050\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 2s 31ms/step - loss: 0.5530 - accuracy: 0.7617 - val_loss: 0.3514 - val_accuracy: 0.8554\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0427 - accuracy: 0.9867 - val_loss: 0.5386 - val_accuracy: 0.8471\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.4941 - val_accuracy: 0.8512\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4601 - val_accuracy: 0.8595\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 3.8812e-04 - accuracy: 1.0000 - val_loss: 0.4971 - val_accuracy: 0.8636\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 1.0852e-04 - accuracy: 1.0000 - val_loss: 0.5000 - val_accuracy: 0.8678\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 7.7968e-05 - accuracy: 1.0000 - val_loss: 0.5103 - val_accuracy: 0.8802\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 6.1265e-05 - accuracy: 1.0000 - val_loss: 0.5171 - val_accuracy: 0.8802\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 5.0376e-05 - accuracy: 1.0000 - val_loss: 0.5239 - val_accuracy: 0.8802\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 4.1693e-05 - accuracy: 1.0000 - val_loss: 0.5311 - val_accuracy: 0.8802\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "\n",
      "Evaluación del Modelo 3 con embeddings de 50 dimensiones - Accuracy: 0.9049586776859504, Precision: 0.8869210892466706, Recall: 0.8659229781771502 \n",
      "\n",
      "\n",
      "Entrenando Modelo 1 con 100 dimensiones...\n",
      "\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 254, 100)          1702100   \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 25400)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               3251328   \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,953,815\n",
      "Trainable params: 3,251,715\n",
      "Non-trainable params: 1,702,100\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 2s 26ms/step - loss: 0.5716 - accuracy: 0.7520 - val_loss: 0.4146 - val_accuracy: 0.8264\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0451 - accuracy: 0.9947 - val_loss: 0.4271 - val_accuracy: 0.8430\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4655 - val_accuracy: 0.8388\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4631 - val_accuracy: 0.8306\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.8264\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4773 - val_accuracy: 0.8306\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4857 - val_accuracy: 0.8306\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.8264\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 9.1751e-04 - accuracy: 1.0000 - val_loss: 0.4943 - val_accuracy: 0.8264\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 7.6879e-04 - accuracy: 1.0000 - val_loss: 0.4933 - val_accuracy: 0.8306\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "\n",
      "Evaluación del Modelo 1 con embeddings de 100 dimensiones - Accuracy: 0.8925619834710744, Precision: 0.8802083007667986, Recall: 0.8398134360290972 \n",
      "\n",
      "\n",
      "Entrenando Modelo 2 con 100 dimensiones...\n",
      "\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 254, 100)          1702100   \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 25400)             0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 256)               6502656   \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,238,039\n",
      "Trainable params: 6,535,939\n",
      "Non-trainable params: 1,702,100\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 2s 30ms/step - loss: 0.5026 - accuracy: 0.7795 - val_loss: 0.3913 - val_accuracy: 0.8140\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.0233 - accuracy: 0.9965 - val_loss: 0.4319 - val_accuracy: 0.8430\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4574 - val_accuracy: 0.8512\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 4.7880e-04 - accuracy: 1.0000 - val_loss: 0.4627 - val_accuracy: 0.8512\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 3.0865e-04 - accuracy: 1.0000 - val_loss: 0.4733 - val_accuracy: 0.8554\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 2.1938e-04 - accuracy: 1.0000 - val_loss: 0.4839 - val_accuracy: 0.8554\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 1.6381e-04 - accuracy: 1.0000 - val_loss: 0.4925 - val_accuracy: 0.8512\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 1.2654e-04 - accuracy: 1.0000 - val_loss: 0.5008 - val_accuracy: 0.8512\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 1.0103e-04 - accuracy: 1.0000 - val_loss: 0.5085 - val_accuracy: 0.8471\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 8.2093e-05 - accuracy: 1.0000 - val_loss: 0.5155 - val_accuracy: 0.8512\n",
      "8/8 [==============================] - 0s 6ms/step\n",
      "\n",
      "Evaluación del Modelo 2 con embeddings de 100 dimensiones - Accuracy: 0.9008264462809917, Precision: 0.8871984649122807, Recall: 0.8744886606760804 \n",
      "\n",
      "\n",
      "Entrenando Modelo 3 con 100 dimensiones...\n",
      "\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 254, 100)          1702100   \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 25400)             0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 512)               13005312  \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,872,023\n",
      "Trainable params: 13,169,923\n",
      "Non-trainable params: 1,702,100\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 3s 53ms/step - loss: 0.5903 - accuracy: 0.7520 - val_loss: 0.4145 - val_accuracy: 0.8182\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.0386 - accuracy: 0.9858 - val_loss: 0.5260 - val_accuracy: 0.8347\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5494 - val_accuracy: 0.8471\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 2.5372e-04 - accuracy: 1.0000 - val_loss: 0.5885 - val_accuracy: 0.8430\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 1.3371e-04 - accuracy: 1.0000 - val_loss: 0.5996 - val_accuracy: 0.8430\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 9.3645e-05 - accuracy: 1.0000 - val_loss: 0.6104 - val_accuracy: 0.8471\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 7.0409e-05 - accuracy: 1.0000 - val_loss: 0.6211 - val_accuracy: 0.8471\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 5.4841e-05 - accuracy: 1.0000 - val_loss: 0.6288 - val_accuracy: 0.8430\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 4.4220e-05 - accuracy: 1.0000 - val_loss: 0.6374 - val_accuracy: 0.8471\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 3.6628e-05 - accuracy: 1.0000 - val_loss: 0.6448 - val_accuracy: 0.8471\n",
      "8/8 [==============================] - 0s 11ms/step\n",
      "\n",
      "Evaluación del Modelo 3 con embeddings de 100 dimensiones - Accuracy: 0.9008264462809917, Precision: 0.8831416031416032, Recall: 0.8652811296534018 \n",
      "\n",
      "\n",
      "Entrenando Modelo 1 con 300 dimensiones...\n",
      "\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 254, 300)          5106300   \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 76200)             0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               9753728   \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,860,415\n",
      "Trainable params: 9,754,115\n",
      "Non-trainable params: 5,106,300\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 2s 40ms/step - loss: 0.5882 - accuracy: 0.7653 - val_loss: 0.4166 - val_accuracy: 0.8430\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.0275 - accuracy: 0.9947 - val_loss: 0.3680 - val_accuracy: 0.8636\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.3838 - val_accuracy: 0.8636\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.8595\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3907 - val_accuracy: 0.8636\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3943 - val_accuracy: 0.8636\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 9.4969e-04 - accuracy: 1.0000 - val_loss: 0.3977 - val_accuracy: 0.8636\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.1844e-04 - accuracy: 1.0000 - val_loss: 0.3997 - val_accuracy: 0.8636\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 5.4108e-04 - accuracy: 1.0000 - val_loss: 0.4036 - val_accuracy: 0.8636\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 4.0896e-04 - accuracy: 1.0000 - val_loss: 0.4111 - val_accuracy: 0.8636\n",
      "8/8 [==============================] - 0s 8ms/step\n",
      "\n",
      "Evaluación del Modelo 1 con embeddings de 300 dimensiones - Accuracy: 0.9090909090909091, Precision: 0.9018313040062843, Recall: 0.8614069319640564 \n",
      "\n",
      "\n",
      "Entrenando Modelo 2 con 300 dimensiones...\n",
      "\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 254, 300)          5106300   \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 76200)             0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 256)               19507456  \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,647,039\n",
      "Trainable params: 19,540,739\n",
      "Non-trainable params: 5,106,300\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 4s 79ms/step - loss: 0.5867 - accuracy: 0.7892 - val_loss: 0.3634 - val_accuracy: 0.8636\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 2s 59ms/step - loss: 0.0277 - accuracy: 0.9903 - val_loss: 0.3971 - val_accuracy: 0.8512\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 2s 65ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4082 - val_accuracy: 0.8636\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 2s 63ms/step - loss: 7.9020e-04 - accuracy: 1.0000 - val_loss: 0.4210 - val_accuracy: 0.8636\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 2s 65ms/step - loss: 4.6355e-04 - accuracy: 1.0000 - val_loss: 0.4241 - val_accuracy: 0.8636\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 2s 62ms/step - loss: 3.0647e-04 - accuracy: 1.0000 - val_loss: 0.4344 - val_accuracy: 0.8636\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 2s 61ms/step - loss: 2.0835e-04 - accuracy: 1.0000 - val_loss: 0.4472 - val_accuracy: 0.8636\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 2s 59ms/step - loss: 1.4883e-04 - accuracy: 1.0000 - val_loss: 0.4535 - val_accuracy: 0.8678\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 1.1064e-04 - accuracy: 1.0000 - val_loss: 0.4606 - val_accuracy: 0.8678\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 2s 61ms/step - loss: 8.6075e-05 - accuracy: 1.0000 - val_loss: 0.4642 - val_accuracy: 0.8636\n",
      "8/8 [==============================] - 0s 12ms/step\n",
      "\n",
      "Evaluación del Modelo 2 con embeddings de 300 dimensiones - Accuracy: 0.9049586776859504, Precision: 0.8926650404978579, Recall: 0.8624843816859221 \n",
      "\n",
      "\n",
      "Entrenando Modelo 3 con 300 dimensiones...\n",
      "\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 254, 300)          5106300   \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 76200)             0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 512)               39014912  \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,285,823\n",
      "Trainable params: 39,179,523\n",
      "Non-trainable params: 5,106,300\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 8s 154ms/step - loss: 0.6179 - accuracy: 0.7228 - val_loss: 0.3913 - val_accuracy: 0.8347\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.0315 - accuracy: 0.9903 - val_loss: 0.4086 - val_accuracy: 0.8636\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 4s 119ms/step - loss: 7.9263e-04 - accuracy: 1.0000 - val_loss: 0.4740 - val_accuracy: 0.8636\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 4s 125ms/step - loss: 1.4464e-04 - accuracy: 1.0000 - val_loss: 0.5175 - val_accuracy: 0.8636\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 5s 126ms/step - loss: 7.3188e-05 - accuracy: 1.0000 - val_loss: 0.5362 - val_accuracy: 0.8636\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 5s 128ms/step - loss: 4.7453e-05 - accuracy: 1.0000 - val_loss: 0.5507 - val_accuracy: 0.8636\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 5s 138ms/step - loss: 3.3836e-05 - accuracy: 1.0000 - val_loss: 0.5659 - val_accuracy: 0.8678\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 5s 131ms/step - loss: 2.5158e-05 - accuracy: 1.0000 - val_loss: 0.5750 - val_accuracy: 0.8636\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 4s 117ms/step - loss: 1.9449e-05 - accuracy: 1.0000 - val_loss: 0.5867 - val_accuracy: 0.8636\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 4s 118ms/step - loss: 1.5490e-05 - accuracy: 1.0000 - val_loss: 0.5968 - val_accuracy: 0.8636\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "\n",
      "Evaluación del Modelo 3 con embeddings de 300 dimensiones - Accuracy: 0.8966942148760331, Precision: 0.8870192307692308, Recall: 0.8534069319640566 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterar sobre las capas de embeddings y las dimensiones de los modelos Word2Vec (50, 100, 300 dimensiones)\n",
    "for embedding_layer, dimensions in [(embedding_layer_50, 50), (embedding_layer_100, 100), (embedding_layer_300, 300)]:\n",
    "    \n",
    "    # Iterar sobre las funciones de creación de modelos FFNN (modelos 1, 2 y 3)\n",
    "    for i, model_fn in enumerate([create_ffnn_model_1, create_ffnn_model_2, create_ffnn_model_3], 1):\n",
    "        \n",
    "        # Crear el modelo usando la capa de embeddings actual\n",
    "        print(f\"\\nEntrenando Modelo {i} con {dimensions} dimensiones...\" \"\\n\")\n",
    "        model = model_fn(embedding_layer)\n",
    "        \n",
    "        # Mostrar el resumen del modelo (capas y dimensiones)\n",
    "        model.summary()\n",
    "\n",
    "        # Compilar y entrenar el modelo\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "        history = model.fit(x_train_pad, y_train_encoded, \n",
    "                            epochs=10, batch_size=32, \n",
    "                            validation_data=(x_val_pad, y_val_encoded), \n",
    "                            verbose=1)\n",
    "        \n",
    "        # Evaluar el modelo en el conjunto de prueba\n",
    "        accuracy, precision, recall = evaluate_model(model, x_test_pad, y_test_encoded)\n",
    "\n",
    "        # Mostrar los resultados finales de la evaluación (accuracy, precision y recall)\n",
    "        print(f\"\\nEvaluación del Modelo {i} con embeddings de {dimensions} dimensiones - Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\", \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
