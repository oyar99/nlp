{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de Texto Usando Embeddings Personalizados\n",
    "\n",
    "Este notebook presenta la creación de un dataset de oraciones con su respectivo autor, con el que luego se entrenan varios clasificadores usando variaciones de redes feed-forward y distintos embeddings pre-entrenados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creación del Dataset\n",
    "\n",
    "Primero, creamos el dataset de oraciones etiquetadas según el autor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Carga el texto crudo a partir de un archivo de texto\n",
    "    \n",
    "    Args:\n",
    "    file_path (str): Ruta del archivo de texto.\n",
    "    \n",
    "    Returns:\n",
    "    str: Texto crudo.\n",
    "    \"\"\"\n",
    "    # Leer el texto crudo\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    return text\n",
    "\n",
    "def extract_sentences(book: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Extrae extractos de un libro asegurando que cumplan con ciertas condiciones de tamaño\n",
    "    \n",
    "    Args:\n",
    "    book (str): Texto crudo.\n",
    "    \n",
    "    Returns:\n",
    "    list[str]: Lista de extractos del libro.\n",
    "    \"\"\"\n",
    "    # Separar el texto en bloques usando líneas completamente vacías como delimitadores\n",
    "    lines = book.split('***')[2].split('\\n\\n')\n",
    "\n",
    "    # Eliminar espacios en blanco al inicio y al final de cada línea\n",
    "    lines = [line.strip() for line in lines]\n",
    "\n",
    "    # Eliminar lineas vacias y títulos no relevantes\n",
    "    lines = [line for line in lines if line and not line.startswith('CHAPTER') and not line.startswith('[Illustration]')]\n",
    "\n",
    "    # Eliminar saltos de líneas de las oraciones\n",
    "    lines = [line.replace('\\n', ' ') for line in lines]\n",
    "\n",
    "    # Usar word count para extraer las oraciones\n",
    "    sentences = []\n",
    "    for sentence in lines:\n",
    "        if len(sentence.split()) > 250:\n",
    "            sentences.extend(sent_tokenize(sentence))  # Dividir en oraciones si es demasiado largo\n",
    "        else:\n",
    "            sentences.append(sentence)\n",
    "\n",
    "    # Filtrar por oraciones que tienen entre 150 y 250 palabras\n",
    "    sentences = [sentence for sentence in sentences if 150 <= len(sentence.split()) <= 250]\n",
    "\n",
    "    # Eliminar espacios en blanco al inicio y al final de cada línea nuevamente\n",
    "    sentences = [sentence.strip() for sentence in sentences]\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta a los libros originales junto con su autor\n",
    "raw_books = {\n",
    "    'austen_sense-and-sensibility': {\n",
    "        'file_path': 'data/raw/austen_sense-and-sensibility.txt',\n",
    "        'author': 'Jane Austen',\n",
    "    },\n",
    "    'austen_pride-and-prejudice': {\n",
    "        'file_path': 'data/raw/austen_pride-and-prejudice.txt',\n",
    "        'author': 'Jane Austen',\n",
    "    },\n",
    "    'austen_emma': {\n",
    "        'file_path': 'data/raw/austen_emma.txt',\n",
    "        'author': 'Jane Austen',\n",
    "    },\n",
    "    'tolstoy_youth': {\n",
    "        'file_path': 'data/raw/tolstoy_youth.txt',\n",
    "        'author': 'Leo Tolstoy',\n",
    "    },\n",
    "    'tolstoy_war-and-peace': {\n",
    "        'file_path': 'data/raw/tolstoy_war-and-peace.txt',\n",
    "        'author': 'Leo Tolstoy',\n",
    "    },\n",
    "    'tolstoy_anna-karenina': {\n",
    "        'file_path': 'data/raw/tolstoy_anna-karenina.txt',\n",
    "        'author': 'Leo Tolstoy',\n",
    "    },\n",
    "    'joyce_dubliners': {\n",
    "        'file_path': 'data/raw/joyce_dubliners.txt',\n",
    "        'author': 'James Joyce',\n",
    "    },\n",
    "    'joyce_a-portrait-of-the-artist-as-a-young-man': {\n",
    "        'file_path': 'data/raw/joyce_a-portrait-of-the-artist-as-a-young-man.txt',\n",
    "        'author': 'James Joyce',\n",
    "    },\n",
    "    'joyce_ulysses': {\n",
    "        'file_path': 'data/raw/joyce_ulysses.txt',\n",
    "        'author': 'James Joyce',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>The family of Dashwood had long been settled i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>The old gentleman died: his will was read, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>No sooner was his father’s funeral over, than ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>“Certainly not; but if you observe, people alw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>Edward Ferrars was not recommended to their go...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author                                           sentence\n",
       "0  Jane Austen  The family of Dashwood had long been settled i...\n",
       "1  Jane Austen  The old gentleman died: his will was read, and...\n",
       "2  Jane Austen  No sooner was his father’s funeral over, than ...\n",
       "3  Jane Austen  “Certainly not; but if you observe, people alw...\n",
       "4  Jane Austen  Edward Ferrars was not recommended to their go..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear dataframe con las oraciones extraídas de los libros\n",
    "df = pd.DataFrame(columns=['author', 'sentence'])\n",
    "\n",
    "# Extraer oraciones para cada libro y concatenarlas en el dataframe\n",
    "for book in raw_books.values():\n",
    "    corpus = load_raw_data(book['file_path'])\n",
    "    author = book['author']\n",
    "    \n",
    "    # Extraer oraciones\n",
    "    sentences = extract_sentences(corpus)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame({'author': author, 'sentence': sentences})], ignore_index=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar dataset como archivo CSV\n",
    "df.to_csv('data/classifier/sentences.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>num_training_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leo Tolstoy</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>James Joyce</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author  num_training_data\n",
       "0  Leo Tolstoy                866\n",
       "1  Jane Austen                426\n",
       "2  James Joyce                321"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contar el número de datos por autor\n",
    "author_counts = df['author'].value_counts()\n",
    "\n",
    "# Crear DataFrame resumen\n",
    "summary_df = author_counts.reset_index()\n",
    "summary_df.columns = ['author', 'num_training_data']\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocesamiento del Dataset\n",
    "\n",
    "Preprocesamos el dataset separandolo en entrenamiento y prueba. Adicionalmente, tokenizamos el texto para poder mapear las palabras a los embeddings construidos y usarlos como la capa de entrada de los modelos de redes neuronales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en conjunto de entrenamiento, validación y prueba\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(df['sentence'], df['author'], train_size=0.7, random_state=42)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, train_size=0.5, random_state=42)\n",
    "\n",
    "# Tokenización usando Keras\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "# Convertir el texto en secuencias de enteros\n",
    "x_train_seq = tokenizer.texts_to_sequences(x_train)\n",
    "x_val_seq = tokenizer.texts_to_sequences(x_val)\n",
    "x_test_seq = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "# Rellenar las secuencias para que tengan la misma longitud\n",
    "max_length = max([len(seq) for seq in x_train_seq])\n",
    "x_train_pad = pad_sequences(x_train_seq, maxlen=max_length, padding='post')\n",
    "x_val_pad = pad_sequences(x_val_seq, maxlen=max_length, padding='post')\n",
    "x_test_pad = pad_sequences(x_test_seq, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Definición de los Modelos de Redes Neuronales\n",
    "\n",
    "Cargamos los los embeddings de Word2Vec pre-entrenados, creamos las capas de embeddings a partir de ellos, y definimos los tres tipos de arquitecturas de redes neuronales que usaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta a los modelos Word2Vec combinados con diferentes tamaños de vectores\n",
    "books_models = [\n",
    "    'data/models/Books_50_CarlosRaulDeLaRosaPeredoJhonStewarRayoMosqueraMarioGarridoCordoba.model',\n",
    "    'data/models/Books_100_CarlosRaulDeLaRosaPeredoJhonStewarRayoMosqueraMarioGarridoCordoba.model',\n",
    "    'data/models/Books_300_CarlosRaulDeLaRosaPeredoJhonStewarRayoMosqueraMarioGarridoCordoba.model'\n",
    "]\n",
    "\n",
    "# Cargar los embeddings de Word2Vec pre-entrenados\n",
    "word2vec_model_50 = gensim.models.Word2Vec.load(books_models[0])\n",
    "word2vec_model_100 = gensim.models.Word2Vec.load(books_models[1])\n",
    "word2vec_model_300 = gensim.models.Word2Vec.load(books_models[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_layer(word2vec_model, tokenizer, max_length):\n",
    "    \"\"\"\n",
    "    Crea una capa de embeddings a partir de un modelo Word2Vec y un tokenizer.\n",
    "\n",
    "    Args:\n",
    "    word2vec_model: Modelo Word2Vec preentrenado.\n",
    "    tokenizer: Tokenizer que contiene el índice de palabras.\n",
    "    max_length (int): Longitud máxima de las secuencias de entrada.\n",
    "\n",
    "    Returns:\n",
    "    Embedding: Capa de embedding de Keras que utiliza la matriz de embeddings generada.\n",
    "    \"\"\"\n",
    "    # Crear la matriz de embeddings para el modelo Word2Vec\n",
    "    embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, word2vec_model.vector_size))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if word in word2vec_model.wv:\n",
    "            embedding_matrix[i] = word2vec_model.wv[word]\n",
    "\n",
    "    # Definir la capa de embedding en Keras\n",
    "    embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1,\n",
    "                                output_dim=word2vec_model.vector_size,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=max_length,\n",
    "                                trainable=False)\n",
    "    \n",
    "    return embedding_layer\n",
    "\n",
    "# Crear las capas de embeddings a partir de los modelos Word2Vec\n",
    "embedding_layer_50 = create_embedding_layer(word2vec_model_50, tokenizer, max_length)\n",
    "embedding_layer_100 = create_embedding_layer(word2vec_model_100, tokenizer, max_length)\n",
    "embedding_layer_300 = create_embedding_layer(word2vec_model_300, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitectura 1: Modelo sencillo\n",
    "def create_ffnn_model_1(embedding_layer):\n",
    "    \"\"\"\n",
    "    Crea un modelo de red neuronal feedforward simple.\n",
    "\n",
    "    Args:\n",
    "    embedding_layer: Capa de embeddings de Keras utilizada como entrada.\n",
    "\n",
    "    Returns:\n",
    "    Sequential: Modelo de red neuronal compilado.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))  # Salida con 3 clases (autores)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Arquitectura 2: Modelo con más capas\n",
    "def create_ffnn_model_2(embedding_layer):\n",
    "    \"\"\"\n",
    "    Crea un modelo de red neuronal feedforward con más capas.\n",
    "\n",
    "    Args:\n",
    "    embedding_layer: Capa de embeddings de Keras utilizada como entrada.\n",
    "\n",
    "    Returns:\n",
    "    Sequential: Modelo de red neuronal compilado.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Arquitectura 3: Modelo con más unidades\n",
    "def create_ffnn_model_3(embedding_layer):\n",
    "    \"\"\"\n",
    "    Crea un modelo de red neuronal feedforward con más unidades.\n",
    "\n",
    "    Args:\n",
    "    embedding_layer: Capa de embeddings de Keras utilizada como entrada.\n",
    "\n",
    "    Returns:\n",
    "    Sequential: Modelo de red neuronal compilado.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creación y Evaluación de los Modelos de Redes Neuronales\n",
    "\n",
    "Creamos un modelo con cada tipo de arquitectura y capa de embeddings y evaluamos su accuracy, precision y recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación de etiquetas (autores)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = to_categorical(label_encoder.fit_transform(y_train))\n",
    "y_val_encoded = to_categorical(label_encoder.transform(y_val))\n",
    "y_test_encoded = to_categorical(label_encoder.transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test_pad, y_test_encoded):\n",
    "    \"\"\"\n",
    "    Evalúa el rendimiento de un modelo entrenado calculando accuracy, precision y recall.\n",
    "    \n",
    "    Args:\n",
    "    model (keras.models.Model): El modelo entrenado.\n",
    "    x_test_pad (numpy.ndarray): Conjunto de datos de prueba preprocesados y tokenizados.\n",
    "    y_test_encoded (numpy.ndarray): Etiquetas de prueba codificadas en formato one-hot.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Un tupla que contiene:\n",
    "        - accuracy (float): La proporción de predicciones correctas.\n",
    "        - precision (float): La proporción de predicciones positivas correctas (precisión macro).\n",
    "        - recall (float): La proporción de verdaderos positivos detectados (recall macro).\n",
    "    \"\"\"\n",
    "    # Obtener predicciones del modelo\n",
    "    y_pred = model.predict(x_test_pad)\n",
    "    \n",
    "    # Convertir las predicciones y etiquetas de one-hot a clases\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test_encoded, axis=1)\n",
    "    \n",
    "    # Calcular accuracy\n",
    "    accuracy = np.mean(y_pred_classes == y_test_classes)\n",
    "    \n",
    "    # Calcular precisión y recall usando la métrica macro (promedio entre todas las clases)\n",
    "    precision = precision_score(y_test_classes, y_pred_classes, average='macro')\n",
    "    recall = recall_score(y_test_classes, y_pred_classes, average='macro')\n",
    "    \n",
    "    return accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando Modelo 1 con 50 dimensiones...\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 254, 50)           851050    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12700)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1625728   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,477,165\n",
      "Trainable params: 1,626,115\n",
      "Non-trainable params: 851,050\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.6705 - accuracy: 0.7192 - val_loss: 0.4193 - val_accuracy: 0.8430\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0941 - accuracy: 0.9787 - val_loss: 0.4039 - val_accuracy: 0.8223\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.3867 - val_accuracy: 0.8388\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4000 - val_accuracy: 0.8430\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4065 - val_accuracy: 0.8430\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4134 - val_accuracy: 0.8347\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4135 - val_accuracy: 0.8430\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4207 - val_accuracy: 0.8347\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4203 - val_accuracy: 0.8430\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4288 - val_accuracy: 0.8347\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "\n",
      "Evaluación del Modelo 1 con embeddings de 50 dimensiones - Accuracy: 0.9132231404958677, Precision: 0.9114367556158601, Recall: 0.8715618314077878 \n",
      "\n",
      "\n",
      "Entrenando Modelo 2 con 50 dimensiones...\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 254, 50)           851050    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 12700)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               3251456   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,135,789\n",
      "Trainable params: 3,284,739\n",
      "Non-trainable params: 851,050\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 2s 20ms/step - loss: 0.5311 - accuracy: 0.7865 - val_loss: 0.4049 - val_accuracy: 0.8471\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0269 - accuracy: 0.9956 - val_loss: 0.4838 - val_accuracy: 0.8388\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4687 - val_accuracy: 0.8512\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 9.0326e-04 - accuracy: 1.0000 - val_loss: 0.4531 - val_accuracy: 0.8512\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 4.8036e-04 - accuracy: 1.0000 - val_loss: 0.4725 - val_accuracy: 0.8471\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 3.3182e-04 - accuracy: 1.0000 - val_loss: 0.4780 - val_accuracy: 0.8554\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 2.5750e-04 - accuracy: 1.0000 - val_loss: 0.4862 - val_accuracy: 0.8554\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 2.0672e-04 - accuracy: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.8554\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 1.6935e-04 - accuracy: 1.0000 - val_loss: 0.4967 - val_accuracy: 0.8554\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 1.4231e-04 - accuracy: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.8554\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "\n",
      "Evaluación del Modelo 2 con embeddings de 50 dimensiones - Accuracy: 0.9132231404958677, Precision: 0.9042957042957043, Recall: 0.8787445442875481 \n",
      "\n",
      "\n",
      "Entrenando Modelo 3 con 50 dimensiones...\n",
      "\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 254, 50)           851050    \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 12700)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               6502912   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,518,573\n",
      "Trainable params: 6,667,523\n",
      "Non-trainable params: 851,050\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 2s 33ms/step - loss: 0.5514 - accuracy: 0.7564 - val_loss: 0.5991 - val_accuracy: 0.7893\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 0.0422 - accuracy: 0.9849 - val_loss: 0.4392 - val_accuracy: 0.8719\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.7538 - val_accuracy: 0.8140\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.6064 - val_accuracy: 0.8554\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 0.0030 - accuracy: 0.9982 - val_loss: 0.6335 - val_accuracy: 0.8430\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 8.5275e-04 - accuracy: 1.0000 - val_loss: 0.7264 - val_accuracy: 0.8347\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 1.2539e-04 - accuracy: 1.0000 - val_loss: 0.7664 - val_accuracy: 0.8223\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 8.0636e-05 - accuracy: 1.0000 - val_loss: 0.7775 - val_accuracy: 0.8223\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 5.6417e-05 - accuracy: 1.0000 - val_loss: 0.7922 - val_accuracy: 0.8264\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 4.3097e-05 - accuracy: 1.0000 - val_loss: 0.8067 - val_accuracy: 0.8264\n",
      "8/8 [==============================] - 0s 6ms/step\n",
      "\n",
      "Evaluación del Modelo 3 con embeddings de 50 dimensiones - Accuracy: 0.8884297520661157, Precision: 0.871486444005528, Recall: 0.8426101839965768 \n",
      "\n",
      "\n",
      "Entrenando Modelo 1 con 100 dimensiones...\n",
      "\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 254, 100)          1702100   \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 25400)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               3251328   \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,953,815\n",
      "Trainable params: 3,251,715\n",
      "Non-trainable params: 1,702,100\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 2s 23ms/step - loss: 0.5331 - accuracy: 0.7724 - val_loss: 0.3350 - val_accuracy: 0.8554\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0225 - accuracy: 0.9991 - val_loss: 0.3263 - val_accuracy: 0.8760\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.3464 - val_accuracy: 0.8554\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3560 - val_accuracy: 0.8595\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.8636\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3659 - val_accuracy: 0.8636\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 8.4205e-04 - accuracy: 1.0000 - val_loss: 0.3719 - val_accuracy: 0.8636\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 6.5161e-04 - accuracy: 1.0000 - val_loss: 0.3777 - val_accuracy: 0.8636\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 5.1101e-04 - accuracy: 1.0000 - val_loss: 0.3813 - val_accuracy: 0.8636\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.0729e-04 - accuracy: 1.0000 - val_loss: 0.3836 - val_accuracy: 0.8595\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "\n",
      "Evaluación del Modelo 1 con embeddings de 100 dimensiones - Accuracy: 0.9090909090909091, Precision: 0.8880199192699193, Recall: 0.8740530594779631 \n",
      "\n",
      "\n",
      "Entrenando Modelo 2 con 100 dimensiones...\n",
      "\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 254, 100)          1702100   \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 25400)             0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 256)               6502656   \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,238,039\n",
      "Trainable params: 6,535,939\n",
      "Non-trainable params: 1,702,100\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 2s 33ms/step - loss: 0.5527 - accuracy: 0.7697 - val_loss: 0.3316 - val_accuracy: 0.8843\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.0209 - accuracy: 0.9956 - val_loss: 0.3887 - val_accuracy: 0.8512\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3893 - val_accuracy: 0.8760\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 5.1804e-04 - accuracy: 1.0000 - val_loss: 0.4032 - val_accuracy: 0.8802\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 3.1585e-04 - accuracy: 1.0000 - val_loss: 0.4131 - val_accuracy: 0.8802\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 2.2772e-04 - accuracy: 1.0000 - val_loss: 0.4207 - val_accuracy: 0.8802\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 1.7321e-04 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.8802\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 1.3673e-04 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.8802\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 1.0992e-04 - accuracy: 1.0000 - val_loss: 0.4420 - val_accuracy: 0.8843\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 9.1017e-05 - accuracy: 1.0000 - val_loss: 0.4478 - val_accuracy: 0.8843\n",
      "8/8 [==============================] - 0s 7ms/step\n",
      "\n",
      "Evaluación del Modelo 2 con embeddings de 100 dimensiones - Accuracy: 0.9008264462809917, Precision: 0.8923664665543507, Recall: 0.8580984167736414 \n",
      "\n",
      "\n",
      "Entrenando Modelo 3 con 100 dimensiones...\n",
      "\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 254, 100)          1702100   \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 25400)             0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 512)               13005312  \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,872,023\n",
      "Trainable params: 13,169,923\n",
      "Non-trainable params: 1,702,100\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 3s 49ms/step - loss: 0.5539 - accuracy: 0.7635 - val_loss: 0.3863 - val_accuracy: 0.8430\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 0.0222 - accuracy: 0.9956 - val_loss: 0.5225 - val_accuracy: 0.8264\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 2s 47ms/step - loss: 0.0066 - accuracy: 0.9973 - val_loss: 0.8369 - val_accuracy: 0.8264\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 2s 47ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6247 - val_accuracy: 0.8471\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 6.2756e-04 - accuracy: 1.0000 - val_loss: 0.6126 - val_accuracy: 0.8512\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 2s 47ms/step - loss: 2.8969e-04 - accuracy: 1.0000 - val_loss: 0.6331 - val_accuracy: 0.8595\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 2s 48ms/step - loss: 5.4231e-05 - accuracy: 1.0000 - val_loss: 0.6429 - val_accuracy: 0.8430\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 2s 48ms/step - loss: 3.7839e-05 - accuracy: 1.0000 - val_loss: 0.6532 - val_accuracy: 0.8388\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 2s 50ms/step - loss: 2.9764e-05 - accuracy: 1.0000 - val_loss: 0.6617 - val_accuracy: 0.8430\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 2s 48ms/step - loss: 2.4534e-05 - accuracy: 1.0000 - val_loss: 0.6695 - val_accuracy: 0.8471\n",
      "8/8 [==============================] - 0s 9ms/step\n",
      "\n",
      "Evaluación del Modelo 3 con embeddings de 100 dimensiones - Accuracy: 0.8884297520661157, Precision: 0.8652125768569513, Recall: 0.8552563115104835 \n",
      "\n",
      "\n",
      "Entrenando Modelo 1 con 300 dimensiones...\n",
      "\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 254, 300)          5106300   \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 76200)             0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               9753728   \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,860,415\n",
      "Trainable params: 9,754,115\n",
      "Non-trainable params: 5,106,300\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.5631 - accuracy: 0.7476 - val_loss: 0.3798 - val_accuracy: 0.8388\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 0.0158 - accuracy: 0.9982 - val_loss: 0.3868 - val_accuracy: 0.8554\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.4699 - val_accuracy: 0.8347\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4157 - val_accuracy: 0.8554\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4209 - val_accuracy: 0.8512\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 7.4636e-04 - accuracy: 1.0000 - val_loss: 0.4222 - val_accuracy: 0.8554\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 5.9826e-04 - accuracy: 1.0000 - val_loss: 0.4234 - val_accuracy: 0.8512\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 4.9487e-04 - accuracy: 1.0000 - val_loss: 0.4244 - val_accuracy: 0.8554\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 4.1792e-04 - accuracy: 1.0000 - val_loss: 0.4262 - val_accuracy: 0.8512\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 3.5960e-04 - accuracy: 1.0000 - val_loss: 0.4282 - val_accuracy: 0.8471\n",
      "8/8 [==============================] - 0s 10ms/step\n",
      "\n",
      "Evaluación del Modelo 1 con embeddings de 300 dimensiones - Accuracy: 0.8884297520661157, Precision: 0.8814359814359815, Recall: 0.842915703893881 \n",
      "\n",
      "\n",
      "Entrenando Modelo 2 con 300 dimensiones...\n",
      "\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 254, 300)          5106300   \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 76200)             0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 256)               19507456  \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,647,039\n",
      "Trainable params: 19,540,739\n",
      "Non-trainable params: 5,106,300\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 4s 77ms/step - loss: 0.5529 - accuracy: 0.7857 - val_loss: 0.3519 - val_accuracy: 0.8595\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 3s 71ms/step - loss: 0.0227 - accuracy: 0.9956 - val_loss: 0.5703 - val_accuracy: 0.8347\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 3s 73ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.8471\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 3s 71ms/step - loss: 5.8515e-04 - accuracy: 1.0000 - val_loss: 0.4712 - val_accuracy: 0.8595\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 2.9928e-04 - accuracy: 1.0000 - val_loss: 0.4757 - val_accuracy: 0.8347\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 3s 73ms/step - loss: 1.8038e-04 - accuracy: 1.0000 - val_loss: 0.4893 - val_accuracy: 0.8306\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 2s 69ms/step - loss: 1.2083e-04 - accuracy: 1.0000 - val_loss: 0.5043 - val_accuracy: 0.8306\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 3s 72ms/step - loss: 8.5639e-05 - accuracy: 1.0000 - val_loss: 0.5165 - val_accuracy: 0.8347\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 6.4305e-05 - accuracy: 1.0000 - val_loss: 0.5257 - val_accuracy: 0.8306\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 5.0816e-05 - accuracy: 1.0000 - val_loss: 0.5302 - val_accuracy: 0.8264\n",
      "8/8 [==============================] - 0s 16ms/step\n",
      "\n",
      "Evaluación del Modelo 2 con embeddings de 300 dimensiones - Accuracy: 0.8966942148760331, Precision: 0.8801198801198802, Recall: 0.8571510483525887 \n",
      "\n",
      "\n",
      "Entrenando Modelo 3 con 300 dimensiones...\n",
      "\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 254, 300)          5106300   \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 76200)             0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 512)               39014912  \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,285,823\n",
      "Trainable params: 39,179,523\n",
      "Non-trainable params: 5,106,300\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 6s 145ms/step - loss: 0.5743 - accuracy: 0.7387 - val_loss: 0.4196 - val_accuracy: 0.8182\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 5s 128ms/step - loss: 0.0292 - accuracy: 0.9911 - val_loss: 0.4551 - val_accuracy: 0.8512\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 5s 126ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.5995 - val_accuracy: 0.8182\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 5s 129ms/step - loss: 5.8249e-04 - accuracy: 1.0000 - val_loss: 0.6240 - val_accuracy: 0.8430\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 5s 134ms/step - loss: 1.4247e-04 - accuracy: 1.0000 - val_loss: 0.6489 - val_accuracy: 0.8471\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 5s 132ms/step - loss: 6.2022e-05 - accuracy: 1.0000 - val_loss: 0.6668 - val_accuracy: 0.8430\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 4s 120ms/step - loss: 4.4715e-05 - accuracy: 1.0000 - val_loss: 0.6802 - val_accuracy: 0.8430\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 4s 111ms/step - loss: 3.4589e-05 - accuracy: 1.0000 - val_loss: 0.6939 - val_accuracy: 0.8430\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 4s 109ms/step - loss: 2.7242e-05 - accuracy: 1.0000 - val_loss: 0.7073 - val_accuracy: 0.8430\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 4s 111ms/step - loss: 2.1814e-05 - accuracy: 1.0000 - val_loss: 0.7190 - val_accuracy: 0.8430\n",
      "8/8 [==============================] - 0s 19ms/step\n",
      "\n",
      "Evaluación del Modelo 3 con embeddings de 300 dimensiones - Accuracy: 0.8760330578512396, Precision: 0.8611312564800938, Recall: 0.8495866495507061 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterar sobre las capas de embeddings y las dimensiones de los modelos Word2Vec (50, 100, 300 dimensiones)\n",
    "for embedding_layer, dimensions in [(embedding_layer_50, 50), (embedding_layer_100, 100), (embedding_layer_300, 300)]:\n",
    "    \n",
    "    # Iterar sobre las funciones de creación de modelos FFNN (modelos 1, 2 y 3)\n",
    "    for i, model_fn in enumerate([create_ffnn_model_1, create_ffnn_model_2, create_ffnn_model_3], 1):\n",
    "        \n",
    "        # Crear el modelo usando la capa de embeddings actual\n",
    "        print(f\"\\nEntrenando Modelo {i} con {dimensions} dimensiones...\" \"\\n\")\n",
    "        model = model_fn(embedding_layer)\n",
    "        \n",
    "        # Mostrar el resumen del modelo (capas y dimensiones)\n",
    "        model.summary()\n",
    "\n",
    "        # Entrenar el modelo con el conjunto de datos de entrenamiento y validar con el conjunto de validación\n",
    "        history = model.fit(x_train_pad, y_train_encoded, \n",
    "                            epochs=10, batch_size=32, \n",
    "                            validation_data=(x_val_pad, y_val_encoded), \n",
    "                            verbose=1)\n",
    "        \n",
    "        # Evaluar el modelo en el conjunto de prueba\n",
    "        accuracy, precision, recall = evaluate_model(model, x_test_pad, y_test_encoded)\n",
    "\n",
    "        # Mostrar los resultados finales de la evaluación (accuracy, precision y recall)\n",
    "        print(f\"\\nEvaluación del Modelo {i} con embeddings de {dimensions} dimensiones - Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\", \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
