\documentclass[11pt,english]{article}

\usepackage{graphicx} % Required for inserting images
\usepackage[margin=2cm,top=2cm,headheight=16pt,headsep=0.2in,heightrounded]{geometry}
\usepackage{fancyhdr} % Required for inserting and customizing page header
    \pagestyle{fancy} % Required for changing page style
\usepackage{amsmath}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{hyperref}
\usepackage[
backend=biber,
style=ieee,
]{biblatex}
\usepackage{caption}

\usepackage{tikz}
\usepackage{booktabs}
\usetikzlibrary{arrows}
\usetikzlibrary{tikzmark}
\usetikzlibrary{trees}

\usepackage{tabularx}
\usepackage{lscape}
\newcolumntype{b}{>{\hsize=2.80\hsize}X}
\newcolumntype{s}{>{\hsize=.4\hsize}X}


\usepackage{enumitem}
\usepackage{longtable}

\captionsetup[table]{name=Tabla}
\captionsetup[figure]{name=Figura}

\usepackage{amsthm}
\theoremstyle{plain}

\newtheorem*{definition*}{Definition}
\newtheorem{definition}{Definition}

\fancyhead{}
\fancyfoot{}

\fancyhead[L]{Tarea 2: Procesamiento de Lenguaje Natural}
\fancyfoot[L]{\thepage}

\addbibresource{biblio.bib} %Imports bibliography file

\renewcommand{\labelitemi}{{\tiny$\bullet$}}

\renewcommand*{\bibfont}{\normalfont\small}

\title{Procesamiento de Lenguaje Natural\\
Tarea 2
}
\author{
  Rayo Mosquera, Jhon Stewar\\
  \texttt{j.rayom@uniandes.edu.co}
  \and
  De La Rosa Peredo, Carlos Raul\\
  \texttt{c.delarosap@uniandes.edu.co}\and
  Mario Garrido Córdoba\\
   \texttt{m.garrido10@uniandes.edu.co}
  \\ 
}
\date{Septiembre 2024}

\begin{document}

\maketitle

\section{Introducción}

El objetivo de esta tarea es construir y evaluar modelos de N-Gramas utilizando los siguientes dos conjuntos de datos.

\begin{itemize}
    \item \textbf{20 Newsgroups (20N)}: Una colección de aproximadamente 18,800 documentos de grupos de noticias, categorizados en diferentes temas.
    \item \textbf{Blog Authorship Corpus (BAC)}: Una colección de publicaciones de blog de más de 19,300 autores.
\end{itemize}

\noindent Estos conjuntos de datos se utilizan para construir modelos de unigramas, bigramas y trigramas, que se evalúan utilizando la métrica de perplejidad y se emplean para generar oraciones.

\section{Implementación}

\subsection{Preprocesamiento de Datos}

El primer paso fue leer y combinar los documentos de los conjuntos de datos 20N y BAC. Los documentos se concatenaron en dos archivos grandes: uno para 20N y otro para BAC.\\

\noindent Para cada conjunto de datos, se implementaron los siguientes pasos de preprocesamiento.

\begin{itemize}
    \item \textbf{Tokenización por Oraciones}: Utilizamos la función \texttt{nltk.sent\_tokenize()} para dividir el texto en oraciones individuales. Cada oración se envolvió con etiquetas de inicio (``<s>'') y fin (``</s>'') para facilitar el entrenamiento de los modelos de N-Gramas.
    \item \textbf{Normalización}: Todos los números en el texto fueron reemplazados con el token ``NUM''. Los tokens con frecuencia unitaria se modelaron como ``<UNK>''.
\end{itemize}

\subsection{Construcción de Modelos de N-Gramas}

Después del preprocesamiento de los datos, cada conjunto de datos se dividió en dos conjuntos.

\begin{itemize}
    \item \textbf{80\% para entrenamiento}: Estas oraciones se utilizaron para construir los modelos de N-Gramas.
    \item \textbf{20\% para prueba}: Estas oraciones se reservaron para la evaluación de los modelos (i.e., el cálculo de su perplejidad).
\end{itemize}

\noindent Luego, construimos tres modelos de N-Gramas diferentes (unigramas, bigramas y trigramas) para cada conjunto de datos.

\begin{itemize}
    \item \textbf{Unigramas}: Representan palabras individuales como unidades independientes.
    \item \textbf{Bigramas}: Capturan pares de palabras para identificar el contexto inmediato de una palabra.
    \item \textbf{Trigramas}: Consideran una secuencia de tres palabras y pueden capturar dependencias más largas entre palabras.
\end{itemize}

Es crucial destacar que, debido a la enorme cantidad de datos, se precisó una estructura de datos capaz de almacenar y consultar la información eficazmente. Para ello, se emplearon diccionarios donde se guardaron los tokens junto con sus respectivas frecuencias, facilitando así el cálculo de probabilidades. Este método resulta significativamente más eficiente que el uso de matrices dispersas, ya que éstas, dado el tamaño del corpus, requerirían decenas de gigabytes de memoria.

\section{Resultados}

\subsection{Evaluación de la Perplejidad}

La perplejidad de los modelos de unigramas, bigramas y trigramas se calculó utilizando los conjuntos de prueba. La \textbf{perplejidad} mide qué tan bien un modelo probabilístico predice una muestra, con valores más bajos indicando mejores predicciones. Para manejar el desbordamiento durante los cálculos de perplejidad, se usaron probabilidades en espacio logarítmico aplicando \textbf{suavizado de Laplace} a cada modelo de N-Gramas.\\

\textbf{Resultados de Perplejidad para los Modelos de 20N:}
\begin{itemize}
    \item \textbf{Unigrama}: 1.0
    \item \textbf{Bigrama}: 4683.49
    \item \textbf{Trigrama}: 168769.46
\end{itemize}

\textbf{Resultados de Perplejidad para los Modelos de BAC:}
\begin{itemize}
    \item \textbf{Unigrama}: 1.0
    \item \textbf{Bigrama}: 1596.41
    \item \textbf{Trigrama}: 267404.24
\end{itemize}

\textbf{Observaciones}:
\begin{itemize}
    \item Los \textbf{modelos de unigrama} para ambos conjuntos de datos arrojaron una perplejidad de 1.0, lo que sugiere que el modelo había visto la mayoría de las palabras en el conjunto de prueba. Sin embargo, esto probablemente se deba a la alta prevalencia de palabras comunes y a la simplicidad del modelo de unigrama, que no captura dependencias entre palabras.
    \item Los \textbf{modelos de bigrama} tuvieron un aumento significativo en la perplejidad en comparación con los de unigrama, reflejando la dificultad del modelo para predecir pares de palabras, especialmente en el conjunto de datos 20N, que presenta combinaciones no vistas. Sin embargo, el modelo de bigrama de BAC mostró un mejor rendimiento debido a un estilo más consistente de lenguaje en las publicaciones de blogs.
    \item Los \textbf{modelos de trigramas} tuvieron la perplejidad más alta, lo que indica que los modelos tuvieron dificultades para predecir secuencias de tres palabras. Este resultado es esperado, ya que los modelos de trigrama requieren más datos de entrenamiento para capturar con precisión las dependencias largas entre palabras.
\end{itemize}

\subsection{Generación de Oraciones}

Después de la evaluación de los modelos, generamos oraciones utilizando los \textbf{modelos de bigrama}. La función toma una palabra inicial y genera una secuencia basada en las probabilidades aprendidas.\\

\textbf{Ejemplos de Oraciones Generadas (Modelo de 20N)}:
\begin{itemize}
    \item \textbf{Palabra inicial ``<s>''}: ``<s> i have a <UNK> <UNK> <UNK>...''
\end{itemize}

\textbf{Ejemplos de Oraciones Generadas (Modelo de BAC)}:
\begin{itemize}
    \item \textbf{Palabra inicial ``book''}: ``book and i was a little bit of the same time''
    \item \textbf{Palabra inicial ``tonight''}: ``tonight i was a little bit of the same time to''
\end{itemize}

\textbf{Observaciones}:
\begin{itemize}
    \item Las oraciones generadas por el \textbf{modelo de bigrama de 20N} tienden a ser repetitivas y frecuentemente contienen tokens desconocidos (``<UNK>''), lo cual es probablemente causado por la variedad de temas y la dispersión de los datos en el conjunto 20N.
    \item Las oraciones generadas por el \textbf{modelo de bigrama de BAC} son más coherentes y estructuradas, probablemente debido a un estilo de lenguaje más consistente en las publicaciones de blogs. Sin embargo, las oraciones aún carecen de contexto significativo y exhiben cierta repetición, como la frase ``a little bit of the same time''.
\end{itemize}

\section{Conclusión}

En esta tarea, implementamos y evaluamos con éxito modelos de N-Gramas utilizando los conjuntos de datos 20 Newsgroups (20N) y Blog Authorship Corpus (BAC). Los modelos variaron desde simples unigramas hasta bigramas y trigramas más complejos.\\

\textbf{Principales conclusiones}:
\begin{itemize}
    \item Los \textbf{modelos de unigramas} tuvieron la perplejidad más baja, pero no capturaron relaciones significativas entre palabras.
    \item Los \textbf{modelos de bigramas} mostraron un rendimiento intermedio, con un aumento en la perplejidad debido a la dificultad de predecir pares de palabras.
    \item Los \textbf{modelos de trigramas} presentaron la mayor dificultad para predecir secuencias largas, reflejada en su alta perplejidad.
\end{itemize}

\noindent En conclusión, aunque los modelos de N-Gramas son efectivos para la generación y predicción básica de texto, su rendimiento depende en gran medida del tamaño y la consistencia del conjunto de datos. La tarea destacó las limitaciones de estos modelos, particularmente para capturar dependencias a largo plazo y manejar la dispersión de datos. El trabajo futuro podría involucrar la exploración de técnicas de modelado del lenguaje más avanzadas, como redes neuronales o modelos basados en transformadores, para superar estas limitaciones y mejorar tanto la perplejidad como la calidad de la generación de oraciones. \\

\noindent Los archivos adjuntos representan los modelos conseguidos. Se excluye el modelo de trigramas para el conjunto BAC pues pesa cerca de 1GB y tuvimos dificultad para subir el archivo, este se puede generar ejecutando ambos notebooks. Tambien se puede referenciar el siguiente repositorio de Github: https://github.com/oyar99/nlp/tree/main/HW02

\end{document}
