{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'aux_functions.n_grams' from '/home/raul/Escritorio/extra/misis/nlp/nlp/HW02/aux_functions/n_grams.py'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pandas import DataFrame, Series\n",
    "import re\n",
    "import numpy as np\n",
    "from random import random\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import chain\n",
    "\n",
    "from aux_functions import read_process_file\n",
    "from aux_functions import n_grams\n",
    "from aux_functions import clean_text\n",
    "\n",
    "from importlib import import_module\n",
    "import_module('aux_functions')\n",
    "import_module('aux_functions.read_process_file')\n",
    "import_module('aux_functions.n_grams')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18828"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_20n = glob('./raw_data/20news-18828/*/*')\n",
    "len(files_20n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18828 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18828/18828 [00:07<00:00, 2378.29it/s]\n"
     ]
    }
   ],
   "source": [
    "df_news_rows = []\n",
    "for f in tqdm(files_20n):\n",
    "    txt = read_process_file.read_file(f)\n",
    "    txt_cln = read_process_file.clean_text(txt)\n",
    "    \n",
    "    # Dividir el texto en oraciones y limpiar oraciones cortas\n",
    "    sentences = [f'<s> {s.strip()} </s>' for s in re.split(r'\\.\\s*', txt_cln) if len(s.strip().split()) > 1]\n",
    "    \n",
    "    # Crear filas de DataFrame\n",
    "    df_news_rows.extend([{\n",
    "        'text': s,\n",
    "        'source': f,\n",
    "        'length': len(s.split())\n",
    "    } for s in sentences])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt; nick pettefar bmw battery &lt;/s&gt;</td>\n",
       "      <td>./raw_data/20news-18828/rec.motorcycles/104315</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt; keith hanlan on the wed NUM apr NUM NUM &lt;/s&gt;</td>\n",
       "      <td>./raw_data/20news-18828/rec.motorcycles/104315</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;s&gt; NUM gmt wibbled &lt;/s&gt;</td>\n",
       "      <td>./raw_data/20news-18828/rec.motorcycles/104315</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;s&gt; in article craig a &lt;/s&gt;</td>\n",
       "      <td>./raw_data/20news-18828/rec.motorcycles/104315</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;s&gt; vechorik writes &lt;/s&gt;</td>\n",
       "      <td>./raw_data/20news-18828/rec.motorcycles/104315</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405879</th>\n",
       "      <td>&lt;s&gt; janet reno and the fbi have the murder of ...</td>\n",
       "      <td>./raw_data/20news-18828/talk.politics.guns/54348</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405880</th>\n",
       "      <td>&lt;s&gt; hope they can sleep at night &lt;/s&gt;</td>\n",
       "      <td>./raw_data/20news-18828/talk.politics.guns/54348</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405881</th>\n",
       "      <td>&lt;s&gt; vasilion kb2nmv suny buffalo std &lt;/s&gt;</td>\n",
       "      <td>./raw_data/20news-18828/talk.politics.guns/54348</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405882</th>\n",
       "      <td>&lt;s&gt; all you cult haters happy now &lt;/s&gt;</td>\n",
       "      <td>./raw_data/20news-18828/talk.politics.guns/54348</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405883</th>\n",
       "      <td>&lt;s&gt; just hope that your not next &lt;/s&gt;</td>\n",
       "      <td>./raw_data/20news-18828/talk.politics.guns/54348</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>405884 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "0                      <s> nick pettefar bmw battery </s>   \n",
       "1        <s> keith hanlan on the wed NUM apr NUM NUM </s>   \n",
       "2                                <s> NUM gmt wibbled </s>   \n",
       "3                             <s> in article craig a </s>   \n",
       "4                                <s> vechorik writes </s>   \n",
       "...                                                   ...   \n",
       "405879  <s> janet reno and the fbi have the murder of ...   \n",
       "405880              <s> hope they can sleep at night </s>   \n",
       "405881          <s> vasilion kb2nmv suny buffalo std </s>   \n",
       "405882             <s> all you cult haters happy now </s>   \n",
       "405883              <s> just hope that your not next </s>   \n",
       "\n",
       "                                                  source  length  \n",
       "0         ./raw_data/20news-18828/rec.motorcycles/104315       6  \n",
       "1         ./raw_data/20news-18828/rec.motorcycles/104315      11  \n",
       "2         ./raw_data/20news-18828/rec.motorcycles/104315       5  \n",
       "3         ./raw_data/20news-18828/rec.motorcycles/104315       6  \n",
       "4         ./raw_data/20news-18828/rec.motorcycles/104315       4  \n",
       "...                                                  ...     ...  \n",
       "405879  ./raw_data/20news-18828/talk.politics.guns/54348      17  \n",
       "405880  ./raw_data/20news-18828/talk.politics.guns/54348       8  \n",
       "405881  ./raw_data/20news-18828/talk.politics.guns/54348       7  \n",
       "405882  ./raw_data/20news-18828/talk.politics.guns/54348       8  \n",
       "405883  ./raw_data/20news-18828/talk.politics.guns/54348       8  \n",
       "\n",
       "[405884 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news = DataFrame(df_news_rows)\n",
    "df_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news.to_parquet('./data/20news.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train - Test Split (20N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra del 80% de los datos para entrenar\n",
    "df_news_train = df_news.sample(frac=0.8, random_state=42)\n",
    "# el resto para evaluar\n",
    "df_news_test = df_news.drop(df_news_train.index)\n",
    "\n",
    "df_news_train.to_parquet('./data/train_test/20news_train.parquet', index=False)\n",
    "df_news_test.to_parquet('./data/train_test/20news_test.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Gram model and prob inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "ngram_counts, final_unigram = n_grams.create_ngram_model(n_gram=n,\n",
    "                                                         text_corpus=df_news_train.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0002865013194831411,\n",
       " 0.0007686257686257686,\n",
       " 1.7924359204158452e-05,\n",
       " 7.138013490845498e-05,\n",
       " 0.0009812142079817317]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Con este proceso, practicamnte ya esta servido el calculo de la perplejidad\n",
    "[n_grams.estimate_probability(token_text=i, n_gram=n, \n",
    "                              final_unigram=final_unigram, \n",
    "                              ngram_counts=ngram_counts) for i in n_grams.create_ngrams(sentence=df_news.text.iloc[0],n=n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<s>', 'uk')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar texto\n",
    "n_gram_probs = {k: n_grams.estimate_probability(token_text=k,\n",
    "                             n_gram=n,\n",
    "                             final_unigram=final_unigram,\n",
    "                             ngram_counts=ngram_counts\n",
    "                             ) for k in ngram_counts.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'same',\n",
       " 'thing',\n",
       " 'as',\n",
       " 'a',\n",
       " 'new',\n",
       " 'york',\n",
       " 'islanders',\n",
       " 'and',\n",
       " 'the',\n",
       " 'same',\n",
       " 'thing',\n",
       " 'about',\n",
       " 'the',\n",
       " 'same',\n",
       " 'thing',\n",
       " 'then',\n",
       " 'the',\n",
       " 'same',\n",
       " 'thing']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sentences \n",
    "\n",
    "sentence_length = 20\n",
    "initial_token = '<s>'\n",
    "sentence = []\n",
    "for _ in range(sentence_length):\n",
    "    next_token = [(k,i) for k,i in n_gram_probs.items() if k[0]==initial_token]\n",
    "    next_token = sorted(next_token, key= lambda x: x[1], reverse=True)\n",
    "    token = next_token[0][0][1]\n",
    "    i = 0\n",
    "    # FIXME: <UNK> is not in the vocab. In the vocab is (<UNK>,)\n",
    "    while token in ['NUM','<UNK>','</s>']: \n",
    "        token = next_token[i][0][1]\n",
    "        i += 1\n",
    "        if random()<.8:\n",
    "            token='NUM'\n",
    "        \n",
    "    sentence.append(token)\n",
    "    \n",
    "    initial_token = token\n",
    "    \n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19320"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_bac = glob('./raw_data/blogs/*')\n",
    "len(files_bac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19320/19320 [01:38<00:00, 196.73it/s]\n"
     ]
    }
   ],
   "source": [
    "df_bac_rows = []\n",
    "for f in tqdm(files_bac):\n",
    "    df_bac_rows.extend(read_process_file.extract_and_process_text_from_xml(f))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt; only NUM days NUM hour NUM minutes and NUM...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt; cant wait &lt;/s&gt;</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;s&gt; and this time jeans gonna kick some ass &lt;/s&gt;</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;s&gt; poor lucy &lt;/s&gt;</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;s&gt; she always had a huge smile on her face bu...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9509671</th>\n",
       "      <td>&lt;s&gt; i can come off sweet and nice but i can be...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9509672</th>\n",
       "      <td>&lt;s&gt; soulfish stew is primarily for me but if o...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9509673</th>\n",
       "      <td>&lt;s&gt; i hope to make an interesting and readable...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9509674</th>\n",
       "      <td>&lt;s&gt; the college era drinking may have stopped ...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9509675</th>\n",
       "      <td>&lt;s&gt; wally bangs &lt;/s&gt;</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9509676 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  length\n",
       "0        <s> only NUM days NUM hour NUM minutes and NUM...      18\n",
       "1                                       <s> cant wait </s>       4\n",
       "2         <s> and this time jeans gonna kick some ass </s>      10\n",
       "3                                       <s> poor lucy </s>       4\n",
       "4        <s> she always had a huge smile on her face bu...      23\n",
       "...                                                    ...     ...\n",
       "9509671  <s> i can come off sweet and nice but i can be...      19\n",
       "9509672  <s> soulfish stew is primarily for me but if o...      18\n",
       "9509673  <s> i hope to make an interesting and readable...      11\n",
       "9509674  <s> the college era drinking may have stopped ...      15\n",
       "9509675                               <s> wally bangs </s>       4\n",
       "\n",
       "[9509676 rows x 2 columns]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bac = DataFrame(df_bac_rows)\n",
    "df_bac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bac.to_parquet('./data/bac.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train - Test Split (BAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 80% of the data\n",
    "df_bac_train = df_bac.sample(frac=0.8, random_state=42)\n",
    "# the rest of the data is for testing\n",
    "df_bac_test = df_bac.drop(df_bac_train.index)\n",
    "\n",
    "df_bac_train.to_parquet('./data/train_test/bac_train.parquet', index=False)\n",
    "df_bac_test.to_parquet('./data/train_test/bac_test.parquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
