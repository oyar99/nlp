{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b8afa2b-90f9-40ee-b1c7-9dcddefba398",
   "metadata": {},
   "source": [
    "# Tarea 2 – ISIS 4221, Notebook II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33740950-a73e-4aaa-91ac-0ee480a992b4",
   "metadata": {},
   "source": [
    "## Paso 0: Importación de Notebooks Necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6319db-79f0-4c01-9569-a47f7ca3a06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"Notebook I.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc636ae-4da0-4107-a3d1-8be464466306",
   "metadata": {},
   "source": [
    "## Paso 1: Definición de las Funciones Necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53e3286-1636-4c0a-bf3e-29050ce08a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity(test_set, ngram_counts, final_unigram, n_gram):\n",
    "    \"\"\"\n",
    "    Calcula la perplejidad de un conjunto de prueba usando el modelo de n-gramas.\n",
    "\n",
    "    La perplejidad es una métrica que evalúa qué tan bien el modelo predice el texto de prueba. \n",
    "    Valores más bajos de perplejidad indican mejores predicciones.\n",
    "\n",
    "    Args:\n",
    "        test_set (list): El conjunto de oraciones de prueba.\n",
    "        ngram_counts (dict): El modelo de n-gramas con las frecuencias de los n-gramas.\n",
    "        final_unigram (dict): El modelo de (n-1)-gramas con las frecuencias.\n",
    "        n_gram (int): El tamaño del n-grama (1 para unigramas, 2 para bigramas, etc.).\n",
    "\n",
    "    Returns:\n",
    "        float: El valor de la perplejidad calculada para el conjunto de prueba.\n",
    "    \"\"\"\n",
    "    perplexity = 0  # Inicializa la suma acumulativa de la perplejidad.\n",
    "    total_words = 0  # Contador para el número total de palabras procesadas.\n",
    "    \n",
    "    for sentence in test_set:\n",
    "        tokens = sentence.split()  # Divide la oración en tokens.\n",
    "        \n",
    "        # Recorre los tokens desde el índice n_gram - 1 hasta el final.\n",
    "        for i in range(n_gram - 1, len(tokens)):\n",
    "            # Estima la probabilidad del n-grama actual.\n",
    "            prob = estimate_probability(tokens[i-n_gram+1:i+1], n_gram, final_unigram, ngram_counts)\n",
    "            # Calcula la logaritmo negativo de la probabilidad y la suma a la perplejidad.\n",
    "            perplexity -= np.log(prob)\n",
    "        \n",
    "        # Incrementa el número total de palabras procesadas.\n",
    "        total_words += len(tokens) - (n_gram - 1)\n",
    "    \n",
    "    # Devuelve la perplejidad exponencial media.\n",
    "    return np.exp(perplexity / total_words)\n",
    "\n",
    "def generate_sentence(start_word, ngram_counts, final_unigram, n_gram, max_length=15):\n",
    "    \"\"\"\n",
    "    Genera una oración automáticamente a partir de un modelo de n-gramas.\n",
    "\n",
    "    Esta función toma una palabra inicial y construye una oración basada en los n-gramas más frecuentes\n",
    "    del modelo, generando hasta `max_length` palabras.\n",
    "\n",
    "    Args:\n",
    "        start_word (str): La primera palabra de la oración.\n",
    "        ngram_counts (dict): El modelo de n-gramas con las frecuencias de los n-gramas.\n",
    "        final_unigram (dict): El modelo de (n-1)-gramas con las frecuencias.\n",
    "        n_gram (int): El tamaño del n-grama utilizado (1 para unigramas, 2 para bigramas, etc.).\n",
    "        max_length (int): La longitud máxima de la oración generada.\n",
    "\n",
    "    Returns:\n",
    "        str: La oración generada automáticamente.\n",
    "    \"\"\"\n",
    "    sentence = [start_word]  # Inicializa la oración con la palabra inicial.\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        # Encuentra los candidatos a la siguiente palabra basados en el contexto actual.\n",
    "        next_token_candidates = [(ngram[-1], count) for ngram, count in ngram_counts.items()\n",
    "                                 if ngram[:-1] == tuple(sentence[-(n_gram-1):])]\n",
    "        \n",
    "        if not next_token_candidates:\n",
    "            break  # Sale del bucle si no hay candidatos válidos.\n",
    "        \n",
    "        # Selecciona la siguiente palabra con la mayor frecuencia.\n",
    "        next_token = max(next_token_candidates, key=lambda x: x[1])[0]\n",
    "        sentence.append(next_token)  # Añade la palabra seleccionada a la oración.\n",
    "        \n",
    "        if next_token == '</s>':\n",
    "            break  # Termina la oración si se encuentra el token de finalización.\n",
    "    \n",
    "    return ' '.join(sentence)  # Devuelve la oración generada como una cadena de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e93c22-aa58-405b-9ac8-1ffb67ff1ab5",
   "metadata": {},
   "source": [
    "## Paso 2: Cálculo de la Perplejidad de los Modelos de N-gramas de 20N y BAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c545d3-a972-45b2-bf08-323631f48e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula la perplejidad de los modelos de N-gramas de 20N\n",
    "perplexity_unigram_20n = compute_perplexity(df_news_test['text'], unigram_counts_20n, unigram_20n, 1)\n",
    "perplexity_bigram_20n = compute_perplexity(df_news_test['text'], bigram_counts_20n, bigram_20n, 2)\n",
    "perplexity_trigram_20n = compute_perplexity(df_news_test['text'], trigram_counts_20n, trigram_20n, 3)\n",
    "\n",
    "print(f\"Perplejidad (Unigrama 20N): {perplexity_unigram_20n}\")\n",
    "print(f\"Perplejidad (Bigrama 20N): {perplexity_bigram_20n}\")\n",
    "print(f\"Perplejidad (Trigrama 20N): {perplexity_trigram_20n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60239c46-cd30-471e-81f1-bc579b5ddb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula la perplejidad de los modelos de N-gramas de BAC\n",
    "perplexity_unigram_bac = compute_perplexity(df_bac_test['text'], unigram_counts_bac, unigram_bac, 1)\n",
    "perplexity_bigram_bac = compute_perplexity(df_bac_test['text'], bigram_counts_bac, bigram_bac, 2)\n",
    "perplexity_trigram_bac = compute_perplexity(df_bac_test['text'], trigram_counts_bac, trigram_bac, 3)\n",
    "\n",
    "print(f\"Perplejidad (Unigrama BAC): {perplexity_unigram_bac}\")\n",
    "print(f\"Perplejidad (Bigrama BAC): {perplexity_bigram_bac}\")\n",
    "print(f\"Perplejidad (Trigrama BAC): {perplejidad_trigram_bac}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1643a7-bb89-4b96-bdd0-c60da1cd10ef",
   "metadata": {},
   "source": [
    "## Paso 3: Generación de Sentencias con los Mejores Modelos de N-gramas de 20N y BAC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed6854d-3375-4358-b1e3-57a49eef3a3a",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">Lo que sigue es solo un ejemplo. Falta encontrar los mejores modelos de cada conjunto de datos.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cade6f-32a3-43d1-94a5-2728ac50e4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de generación de oraciones con `bigram_counts_20n`\n",
    "generated_sentence_20n = generate_sentence('<s>', bigram_counts_20n, bigram_20n, 2)\n",
    "print(f\"Oración generada (20N): {generated_sentence_20n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e38da7-b4dd-499a-af75-7c176c014ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de generación de oraciones con `bigram_counts_bac`\n",
    "generated_sentence_bac = generate_sentence('<s>', bigram_counts_bac, bigram_bac, 2)\n",
    "print(f\"Oración generada (BAC): {generated_sentence_bac}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
