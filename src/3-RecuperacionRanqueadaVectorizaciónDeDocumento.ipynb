{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"1-MetricasDeEvaluacionDeIR.ipynb\"\n",
    "%run \"2-BusquedaBinariaUsandoIndiceInvertido.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción matriz/vector tf-idf a partir del índice invertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_tf_idf_matrix(inverted_index: dict[dict[int]], \n",
    "                        tf_log_scale: bool = True,\n",
    "                        normalize_matrix: bool = True) -> tuple[np.array, list[str], list[int]]:\n",
    "    \"\"\"\n",
    "    Calcula la matriz TF-IDF a partir de un índice invertido.\n",
    "\n",
    "    Esta función toma un índice invertido que mapea términos a documentos y sus frecuencias, \n",
    "    y calcula la matriz TF-IDF para cada término en cada documento. La opción de usar escala \n",
    "    logarítmica para la frecuencia de términos (TF) es configurable, así como la opción de \n",
    "    normalizar la matriz resultante.\n",
    "\n",
    "    Args:\n",
    "        inverted_index (dict[dict[int]]): \n",
    "            Un diccionario donde las claves son términos (str) y los valores son diccionarios.\n",
    "            Estos diccionarios internos mapean el ID del documento (int) a la frecuencia de ese \n",
    "            término en el documento.\n",
    "\n",
    "        tf_log_scale (bool, opcional): \n",
    "            Indica si se debe aplicar escala logarítmica al cálculo de la frecuencia de términos (TF).\n",
    "            Por defecto es True, lo que significa que se usará la fórmula `log10(1 + frecuencia)`. Si \n",
    "            se establece en False, se usará la frecuencia sin escala logarítmica.\n",
    "\n",
    "        normalize_matrix (bool, opcional): \n",
    "            Indica si se debe normalizar la matriz TF-IDF resultante. La normalización se realiza por \n",
    "            filas, lo que significa que cada vector de documento se ajusta para que su norma sea 1. \n",
    "            Por defecto es True.\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.array, list[str], list[int]]: \n",
    "            Retorna una tupla que contiene:\n",
    "            - tf_idf_matrix (np.array): Un array bidimensional donde cada fila representa un documento \n",
    "              y cada columna representa un término. Los valores en la matriz son los pesos TF-IDF \n",
    "              correspondientes.\n",
    "            - terms (list[str]): Una lista ordenada de los términos presentes en el índice invertido.\n",
    "            - docs (list[int]): Una lista ordenada de los IDs de documentos únicos en el corpus.\n",
    "    \"\"\"\n",
    "\n",
    "    # Obtiene y ordena los términos únicos en el índice invertido.\n",
    "    terms = np.array(sorted(list(inverted_index.keys())))\n",
    "\n",
    "    # Extrae y ordena los IDs de documentos únicos en el corpus.\n",
    "    docs = {doc for docs_freq in inverted_index.values() for doc in docs_freq}\n",
    "    docs = np.array(sorted(list(docs)))\n",
    "\n",
    "    # Calcula el Inverse Document Frequency (IDF) para cada término.\n",
    "    # IDF = log10(N / df), donde N es el número total de documentos y df es la frecuencia de documentos \n",
    "    # que contienen el término.\n",
    "    idf = {term: np.log10(len(docs) / len(inverted_index[term]))\n",
    "           for term in terms}\n",
    "\n",
    "    # Calcula el Term Frequency (TF) para cada término en cada documento.\n",
    "    # Si se aplica escala logarítmica, se usa la fórmula: TF = log10(1 + frecuencia).\n",
    "    # Si no, se utiliza la frecuencia directa.\n",
    "    if tf_log_scale:\n",
    "        tf = {doc: {term: np.log10(1 + inverted_index[term].get(doc, 0)) \n",
    "                    for term in terms} for doc in docs}\n",
    "    else:\n",
    "        tf = {doc: {term: inverted_index[term].get(\n",
    "            doc, 0) for term in terms} for doc in docs}\n",
    "\n",
    "    # Calcula el TF-IDF para cada término en cada documento.\n",
    "    # TF-IDF = TF * IDF para cada término en cada documento.\n",
    "    tf_idf = {doc: {term: tf[doc][term] * idf[term]\n",
    "                    for term in terms} for doc in docs}\n",
    "\n",
    "    # Convierte el diccionario de TF-IDF en una matriz numpy para facilitar el procesamiento posterior.\n",
    "    # Cada fila de la matriz representa un documento y cada columna un término.\n",
    "    tf_idf_matrix = np.array([[tf_idf[doc][term] for term in terms] for doc in docs])\n",
    "    \n",
    "    # Normaliza la matriz TF-IDF, de manera que la norma de cada vector de documento sea 1.\n",
    "    if normalize_matrix:\n",
    "        tf_idf_matrix = tf_idf_matrix / np.linalg.norm(tf_idf_matrix, axis=1, keepdims=True)\n",
    "    \n",
    "    # Retorna la matriz TF-IDF, la lista de términos y la lista de documentos en el orden correspondiente.\n",
    "    # Redondea a 7 decimales para evitar errores de precisión\n",
    "    return tf_idf_matrix.round(7), terms, docs, idf\n",
    "\n",
    "\n",
    "def crear_vector_tf_idf(text: str,\n",
    "                        terms: list[str],\n",
    "                        corpus_idf: dict[str, float],\n",
    "                        tf_log_scale: bool = True,\n",
    "                        normalize_vector: bool = True) -> np.array:\n",
    "    \"\"\"\n",
    "    Crea un vector TF-IDF a partir de un texto dado.\n",
    "\n",
    "    Esta función toma un texto, una lista de términos y un diccionario de valores \n",
    "    IDF precomputados para un corpus, y genera un vector TF-IDF para el texto \n",
    "    proporcionado. La opción de usar escala logarítmica para la frecuencia de términos \n",
    "    (TF) y la normalización del vector resultante es configurable.\n",
    "\n",
    "    Args:\n",
    "        text (str): \n",
    "            El texto a partir del cual se generará el vector TF-IDF.\n",
    "        \n",
    "        terms (list[str]): \n",
    "            Una lista de términos que se consideran en el corpus. Cada término de la lista \n",
    "            corresponde a una columna en el vector TF-IDF.\n",
    "\n",
    "        corpus_idf (dict[str, float]): \n",
    "            Un diccionario que mapea cada término a su valor IDF (Inverse Document Frequency) \n",
    "            precomputado en el corpus. \n",
    "\n",
    "        tf_log_scale (bool, opcional): \n",
    "            Indica si se debe aplicar escala logarítmica al cálculo de la frecuencia de términos (TF).\n",
    "            Por defecto es True, lo que significa que se usará la fórmula `log10(1 + frecuencia)`. \n",
    "            Si se establece en False, se usará la frecuencia sin escala logarítmica.\n",
    "\n",
    "        normalize_vector (bool, opcional): \n",
    "            Indica si se debe normalizar el vector TF-IDF resultante. La normalización ajusta \n",
    "            el vector para que su norma sea 1, lo que facilita la comparación entre textos.\n",
    "            Por defecto es True.\n",
    "\n",
    "    Returns:\n",
    "        np.array: \n",
    "            Un array de NumPy que representa el vector TF-IDF del texto dado. Cada posición en el \n",
    "            vector corresponde a un término en la lista `terms`, y su valor es el peso TF-IDF \n",
    "            correspondiente a ese término en el texto.\n",
    "    \"\"\"    \n",
    "\n",
    "    # Procesa el texto para limpiarlo y normalizarlo, preparando los datos para el análisis.\n",
    "    # process_text fue definido en el notebook 2-BusquedaBinariaUsandoIndiceInvertido.ipynb\n",
    "    text_cln = process_text({'0': text})['0']\n",
    "\n",
    "    # Calcula el vector TF-IDF, aplicando escala logarítmica si se especifica.\n",
    "    if tf_log_scale:\n",
    "        txt_vector = np.array([\n",
    "            np.log10(1 + text_cln.count(term)) * corpus_idf[term] if term in text_cln else 0\n",
    "            for term in terms])\n",
    "    else:\n",
    "        # Si no se aplica escala logarítmica, se utiliza la frecuencia directa.\n",
    "        txt_vector = np.array([\n",
    "            text_cln.count(term) * corpus_idf[term] if term in text_cln else 0\n",
    "            for term in terms])\n",
    "\n",
    "    # Normaliza el vector TF-IDF, de manera que su norma sea 1 si la opción está activada.\n",
    "    if normalize_vector:\n",
    "        txt_vector = txt_vector / np.linalg.norm(txt_vector)\n",
    "    \n",
    "    # Redondea los valores del vector a 7 decimales para evitar errores de precisión.\n",
    "    return txt_vector.round(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculo de la similitud coseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_simi(v1: np.array, v2: np.array, asume_norm_1: bool = False) -> float:\n",
    "    \"\"\"\n",
    "    Calcula la similitud coseno entre dos vectores.\n",
    "\n",
    "    Esta función calcula la similitud coseno entre dos vectores `v1` y `v2`. \n",
    "    La similitud coseno es una medida de la similitud entre dos vectores \n",
    "    en un espacio vectorial que mide el coseno del ángulo entre ellos. \n",
    "    Se utiliza comúnmente en análisis de texto y en tareas de recuperación de información.\n",
    "\n",
    "    Args:\n",
    "        v1 (np.array): \n",
    "            El primer vector (como un array de NumPy) con el que se calculará la similitud.\n",
    "        \n",
    "        v2 (np.array): \n",
    "            El segundo vector (como un array de NumPy) con el que se calculará la similitud.\n",
    "        \n",
    "        asume_norm_1 (bool, opcional): \n",
    "            Si se establece en True, la función asume que ambos vectores `v1` y `v2` \n",
    "            ya están normalizados (es decir, su norma es 1). Esto permite omitir el \n",
    "            cálculo de las normas, mejorando la eficiencia. Por defecto es False.\n",
    "\n",
    "    Returns:\n",
    "        float: \n",
    "            Un valor de tipo float que representa la similitud coseno entre los dos vectores.\n",
    "            Un valor cercano a 1 indica que los vectores son muy similares (paralelos), \n",
    "            mientras que un valor cercano a 0 indica que son ortogonales (no relacionados).\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if asume_norm_1:\n",
    "        # Si se asume que los vectores ya están normalizados (norma = 1), \n",
    "        # la similitud coseno se reduce al producto punto entre ellos.\n",
    "        res = np.dot(v1, v2)\n",
    "    else:\n",
    "        # Si los vectores no están normalizados, se calcula la similitud coseno \n",
    "        # como el producto punto dividido por el producto de las normas de los vectores.\n",
    "        res = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    \n",
    "    # Redondea a 4 decimales para evitar errores de precisión\n",
    "    return res.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizar consultas para obtener documentos relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_relevant_docs(text: str, \n",
    "                           terms: np.array, \n",
    "                           docs: np.array, \n",
    "                           corpus_idf: dict[str, float], \n",
    "                           tf_idf_matrix: np.array, \n",
    "                           relevance_treshold: float = 0,\n",
    "                           tf_log_scale: bool = True,\n",
    "                           normalize_vector: bool = True\n",
    "                           ) -> np.array:\n",
    "    \"\"\"\n",
    "    Obtiene los documentos más relevantes en función de una consulta de texto.\n",
    "\n",
    "    Esta función toma un texto de consulta, calcula su vector TF-IDF, y luego compara \n",
    "    este vector con una matriz TF-IDF de un corpus utilizando la similitud coseno. \n",
    "    Los documentos cuya similitud coseno con la consulta es mayor que un umbral \n",
    "    especificado se consideran relevantes y se retornan en orden de relevancia.\n",
    "\n",
    "    Args:\n",
    "        text (str): \n",
    "            El texto de la consulta para el cual se desean encontrar los documentos más relevantes.\n",
    "        \n",
    "        terms (np.array[str]): \n",
    "            Un array de términos relevantes en el corpus, utilizado para construir el vector TF-IDF \n",
    "            de la consulta.\n",
    "        \n",
    "        docs (np.array[str]): \n",
    "            Un array de IDs o nombres de documentos en el corpus, donde cada documento se corresponde \n",
    "            con una fila en la matriz `tf_idf_matrix`.\n",
    "        \n",
    "        corpus_idf (dict[str, float]): \n",
    "            Un diccionario que mapea cada término a su valor IDF (Inverse Document Frequency) \n",
    "            precomputado en el corpus.\n",
    "\n",
    "        tf_idf_matrix (np.array[float]): \n",
    "            Una matriz TF-IDF donde cada fila representa un documento y cada columna representa un \n",
    "            término del corpus. Esta matriz se usa para comparar la consulta con los documentos existentes.\n",
    "\n",
    "        relevance_treshold (float, opcional): \n",
    "            Un umbral de relevancia. Solo se retornarán los documentos cuya similitud coseno con \n",
    "            la consulta sea mayor que este valor. Por defecto es 0, lo que significa que se incluirán \n",
    "            todos los documentos con una similitud positiva.\n",
    "            \n",
    "        tf_log_scale (bool, opcional):\n",
    "            Indica si se debe aplicar escala logarítmica al cálculo de la frecuencia de términos (TF).\n",
    "            Por defecto es True, lo que significa que se usará la fórmula `log10(1 + frecuencia)`. \n",
    "            Si se establece en False, se usará la frecuencia sin escala logarítmica.\n",
    "        \n",
    "        normalize_vector (bool, opcional):\n",
    "            Indica si se debe normalizar el vector TF-IDF de la consulta. La normalización ajusta \n",
    "            el vector para que su norma sea 1, lo que facilita la comparación con los vectores \n",
    "            de documentos. Por defecto es True.\n",
    "\n",
    "    Returns:\n",
    "        np.array[str]: \n",
    "            Un array de IDs o nombres de documentos ordenados por relevancia, desde el más relevante \n",
    "            hasta el menos relevante, según la similitud coseno con la consulta.\n",
    "    \"\"\"\n",
    "\n",
    "    # Crear el vector TF-IDF para la consulta de texto dada, utilizando el corpus y la lista de términos.\n",
    "    v_query = crear_vector_tf_idf(text, terms, corpus_idf, \n",
    "                                  tf_log_scale=tf_log_scale, \n",
    "                                  normalize_vector=normalize_vector)\n",
    "\n",
    "    # Calcular la similitud coseno entre el vector de la consulta y la matriz TF-IDF del corpus.\n",
    "    # Se asume que los vectores en la matriz TF-IDF ya están normalizados.\n",
    "    cosine_similarities = cosine_simi(v_query, tf_idf_matrix.T, asume_norm_1=True)\n",
    "\n",
    "    # Identificar los índices de los documentos cuya similitud coseno es mayor que el umbral de relevancia.\n",
    "    indices = np.where(cosine_similarities > relevance_treshold)[0]\n",
    "\n",
    "    # Ordenar los índices de los documentos por similitud coseno en orden descendente.\n",
    "    sorted_indices = indices[np.argsort(-cosine_similarities[indices])]\n",
    "\n",
    "    # Obtener los documentos correspondientes a los índices ordenados por relevancia.\n",
    "    sorted_docs = [(docs[i], cosine_similarities[i]) for i in sorted_indices]\n",
    "    \n",
    "    return sorted_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear matriz tf-idf a partir del índice invertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = json.loads(open('./output/inverted_index.json').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix, terms, docs, corpus_idf = crear_tf_idf_matrix(inverted_index, \n",
    "                                                             tf_log_scale=True,\n",
    "                                                             normalize_matrix=True\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecutar consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output/processed_queries.json') as f:\n",
    "    processed_queries = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_res = {}\n",
    "with open(\"./output/RRDV_metrics/RRDV-consultas_resultados.tsv\", \"w\") as f:\n",
    "    for q,t in processed_queries.items():\n",
    "        \n",
    "        rel_docs = get_most_relevant_docs(\n",
    "                                ' '.join(t), \n",
    "                                terms, \n",
    "                                docs, \n",
    "                                corpus_idf, \n",
    "                                tf_idf_matrix, \n",
    "                                relevance_treshold=0,\n",
    "                                tf_log_scale=True,\n",
    "                                normalize_vector=True\n",
    "                                )\n",
    "        \n",
    "        queries_res[q] = rel_docs\n",
    "        rel_docs = ','.join([f'{d[0]}:{d[1]}' for d in rel_docs])\n",
    "        \n",
    "        f.write(f\"{q}\\t{rel_docs}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular metricas de evaluacion\n",
    "file_path = 'data/relevance-judgments.tsv'\n",
    "\n",
    "queries = {}\n",
    "\n",
    "# Abrir el archivo de relevance-judgments\n",
    "with open(file_path, 'r', newline='', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file, delimiter='\\t')\n",
    "    \n",
    "    for row in reader:\n",
    "        # la primera columna es el id del query\n",
    "        query_id = row[0]\n",
    "        \n",
    "        # Extraer el id de los documentos relevantes y su score\n",
    "        document_scores = row[1].split(',')\n",
    "        \n",
    "        documents = {}\n",
    "        \n",
    "        for document_score in document_scores:\n",
    "            # Obtener el id del documento y su puntaje\n",
    "            document_id, score = document_score.split(':')\n",
    "            \n",
    "            score = int(score)\n",
    "            documents[document_id] = score\n",
    "        \n",
    "        queries[query_id] = documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos los vectores de relevancia binaria para cada query\n",
    "relevances = {}\n",
    "\n",
    "for query, documents in queries.items():\n",
    "    binary_array = []\n",
    "    for d in queries_res[query]:\n",
    "        binary_array.append(1 if d[0] in documents else 0)\n",
    "    relevances[query] = binary_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P@M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'output/RRDV_metrics/P@M.txt'\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    for query, documents in queries.items():\n",
    "        precision = precision_at_k(relevances[query], len(documents))\n",
    "        file.write(f\"{query}: {precision}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R@M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'output/RRDV_metrics/R@M.txt'\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    for query, documents in queries.items():\n",
    "        recall = recall_at_k(relevances[query], len(documents), len(documents))\n",
    "        file.write(f\"{query}: {recall}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7402507734672369"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map = mean_average_precision(list(relevances.values()))\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NDCG@M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos los vectores de relevancia para cada query\n",
    "relevances_ranked = {}\n",
    "\n",
    "for query, documents in queries.items():\n",
    "    binary_array = []\n",
    "    for d in queries_res[query]:\n",
    "        binary_array.append(documents.get(d[0],0))\n",
    "    relevances_ranked[query] = binary_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'output/RRDV_metrics/NDCG@M.txt'\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    for query, documents in queries.items():\n",
    "        ndcg = ndcg_at_k(relevances_ranked[query], len(documents))\n",
    "        file.write(f\"{query}: {ndcg}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
