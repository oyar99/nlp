\documentclass[11pt,english]{article}

\usepackage{graphicx} % Required for inserting images
\usepackage[margin=2cm,top=2cm,headheight=16pt,headsep=0.2in,heightrounded]{geometry}
\usepackage{fancyhdr} % Required for inserting and customizing page header
    \pagestyle{fancy} % Required for changing page style
\usepackage{amsmath}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{hyperref}
\usepackage{caption}

\usepackage{tikz}
\usepackage{booktabs}
\usetikzlibrary{arrows}
\usetikzlibrary{tikzmark}
\usetikzlibrary{trees}

\usepackage{tabularx}
\usepackage{lscape}
\newcolumntype{b}{>{\hsize=2.80\hsize}X}
\newcolumntype{s}{>{\hsize=.4\hsize}X}

\usepackage{enumitem}
\usepackage{longtable}

\captionsetup[table]{name=Tabla}
\captionsetup[figure]{name=Figura}

\usepackage{amsthm}
\theoremstyle{plain}

\newtheorem*{definition*}{Definition}
\newtheorem{definition}{Definition}

\fancyhead{}
\fancyfoot{}

\fancyhead[L]{Proyecto Final: Procesamiento de Lenguaje Natural}
\fancyfoot[L]{\thepage}

\title{Procesamiento de Lenguaje Natural\\
Proyecto Final
}
\author{
  Rayo Mosquera, Jhon Stewar\\
  \texttt{j.rayom@uniandes.edu.co}
  \and
  De La Rosa Peredo, Carlos Raul\\
  \texttt{c.delarosap@uniandes.edu.co}\and
  Mario Garrido Córdoba\\
   \texttt{m.garrido10@uniandes.edu.co}
  \\ 
}
\date{Noviembre 2024}

\begin{document}

\maketitle

\section{Introducción}

El proyecto \textbf{Recuperación de Información Regulatoria y Generación de Respuestas (RIRAG)} se enfoca en desarrollar soluciones que permitan recuperar y comprender información en contextos regulatorios. Este informe detalla nuestra primera entrega, centrada en el \textbf{Subtask 1: Recuperación de Pasajes}, cuyo objetivo es mejorar el rendimiento del baseline BM25 en la recuperación de pasajes relevantes para consultas específicas.

\section{Metodología}

\subsection{Preparación y Limpieza de Datos}

\subsubsection{Descripción del Conjunto de Datos}

El \textbf{conjunto de datos ObliQA} es una colección de documentos regulatorios provenientes de \textit{Abu Dhabi Global Markets (ADGM)}. Incluye 40 documentos legales y un conjunto de preguntas asociadas, distribuidas en conjuntos de entrenamiento, validación y prueba. Cada pregunta está relacionada con uno o más pasajes relevantes dentro de los documentos, proporcionando una base sólida para tareas de recuperación y generación de respuestas.

\subsubsection{Preprocesamiento del Texto}

Llevamos a cabo las siguientes acciones:

\begin{itemize}
    \item \textbf{Expansión de Contracciones:} Utilizamos la librería \texttt{contractions} para expandir términos como \textit{don't} a \textit{do not}, evitando ambigüedades.

    \item \textbf{Normalización y Limpieza:} Convertimos el texto a minúsculas y eliminamos caracteres no alfanuméricos y signos de puntuación mediante expresiones regulares con la librería \texttt{re}.

    \item \textbf{Eliminación de Espacios Redundantes:} Eliminamos espacios en blanco adicionales y caracteres de control para mantener la consistencia en el texto.

    \item \textbf{Preservación de Formato Legal:} Evitamos la normalización Unicode para conservar caracteres especiales que puedan ser relevantes en contextos legales.
\end{itemize}

\subsection{Tokenización, Stopwords y Stemming}

Aplicamos las siguientes técnicas:

\begin{itemize}
    \item \textbf{Tokenización:} Implementamos una función personalizada que genera \textbf{unigramas y bigramas} para capturar tanto términos individuales como combinaciones de palabras significativas.

    \item \textbf{Eliminación de Stopwords:} Combinamos las stopwords de \texttt{nltk} y \texttt{scikit-learn} para crear una lista adaptada al dominio, eliminando palabras comunes que no aportan significado.

    \item \textbf{Stemming:} Aplicamos el \textbf{algoritmo Snowball Stemmer} para reducir las palabras a sus raíces, unificando diferentes formas de una misma palabra y reduciendo la dimensionalidad.
\end{itemize}

\subsection{Modelos Implementados}

\subsubsection{Modelos Sintácticos}

\paragraph{BM25}

Utilizamos la implementación de \texttt{rank\_bm25} para construir un modelo BM25. Este modelo considera la frecuencia de términos y la longitud del documento para asignar puntuaciones de relevancia. Configuramos los parámetros $k1=1.5$ y $b=0.75$, valores comúnmente utilizados que ofrecen un equilibrio entre frecuencia y longitud.

\paragraph{TF-IDF}

Implementamos un vectorizador TF-IDF utilizando \texttt{TfidfVectorizer} de \texttt{scikit-learn}. Configuramos parámetros como \texttt{ngram\_range=(1,2)}, \texttt{max\_features=30000}, \texttt{max\_df=0.9} y \texttt{min\_df=3} para optimizar la representación del texto y reducir el impacto de términos muy frecuentes o muy raros.

\subsubsection{Modelo Semántico}

Seleccionamos el modelo \texttt{BAAI/bge-small-en-v1.5}, un transformer preentrenado capaz de generar embeddings semánticos de alta calidad. Realizamos \textit{fine-tuning} utilizando el conjunto de datos preparado, enfocándonos en maximizar la similitud entre pares de preguntas y pasajes relevantes. Configuramos el modelo con las siguientes especificaciones:

\begin{itemize}
    \item \textbf{Capa de Embeddings:} Utilizamos \texttt{SentenceTransformer} con \texttt{torch\_dtype=float16} para optimizar la memoria y velocidad.

    \item \textbf{Pooling y Normalización:} Incluimos capas de \texttt{Pooling} (utilizando el token [CLS]) y \texttt{Normalize} para mejorar la representación vectorial de los textos.

    \item \textbf{Función de Pérdida:} Empleamos \texttt{MultipleNegativesRankingLoss} para entrenar el modelo en tareas de recuperación de información.
\end{itemize}

\subsubsection{Sistema Híbrido de Recuperación}

Para combinar las ventajas de los modelos sintácticos y semánticos, desarrollamos un sistema híbrido que integra ambos enfoques mediante un promedio ponderado de sus puntuaciones:

\[
\text{Puntuación Híbrida} = \alpha \times \text{Puntuación Semántica} + (1 - \alpha) \times \text{Puntuación Sintáctica}
\]

\noindent Donde $\alpha = 0.65$ asigna mayor peso al componente semántico. Normalizamos las puntuaciones de ambos modelos entre 0 y 1 para asegurar una combinación equilibrada.

\subsection{Entrenamiento y Fine-Tuning}

Para entrenar el modelo semántico:

\begin{itemize}
    \item \textbf{Configuración de Entrenamiento:}
    \begin{itemize}
        \item \textbf{Épocas:} 10.
        \item \textbf{Batch size:} 64 con \texttt{gradient\_accumulation\_steps=4} para simular un batch de 256.
        \item \textbf{Learning rate:} $2 \times 10^{-5}$.
    \end{itemize}

    \item \textbf{Estrategias de Optimización:} Utilizamos \texttt{warmup\_ratio=0.1} y desactivamos \texttt{gradient\_checkpointing} para mejorar la eficiencia.

    \item \textbf{Evaluación Continua:} Empleamos \texttt{InformationRetrievalEvaluator} para monitorizar el rendimiento en cada época, enfocándonos en métricas clave.

    \item \textbf{Implementación de Hard Negatives:} Incorporamos ejemplos negativos difíciles extraídos con BM25 para robustecer el entrenamiento.
\end{itemize}

\section{Experimentos y Resultados}

\subsection{Configuración Experimental}

Realizamos los experimentos utilizando los conjuntos de datos de entrenamiento, validación y prueba proporcionados por ObliQA. Las implementaciones se llevaron a cabo en Python, utilizando librerías como \texttt{sentence-transformers}, \texttt{nltk} y \texttt{scikit-learn}. Los modelos fueron entrenados y evaluados en una GPU NVIDIA A40 para acelerar el procesamiento.

\subsection{Evaluación y Métricas}

Utilizamos las métricas \textbf{Recall@10}, \textbf{MAP@10}, \textbf{Recall@20} y \textbf{MAP@20} para evaluar el rendimiento de los modelos. Estas métricas son estándar en tareas de recuperación de información y proporcionan una visión integral de la capacidad de los modelos para recuperar y ordenar pasajes relevantes. La evaluación se realizó con la herramienta \texttt{trec\_eval}, siguiendo los estándares de la comunidad en IR (Information Retrieval).

\subsection{Rendimiento Comparativo}

\begin{table}[h!]
\centering
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Modelo} & \textbf{Recall@10} & \textbf{MAP@10} & \textbf{Recall@20} & \textbf{MAP@20} \\ \hline
BM25 (Baseline) & 0.7791 & 0.6415 & 0.8204 & 0.6453 \\ \hline
Modelo Semántico     & 0.8103 & 0.6286 & 0.8622 & 0.6334 \\ \hline
Sistema Híbrido         & \textbf{0.8333} & \textbf{0.7016} & \textbf{0.8704} & \textbf{0.7053} \\ \hline
\end{tabular}
\caption{Rendimiento comparativo de los modelos en el conjunto de prueba.}
\end{table}

\noindent Los resultados muestran que el sistema híbrido supera significativamente al baseline BM25 y al modelo semántico individual en todas las métricas evaluadas.

\section{Discusión}

Los experimentos confirman que la combinación de modelos sintácticos y semánticos mejora la recuperación de información en el dominio regulatorio. El modelo BM25 es eficaz en recuperar pasajes con coincidencias exactas, pero carece de capacidad para entender sinónimos o términos relacionados. Por otro lado, el modelo semántico captura relaciones profundas entre términos, pero puede perder precisión en coincidencias exactas.

El sistema híbrido equilibra estas limitaciones, logrando un mayor \textbf{Recall@10} y \textbf{MAP@10}. La elección de $\alpha = 0.65$ refleja la importancia de la semántica en este dominio, sin descuidar la sintaxis.

Además, observamos que el modelo semántico ajustado mantiene capacidades generales del modelo base, lo que es beneficioso para manejar consultas fuera del dominio específico.

\section{Conclusiones}

Hemos desarrollado un sistema de recuperación de pasajes que supera al baseline BM25 mediante la integración de modelos sintácticos y semánticos. Nuestro enfoque híbrido demuestra ser efectivo en capturar tanto coincidencias exactas como relaciones semánticas, lo que es crucial en el contexto regulatorio.

Los resultados obtenidos validan nuestra hipótesis y resaltan la importancia de combinar técnicas tradicionales y avanzadas en NLP. Este trabajo sienta las bases para abordar el Subtask 2, enfocado en la generación de respuestas.

\end{document}
