{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from functions import read_file, build_preprocess_pipeline\n",
    "from pandas import DataFrame\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total topics (classes):  20\n",
      "Total files:  18828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "topics\n",
       "rec.sport.hockey            999\n",
       "soc.religion.christian      997\n",
       "rec.motorcycles             994\n",
       "rec.sport.baseball          994\n",
       "sci.crypt                   991\n",
       "rec.autos                   990\n",
       "sci.med                     990\n",
       "sci.space                   987\n",
       "comp.os.ms-windows.misc     985\n",
       "comp.sys.ibm.pc.hardware    982\n",
       "sci.electronics             981\n",
       "comp.windows.x              980\n",
       "comp.graphics               973\n",
       "misc.forsale                972\n",
       "comp.sys.mac.hardware       961\n",
       "talk.politics.mideast       940\n",
       "talk.politics.guns          910\n",
       "alt.atheism                 799\n",
       "talk.politics.misc          775\n",
       "talk.religion.misc          628\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cates_dir = glob('data/20news-18828/*')\n",
    "\n",
    "topics_path = {c.split('/')[-1]: glob(f'{c}/*') for c in cates_dir}\n",
    "\n",
    "print(\"Total topics (classes): \", len(topics_path)) \n",
    "\n",
    "df = DataFrame([(k, v) for k, v in topics_path.items()], columns=['topics', 'files'])\n",
    "\n",
    "df = df.explode('files')\n",
    "\n",
    "print(\"Total files: \", len(df))\n",
    "\n",
    "df['text'] = df['files'].apply(read_file)\n",
    "\n",
    "df.value_counts('topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  13179\n",
      "Test:  5649\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['text'], df['topics'], \n",
    "                                                    train_size=0.7, random_state=42)\n",
    "\n",
    "print(\"Train: \", len(x_train))\n",
    "print(\"Test: \", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_pipeline = build_preprocess_pipeline('count').fit(x_train)\n",
    "tfidf_pipeline = build_preprocess_pipeline('tfidf').fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=10, random_state=42, \n",
    "                            test_size=1/7) # Validation is around 10% of original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf_transformed = tfidf_pipeline.transform(x_train)\n",
    "X_train_cnt_transformed = cnt_pipeline.transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF - IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión Logística "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([3.38539026, 2.51609988]),\n",
       " 'std_fit_time': array([0.26490418, 0.77298931]),\n",
       " 'mean_score_time': array([0.03264205, 0.01881719]),\n",
       " 'std_score_time': array([0.00356123, 0.01154198]),\n",
       " 'param_C': masked_array(data=[1, 10],\n",
       "              mask=[False, False],\n",
       "        fill_value=999999),\n",
       " 'params': [{'C': 1}, {'C': 10}],\n",
       " 'split0_test_score': array([0.87930025, 0.9001992 ]),\n",
       " 'split1_test_score': array([0.87784715, 0.89756575]),\n",
       " 'split2_test_score': array([0.86912299, 0.88878176]),\n",
       " 'split3_test_score': array([0.88287883, 0.89907949]),\n",
       " 'split4_test_score': array([0.86221038, 0.88897247]),\n",
       " 'split5_test_score': array([0.86454146, 0.88715902]),\n",
       " 'split6_test_score': array([0.87892903, 0.89912519]),\n",
       " 'split7_test_score': array([0.89251666, 0.91182899]),\n",
       " 'split8_test_score': array([0.874674  , 0.89981077]),\n",
       " 'split9_test_score': array([0.88293258, 0.90564576]),\n",
       " 'mean_test_score': array([0.87649533, 0.89781684]),\n",
       " 'std_test_score': array([0.0087127, 0.0073763]),\n",
       " 'rank_test_score': array([2, 1], dtype=int32)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar un clasificador\n",
    "logistic_estimator = LogisticRegression(n_jobs=-1, random_state=42, \n",
    "                                        class_weight='balanced', solver='saga',\n",
    "                                        max_iter=1000, penalty='l2',\n",
    "                                        tol=1e-2,\n",
    "                                        )\n",
    "\n",
    "logistic_param_grid = {\n",
    "    'C': [1, 10],\n",
    "}\n",
    "\n",
    "\n",
    "grid_search_best_tfidf_lr_estimator = GridSearchCV(\n",
    "    estimator=logistic_estimator,\n",
    "    param_grid=logistic_param_grid,\n",
    "    cv=cv,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    return_train_score=False,\n",
    "    refit=True\n",
    ").fit(X_train_tfidf_transformed, y_train)\n",
    "\n",
    "grid_search_best_tfidf_lr_estimator.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.91      0.88      0.89       249\n",
      "           comp.graphics       0.80      0.86      0.83       279\n",
      " comp.os.ms-windows.misc       0.86      0.80      0.83       280\n",
      "comp.sys.ibm.pc.hardware       0.80      0.84      0.82       316\n",
      "   comp.sys.mac.hardware       0.91      0.88      0.90       283\n",
      "          comp.windows.x       0.86      0.87      0.87       292\n",
      "            misc.forsale       0.85      0.89      0.87       298\n",
      "               rec.autos       0.91      0.92      0.92       305\n",
      "         rec.motorcycles       0.97      0.95      0.96       276\n",
      "      rec.sport.baseball       0.96      0.96      0.96       302\n",
      "        rec.sport.hockey       0.96      0.98      0.97       301\n",
      "               sci.crypt       0.98      0.91      0.95       301\n",
      "         sci.electronics       0.88      0.90      0.89       292\n",
      "                 sci.med       0.92      0.94      0.93       320\n",
      "               sci.space       0.96      0.94      0.95       287\n",
      "  soc.religion.christian       0.88      0.94      0.91       293\n",
      "      talk.politics.guns       0.94      0.95      0.94       266\n",
      "   talk.politics.mideast       0.97      0.96      0.97       283\n",
      "      talk.politics.misc       0.90      0.91      0.91       229\n",
      "      talk.religion.misc       0.92      0.77      0.84       197\n",
      "\n",
      "                accuracy                           0.91      5649\n",
      "               macro avg       0.91      0.90      0.90      5649\n",
      "            weighted avg       0.91      0.91      0.91      5649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "X_test_transformed_tfidf = tfidf_pipeline.transform(x_test)\n",
    "y_pred = grid_search_best_tfidf_lr_estimator.predict(X_test_transformed_tfidf)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.09111302, 0.07599483, 0.07769463]),\n",
       " 'std_fit_time': array([0.01943291, 0.01732374, 0.02015989]),\n",
       " 'mean_score_time': array([0.0183924 , 0.01903548, 0.01129441]),\n",
       " 'std_score_time': array([0.00230426, 0.00402743, 0.00407774]),\n",
       " 'param_alpha': masked_array(data=[0.01, 0.1, 1.0],\n",
       "              mask=[False, False, False],\n",
       "        fill_value=1e+20),\n",
       " 'params': [{'alpha': 0.01}, {'alpha': 0.1}, {'alpha': 1}],\n",
       " 'split0_test_score': array([0.88913242, 0.88264894, 0.84739137]),\n",
       " 'split1_test_score': array([0.88891316, 0.88568149, 0.85248198]),\n",
       " 'split2_test_score': array([0.88056591, 0.87790917, 0.84179237]),\n",
       " 'split3_test_score': array([0.8941979 , 0.89112104, 0.86179421]),\n",
       " 'split4_test_score': array([0.86861596, 0.86122972, 0.8322441 ]),\n",
       " 'split5_test_score': array([0.87497521, 0.8756686 , 0.84596561]),\n",
       " 'split6_test_score': array([0.87336639, 0.87381385, 0.84106798]),\n",
       " 'split7_test_score': array([0.88968498, 0.89033201, 0.85584369]),\n",
       " 'split8_test_score': array([0.8898612 , 0.88810441, 0.84721536]),\n",
       " 'split9_test_score': array([0.88703478, 0.88170769, 0.85096735]),\n",
       " 'mean_test_score': array([0.88363479, 0.88082169, 0.8476764 ]),\n",
       " 'std_test_score': array([0.00819762, 0.00863304, 0.00787154]),\n",
       " 'rank_test_score': array([1, 2, 3], dtype=int32)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_estimator = MultinomialNB()\n",
    "\n",
    "nb_param_grid = {\n",
    "    'alpha': [0.01, 0.1, 1],\n",
    "}\n",
    "\n",
    "\n",
    "grid_search_best_tfidf_nb_estimator = GridSearchCV(\n",
    "    estimator=nb_estimator,\n",
    "    param_grid=nb_param_grid,\n",
    "    cv=cv,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    return_train_score=False,\n",
    "    refit=True\n",
    ").fit(X_train_tfidf_transformed, y_train)\n",
    "\n",
    "grid_search_best_tfidf_nb_estimator.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.93      0.90      0.91       249\n",
      "           comp.graphics       0.73      0.87      0.80       279\n",
      " comp.os.ms-windows.misc       0.82      0.78      0.80       280\n",
      "comp.sys.ibm.pc.hardware       0.80      0.83      0.81       316\n",
      "   comp.sys.mac.hardware       0.89      0.90      0.90       283\n",
      "          comp.windows.x       0.86      0.88      0.87       292\n",
      "            misc.forsale       0.87      0.83      0.85       298\n",
      "               rec.autos       0.94      0.93      0.93       305\n",
      "         rec.motorcycles       0.95      0.95      0.95       276\n",
      "      rec.sport.baseball       0.96      0.95      0.95       302\n",
      "        rec.sport.hockey       0.96      0.98      0.97       301\n",
      "               sci.crypt       0.97      0.91      0.94       301\n",
      "         sci.electronics       0.90      0.85      0.88       292\n",
      "                 sci.med       0.95      0.93      0.94       320\n",
      "               sci.space       0.93      0.94      0.94       287\n",
      "  soc.religion.christian       0.85      0.94      0.89       293\n",
      "      talk.politics.guns       0.89      0.95      0.92       266\n",
      "   talk.politics.mideast       0.95      0.97      0.96       283\n",
      "      talk.politics.misc       0.89      0.88      0.89       229\n",
      "      talk.religion.misc       0.96      0.68      0.79       197\n",
      "\n",
      "                accuracy                           0.90      5649\n",
      "               macro avg       0.90      0.89      0.89      5649\n",
      "            weighted avg       0.90      0.90      0.90      5649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "y_pred = grid_search_best_tfidf_nb_estimator.predict(X_test_transformed_tfidf)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión Logística "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([11.91115923,  8.02337012]),\n",
       " 'std_fit_time': array([0.63712802, 2.59289698]),\n",
       " 'mean_score_time': array([0.03099525, 0.01737478]),\n",
       " 'std_score_time': array([0.00334988, 0.01030024]),\n",
       " 'param_C': masked_array(data=[1, 10],\n",
       "              mask=[False, False],\n",
       "        fill_value=999999),\n",
       " 'params': [{'C': 1}, {'C': 10}],\n",
       " 'split0_test_score': array([0.84074035, 0.84515215]),\n",
       " 'split1_test_score': array([0.83339301, 0.83852541]),\n",
       " 'split2_test_score': array([0.82657941, 0.83288213]),\n",
       " 'split3_test_score': array([0.83085266, 0.83210439]),\n",
       " 'split4_test_score': array([0.81295536, 0.8159114 ]),\n",
       " 'split5_test_score': array([0.81231889, 0.81689367]),\n",
       " 'split6_test_score': array([0.8210875 , 0.82483526]),\n",
       " 'split7_test_score': array([0.83510687, 0.84122617]),\n",
       " 'split8_test_score': array([0.81969603, 0.82091896]),\n",
       " 'split9_test_score': array([0.82714804, 0.82899527]),\n",
       " 'mean_test_score': array([0.82598781, 0.82974448]),\n",
       " 'std_test_score': array([0.00895141, 0.0095958 ]),\n",
       " 'rank_test_score': array([2, 1], dtype=int32)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_best_cnt_lr_estimator = GridSearchCV(\n",
    "    estimator=logistic_estimator,\n",
    "    param_grid=logistic_param_grid,\n",
    "    cv=cv,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    return_train_score=False,\n",
    "    refit=True\n",
    ").fit(X_train_cnt_transformed, y_train)\n",
    "\n",
    "grid_search_best_cnt_lr_estimator.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.92      0.87      0.89       249\n",
      "           comp.graphics       0.54      0.72      0.62       279\n",
      " comp.os.ms-windows.misc       0.79      0.72      0.75       280\n",
      "comp.sys.ibm.pc.hardware       0.72      0.72      0.72       316\n",
      "   comp.sys.mac.hardware       0.77      0.78      0.78       283\n",
      "          comp.windows.x       0.63      0.76      0.69       292\n",
      "            misc.forsale       0.69      0.87      0.77       298\n",
      "               rec.autos       0.89      0.86      0.87       305\n",
      "         rec.motorcycles       0.94      0.91      0.93       276\n",
      "      rec.sport.baseball       0.88      0.88      0.88       302\n",
      "        rec.sport.hockey       0.94      0.92      0.93       301\n",
      "               sci.crypt       0.97      0.89      0.93       301\n",
      "         sci.electronics       0.83      0.78      0.80       292\n",
      "                 sci.med       0.89      0.82      0.85       320\n",
      "               sci.space       0.89      0.81      0.85       287\n",
      "  soc.religion.christian       0.85      0.88      0.87       293\n",
      "      talk.politics.guns       0.95      0.84      0.89       266\n",
      "   talk.politics.mideast       0.97      0.92      0.95       283\n",
      "      talk.politics.misc       0.88      0.84      0.86       229\n",
      "      talk.religion.misc       0.88      0.70      0.78       197\n",
      "\n",
      "                accuracy                           0.83      5649\n",
      "               macro avg       0.84      0.83      0.83      5649\n",
      "            weighted avg       0.84      0.83      0.83      5649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "X_test_transformed_cnt = cnt_pipeline.transform(x_test)\n",
    "y_pred = grid_search_best_cnt_lr_estimator.predict(X_test_transformed_cnt)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.08484521, 0.07945714, 0.0769522 ]),\n",
       " 'std_fit_time': array([0.020741  , 0.01090585, 0.01583733]),\n",
       " 'mean_score_time': array([0.01946864, 0.0156971 , 0.01218255]),\n",
       " 'std_score_time': array([0.00250013, 0.00177999, 0.00416096]),\n",
       " 'param_alpha': masked_array(data=[0.01, 0.1, 1.0],\n",
       "              mask=[False, False, False],\n",
       "        fill_value=1e+20),\n",
       " 'params': [{'alpha': 0.01}, {'alpha': 0.1}, {'alpha': 1}],\n",
       " 'split0_test_score': array([0.83808854, 0.84154247, 0.83470547]),\n",
       " 'split1_test_score': array([0.81970393, 0.82954796, 0.81935783]),\n",
       " 'split2_test_score': array([0.83195907, 0.83179974, 0.81658051]),\n",
       " 'split3_test_score': array([0.82412385, 0.83357243, 0.81593027]),\n",
       " 'split4_test_score': array([0.81230462, 0.81370069, 0.802438  ]),\n",
       " 'split5_test_score': array([0.82081095, 0.82712503, 0.81868469]),\n",
       " 'split6_test_score': array([0.82564492, 0.83281951, 0.81364724]),\n",
       " 'split7_test_score': array([0.83058794, 0.83873596, 0.84143887]),\n",
       " 'split8_test_score': array([0.81800059, 0.82898627, 0.80573957]),\n",
       " 'split9_test_score': array([0.82679267, 0.82608505, 0.81870289]),\n",
       " 'mean_test_score': array([0.82480171, 0.83039151, 0.81872253]),\n",
       " 'std_test_score': array([0.00714653, 0.00722811, 0.01115248]),\n",
       " 'rank_test_score': array([2, 1, 3], dtype=int32)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_best_cnt_nb_estimator = GridSearchCV(\n",
    "    estimator=nb_estimator,\n",
    "    param_grid=nb_param_grid,\n",
    "    cv=cv,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    return_train_score=False,\n",
    "    refit=True\n",
    ").fit(X_train_cnt_transformed, y_train)\n",
    "\n",
    "grid_search_best_cnt_nb_estimator.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.85      0.87      0.86       249\n",
      "           comp.graphics       0.64      0.72      0.67       279\n",
      " comp.os.ms-windows.misc       0.84      0.60      0.70       280\n",
      "comp.sys.ibm.pc.hardware       0.67      0.78      0.72       316\n",
      "   comp.sys.mac.hardware       0.72      0.82      0.77       283\n",
      "          comp.windows.x       0.73      0.79      0.76       292\n",
      "            misc.forsale       0.81      0.79      0.80       298\n",
      "               rec.autos       0.89      0.90      0.89       305\n",
      "         rec.motorcycles       0.92      0.93      0.93       276\n",
      "      rec.sport.baseball       0.91      0.91      0.91       302\n",
      "        rec.sport.hockey       0.95      0.94      0.95       301\n",
      "               sci.crypt       0.94      0.92      0.93       301\n",
      "         sci.electronics       0.76      0.80      0.78       292\n",
      "                 sci.med       0.91      0.82      0.86       320\n",
      "               sci.space       0.89      0.87      0.88       287\n",
      "  soc.religion.christian       0.82      0.91      0.86       293\n",
      "      talk.politics.guns       0.87      0.88      0.88       266\n",
      "   talk.politics.mideast       0.98      0.93      0.96       283\n",
      "      talk.politics.misc       0.86      0.85      0.85       229\n",
      "      talk.religion.misc       0.92      0.67      0.77       197\n",
      "\n",
      "                accuracy                           0.84      5649\n",
      "               macro avg       0.85      0.84      0.84      5649\n",
      "            weighted avg       0.84      0.84      0.84      5649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "y_pred = grid_search_best_cnt_nb_estimator.predict(X_test_transformed_cnt)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_pipeline = Pipeline([\n",
    "                            ('preprocess',tfidf_pipeline),\n",
    "                            ('classifier', grid_search_best_tfidf_lr_estimator)\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sci.med'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_pipeline.predict(['hi! I suffer very painful stomach pains'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
