{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from functions import read_file, build_pipeline\n",
    "from pandas import DataFrame\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedShuffleSplit, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total topics (classes):  20\n",
      "Total files:  18828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "topics\n",
       "rec.sport.hockey            999\n",
       "soc.religion.christian      997\n",
       "rec.motorcycles             994\n",
       "rec.sport.baseball          994\n",
       "sci.crypt                   991\n",
       "rec.autos                   990\n",
       "sci.med                     990\n",
       "sci.space                   987\n",
       "comp.os.ms-windows.misc     985\n",
       "comp.sys.ibm.pc.hardware    982\n",
       "sci.electronics             981\n",
       "comp.windows.x              980\n",
       "comp.graphics               973\n",
       "misc.forsale                972\n",
       "comp.sys.mac.hardware       961\n",
       "talk.politics.mideast       940\n",
       "talk.politics.guns          910\n",
       "alt.atheism                 799\n",
       "talk.politics.misc          775\n",
       "talk.religion.misc          628\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cates_dir = glob('data/20news-18828/*')\n",
    "\n",
    "topics_path = {c.split('/')[-1]: glob(f'{c}/*') for c in cates_dir}\n",
    "\n",
    "print(\"Total topics (classes): \", len(topics_path)) \n",
    "\n",
    "df = DataFrame([(k, v) for k, v in topics_path.items()], columns=['topics', 'files'])\n",
    "\n",
    "df = df.explode('files')\n",
    "\n",
    "print(\"Total files: \", len(df))\n",
    "\n",
    "df['text'] = df['files'].apply(read_file)\n",
    "\n",
    "df.value_counts('topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  13179\n",
      "Test:  5649\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['text'], df['topics'], train_size=0.7, random_state=42)\n",
    "\n",
    "print(\"Train: \", len(x_train))\n",
    "print(\"Test: \", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_pipeline = build_pipeline('count').fit(x_train)\n",
    "tfidf_pipeline = build_pipeline('tfidf').fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=10, random_state=42, test_size=1/7) # Validation is around 10% of original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = tfidf_pipeline.transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 6.92132976, 13.00456645]),\n",
       " 'std_fit_time': array([0.47966842, 1.6608313 ]),\n",
       " 'mean_score_time': array([0.04260573, 0.01889541]),\n",
       " 'std_score_time': array([0.01208735, 0.0091829 ]),\n",
       " 'param_C': masked_array(data=[1, 10],\n",
       "              mask=[False, False],\n",
       "        fill_value=999999),\n",
       " 'params': [{'C': 1}, {'C': 10}],\n",
       " 'split0_test_score': array([0.88469509, 0.90540793]),\n",
       " 'split1_test_score': array([0.88197685, 0.9039375 ]),\n",
       " 'split2_test_score': array([0.87683065, 0.89847258]),\n",
       " 'split3_test_score': array([0.89030482, 0.90925725]),\n",
       " 'split4_test_score': array([0.86866562, 0.89129165]),\n",
       " 'split5_test_score': array([0.87007643, 0.89661617]),\n",
       " 'split6_test_score': array([0.88704218, 0.90643806]),\n",
       " 'split7_test_score': array([0.90051016, 0.91844248]),\n",
       " 'split8_test_score': array([0.87857204, 0.9053864 ]),\n",
       " 'split9_test_score': array([0.88901983, 0.90796304]),\n",
       " 'mean_test_score': array([0.88276937, 0.9043213 ]),\n",
       " 'std_test_score': array([0.00919833, 0.00712268]),\n",
       " 'rank_test_score': array([2, 1], dtype=int32)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar un clasificador\n",
    "estimator = LogisticRegression(n_jobs=-1, random_state=42, \n",
    "                         class_weight='balanced', solver='saga',\n",
    "                         max_iter=1000, penalty='l2')\n",
    "\n",
    "param_grid = {\n",
    "    'C': [1, 10],\n",
    "}\n",
    "\n",
    "\n",
    "grid_search_best_estimator = GridSearchCV(\n",
    "    estimator=estimator,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    return_train_score=False,\n",
    "    refit=True\n",
    ").fit(X_train_transformed, y_train)\n",
    "\n",
    "grid_search_best_estimator.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.92      0.88      0.90       249\n",
      "           comp.graphics       0.81      0.88      0.85       279\n",
      " comp.os.ms-windows.misc       0.88      0.82      0.85       280\n",
      "comp.sys.ibm.pc.hardware       0.81      0.83      0.82       316\n",
      "   comp.sys.mac.hardware       0.90      0.89      0.90       283\n",
      "          comp.windows.x       0.88      0.89      0.88       292\n",
      "            misc.forsale       0.86      0.89      0.87       298\n",
      "               rec.autos       0.93      0.91      0.92       305\n",
      "         rec.motorcycles       0.97      0.96      0.96       276\n",
      "      rec.sport.baseball       0.96      0.96      0.96       302\n",
      "        rec.sport.hockey       0.95      0.98      0.97       301\n",
      "               sci.crypt       0.98      0.93      0.95       301\n",
      "         sci.electronics       0.89      0.91      0.90       292\n",
      "                 sci.med       0.94      0.96      0.95       320\n",
      "               sci.space       0.96      0.94      0.95       287\n",
      "  soc.religion.christian       0.88      0.96      0.92       293\n",
      "      talk.politics.guns       0.93      0.96      0.95       266\n",
      "   talk.politics.mideast       0.99      0.96      0.97       283\n",
      "      talk.politics.misc       0.92      0.90      0.91       229\n",
      "      talk.religion.misc       0.94      0.79      0.86       197\n",
      "\n",
      "                accuracy                           0.91      5649\n",
      "               macro avg       0.91      0.91      0.91      5649\n",
      "            weighted avg       0.91      0.91      0.91      5649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "X_test_transformed = tfidf_pipeline.transform(x_test)\n",
    "y_pred = grid_search_best_estimator.predict(X_test_transformed)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.12618616, 0.13382003, 0.10436502]),\n",
       " 'std_fit_time': array([0.02513395, 0.03558606, 0.00985353]),\n",
       " 'mean_score_time': array([0.02255607, 0.02746015, 0.01695735]),\n",
       " 'std_score_time': array([0.00228209, 0.00913215, 0.00584362]),\n",
       " 'param_alpha': masked_array(data=[0.01, 0.1, 1.0],\n",
       "              mask=[False, False, False],\n",
       "        fill_value=1e+20),\n",
       " 'params': [{'alpha': 0.01}, {'alpha': 0.1}, {'alpha': 1}],\n",
       " 'split0_test_score': array([0.89648046, 0.88887367, 0.85472444]),\n",
       " 'split1_test_score': array([0.89135108, 0.88950543, 0.85422328]),\n",
       " 'split2_test_score': array([0.8897076 , 0.88604202, 0.84697417]),\n",
       " 'split3_test_score': array([0.90468242, 0.90117251, 0.86388099]),\n",
       " 'split4_test_score': array([0.8734912 , 0.86290117, 0.83096433]),\n",
       " 'split5_test_score': array([0.88137618, 0.87806768, 0.85126581]),\n",
       " 'split6_test_score': array([0.88574744, 0.8835521 , 0.84466198]),\n",
       " 'split7_test_score': array([0.89753053, 0.89568674, 0.86147626]),\n",
       " 'split8_test_score': array([0.89561659, 0.88962532, 0.85274381]),\n",
       " 'split9_test_score': array([0.89308357, 0.88997327, 0.85585674]),\n",
       " 'mean_test_score': array([0.89090671, 0.88653999, 0.85167718]),\n",
       " 'std_test_score': array([0.00844996, 0.00986443, 0.00883093]),\n",
       " 'rank_test_score': array([1, 2, 3], dtype=int32)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = MultinomialNB()\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 1],\n",
    "}\n",
    "\n",
    "\n",
    "grid_search_best_estimator = GridSearchCV(\n",
    "    estimator=estimator,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    return_train_score=False,\n",
    "    refit=True\n",
    ").fit(X_train_transformed, y_train)\n",
    "\n",
    "grid_search_best_estimator.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.93      0.90      0.91       249\n",
      "           comp.graphics       0.74      0.89      0.81       279\n",
      " comp.os.ms-windows.misc       0.83      0.77      0.80       280\n",
      "comp.sys.ibm.pc.hardware       0.80      0.83      0.81       316\n",
      "   comp.sys.mac.hardware       0.87      0.90      0.89       283\n",
      "          comp.windows.x       0.85      0.87      0.86       292\n",
      "            misc.forsale       0.87      0.84      0.85       298\n",
      "               rec.autos       0.96      0.93      0.95       305\n",
      "         rec.motorcycles       0.96      0.96      0.96       276\n",
      "      rec.sport.baseball       0.96      0.96      0.96       302\n",
      "        rec.sport.hockey       0.97      0.98      0.97       301\n",
      "               sci.crypt       0.97      0.93      0.95       301\n",
      "         sci.electronics       0.90      0.87      0.89       292\n",
      "                 sci.med       0.94      0.94      0.94       320\n",
      "               sci.space       0.94      0.94      0.94       287\n",
      "  soc.religion.christian       0.86      0.94      0.90       293\n",
      "      talk.politics.guns       0.89      0.94      0.92       266\n",
      "   talk.politics.mideast       0.96      0.97      0.97       283\n",
      "      talk.politics.misc       0.89      0.87      0.88       229\n",
      "      talk.religion.misc       0.95      0.69      0.80       197\n",
      "\n",
      "                accuracy                           0.90      5649\n",
      "               macro avg       0.90      0.90      0.90      5649\n",
      "            weighted avg       0.90      0.90      0.90      5649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "y_pred = grid_search_best_estimator.predict(X_test_transformed)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
