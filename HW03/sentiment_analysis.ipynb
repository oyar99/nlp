{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "Este notebook presenta modelos para analisis de sentimientos para varios dominios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importar Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from functions import create_sentiment_dataset, build_preprocess_pipeline, build_preprocess_pipeline_lexicon\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del data set - Cambiar segun sea necesario\n",
    "files = glob('data/Multi Domain Sentiment/processed_acl/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>folder</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i_forget:1 is_no:1 no_special:1 old:2 messy:1 ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>i forget  is no  no special  old  messy  probl...</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>unlabeled.review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lasted_less:1 a_chance:1 chance_to:1 the_motor...</td>\n",
       "      <td>negative</td>\n",
       "      <td>lasted less  a chance  chance to  the motor  g...</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>unlabeled.review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cooper_cooler:1 bottles:1 i:1 cooler:1 (2-3_mi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>cooper cooler  bottles  i  cooler  (2-3 mins  ...</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>unlabeled.review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the_idea:1 quick_marinate:1 to_clean-up.:1 con...</td>\n",
       "      <td>negative</td>\n",
       "      <td>the idea  quick marinate  to clean-up.  contai...</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>unlabeled.review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>small_i:1 though_only:1 craft_i:1 full_grip:1 ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>small i  though only  craft i  full grip  my h...</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>unlabeled.review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27672</th>\n",
       "      <td>z:10 only:1 course_of:1 no:5 help:1 plenty:1 l...</td>\n",
       "      <td>positive</td>\n",
       "      <td>z  only  course of  no  help  plenty  like  he...</td>\n",
       "      <td>dvd</td>\n",
       "      <td>positive.review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27673</th>\n",
       "      <td>well:1 i:1 interesting_as:1 raiders:1 liked_th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>well  i  interesting as  raiders  liked this  ...</td>\n",
       "      <td>dvd</td>\n",
       "      <td>positive.review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27674</th>\n",
       "      <td>this_movie:1 is_very:1 enjoys_a:1 you're:1 yet...</td>\n",
       "      <td>positive</td>\n",
       "      <td>this movie  is very  enjoys a  you're  yet ver...</td>\n",
       "      <td>dvd</td>\n",
       "      <td>positive.review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27675</th>\n",
       "      <td>episodes_ommitted:1 show:2 gareth's:1 america:...</td>\n",
       "      <td>positive</td>\n",
       "      <td>episodes ommitted  show  gareth's  america  te...</td>\n",
       "      <td>dvd</td>\n",
       "      <td>positive.review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27676</th>\n",
       "      <td>i:4 who_protest:1 in_wwii:1 was_acted:1 like:2...</td>\n",
       "      <td>positive</td>\n",
       "      <td>i  who protest  in wwii  was acted  like  show...</td>\n",
       "      <td>dvd</td>\n",
       "      <td>positive.review</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27677 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                raw_text     label  \\\n",
       "0      i_forget:1 is_no:1 no_special:1 old:2 messy:1 ...  negative   \n",
       "1      lasted_less:1 a_chance:1 chance_to:1 the_motor...  negative   \n",
       "2      cooper_cooler:1 bottles:1 i:1 cooler:1 (2-3_mi...  positive   \n",
       "3      the_idea:1 quick_marinate:1 to_clean-up.:1 con...  negative   \n",
       "4      small_i:1 though_only:1 craft_i:1 full_grip:1 ...  negative   \n",
       "...                                                  ...       ...   \n",
       "27672  z:10 only:1 course_of:1 no:5 help:1 plenty:1 l...  positive   \n",
       "27673  well:1 i:1 interesting_as:1 raiders:1 liked_th...  positive   \n",
       "27674  this_movie:1 is_very:1 enjoys_a:1 you're:1 yet...  positive   \n",
       "27675  episodes_ommitted:1 show:2 gareth's:1 america:...  positive   \n",
       "27676  i:4 who_protest:1 in_wwii:1 was_acted:1 like:2...  positive   \n",
       "\n",
       "                                                    text   folder  \\\n",
       "0      i forget  is no  no special  old  messy  probl...  kitchen   \n",
       "1      lasted less  a chance  chance to  the motor  g...  kitchen   \n",
       "2      cooper cooler  bottles  i  cooler  (2-3 mins  ...  kitchen   \n",
       "3      the idea  quick marinate  to clean-up.  contai...  kitchen   \n",
       "4      small i  though only  craft i  full grip  my h...  kitchen   \n",
       "...                                                  ...      ...   \n",
       "27672  z  only  course of  no  help  plenty  like  he...      dvd   \n",
       "27673  well  i  interesting as  raiders  liked this  ...      dvd   \n",
       "27674  this movie  is very  enjoys a  you're  yet ver...      dvd   \n",
       "27675  episodes ommitted  show  gareth's  america  te...      dvd   \n",
       "27676  i  who protest  in wwii  was acted  like  show...      dvd   \n",
       "\n",
       "                   file  \n",
       "0      unlabeled.review  \n",
       "1      unlabeled.review  \n",
       "2      unlabeled.review  \n",
       "3      unlabeled.review  \n",
       "4      unlabeled.review  \n",
       "...                 ...  \n",
       "27672   positive.review  \n",
       "27673   positive.review  \n",
       "27674   positive.review  \n",
       "27675   positive.review  \n",
       "27676   positive.review  \n",
       "\n",
       "[27677 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_sentiment_dataset(files)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>file</th>\n",
       "      <th>negative.review</th>\n",
       "      <th>positive.review</th>\n",
       "      <th>unlabeled.review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>folder</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>books</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>4465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dvd</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>3586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electronics</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kitchen</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "file         negative.review  positive.review  unlabeled.review\n",
       "folder                                                         \n",
       "books                   1000             1000              4465\n",
       "dvd                     1000             1000              3586\n",
       "electronics             1000             1000              5681\n",
       "kitchen                 1000             1000              5945"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agrupar los reviews por categoria\n",
    "df.groupby(['folder','file']).size().unstack().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los datos de entrenamiento consisten de los reviews que estan marcados como positivos o negativos\n",
    "train_data = df[df.file!='unlabeled.review'].reset_index(drop=True)\n",
    "# El conjunto de pruebas consiste de los reviews que no estan marcados\n",
    "test_data = df[df.file=='unlabeled.review'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Clasificador por categoria\n",
    "\n",
    "En esta seccion se va a construir un clasificador por cada una de las 4 categorias (Books/DVD/electronics/kitchen)\n",
    "\n",
    "### TF - IDF\n",
    "\n",
    "En los siguientes clasificadores se utiliza `tf-idf` para vectorizar el texto.\n",
    "\n",
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* kitchen *************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86      2991\n",
      "    positive       0.86      0.85      0.86      2954\n",
      "\n",
      "    accuracy                           0.86      5945\n",
      "   macro avg       0.86      0.86      0.86      5945\n",
      "weighted avg       0.86      0.86      0.86      5945\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:08<00:08,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* electronics *************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.84      0.84      2824\n",
      "    positive       0.84      0.85      0.85      2857\n",
      "\n",
      "    accuracy                           0.85      5681\n",
      "   macro avg       0.85      0.85      0.85      5681\n",
      "weighted avg       0.85      0.85      0.85      5681\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:14<00:05,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* books *************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82      2201\n",
      "    positive       0.82      0.83      0.83      2264\n",
      "\n",
      "    accuracy                           0.82      4465\n",
      "   macro avg       0.82      0.82      0.82      4465\n",
      "weighted avg       0.82      0.82      0.82      4465\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:20<00:00,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* dvd *************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.80      0.82      1779\n",
      "    positive       0.81      0.86      0.84      1807\n",
      "\n",
      "    accuracy                           0.83      3586\n",
      "   macro avg       0.83      0.83      0.83      3586\n",
      "weighted avg       0.83      0.83      0.83      3586\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Por cada categoria se crea un modelo\n",
    "for cate in tqdm(train_data['folder'].unique()):\n",
    "    \n",
    "    cate_train_data = train_data[train_data['folder']==cate]\n",
    "    cate_test_data = test_data[test_data['folder']==cate]\n",
    "    \n",
    "    # Pipeline de preprocesamiento de datos usado tambien para el notebook de 20N\n",
    "    tfidf_pipeline = build_preprocess_pipeline('tfidf').fit(cate_train_data['text'])\n",
    "    X_train_tfidf_transformed = tfidf_pipeline.transform(cate_train_data['text'])\n",
    "    \n",
    "    # Clasificador de regresion logistica\n",
    "    logistic_estimator = LogisticRegression(n_jobs=-1, random_state=42, \n",
    "                                            class_weight=None, solver='saga',\n",
    "                                            max_iter=1000, penalty='l2',\n",
    "                                            tol=1e-2, C=1\n",
    "                                            )\n",
    "\n",
    "    cate_lr = logistic_estimator.fit(X_train_tfidf_transformed, cate_train_data['label'])\n",
    "    \n",
    "    ## Probar el modelo y obtener las metricas\n",
    "    \n",
    "    X_test_transformed_tfidf = tfidf_pipeline.transform(cate_test_data['text'])\n",
    "    y_pred = cate_lr.predict(X_test_transformed_tfidf)\n",
    "    \n",
    "    print(f'************* {cate} *************')\n",
    "    print(classification_report(cate_test_data['label'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* kitchen *************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.85      2991\n",
      "    positive       0.84      0.86      0.85      2954\n",
      "\n",
      "    accuracy                           0.85      5945\n",
      "   macro avg       0.85      0.85      0.85      5945\n",
      "weighted avg       0.85      0.85      0.85      5945\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:08<00:08,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* electronics *************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.84      0.84      2824\n",
      "    positive       0.84      0.84      0.84      2857\n",
      "\n",
      "    accuracy                           0.84      5681\n",
      "   macro avg       0.84      0.84      0.84      5681\n",
      "weighted avg       0.84      0.84      0.84      5681\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:14<00:05,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* books *************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.83      0.82      2201\n",
      "    positive       0.83      0.82      0.82      2264\n",
      "\n",
      "    accuracy                           0.82      4465\n",
      "   macro avg       0.82      0.82      0.82      4465\n",
      "weighted avg       0.82      0.82      0.82      4465\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:19<00:00,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* dvd *************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.83      0.82      1779\n",
      "    positive       0.83      0.83      0.83      1807\n",
      "\n",
      "    accuracy                           0.83      3586\n",
      "   macro avg       0.83      0.83      0.83      3586\n",
      "weighted avg       0.83      0.83      0.83      3586\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Por cada categoria se crea un modelo\n",
    "for cate in tqdm(train_data['folder'].unique()):\n",
    "    cate_train_data = train_data[train_data['folder']==cate]\n",
    "    cate_test_data = test_data[test_data['folder']==cate]\n",
    "    \n",
    "    # Pipeline de preprocesamiento de datos usado tambien para el notebook de 20N\n",
    "    tfidf_pipeline = build_preprocess_pipeline('tfidf').fit(cate_train_data['text'])\n",
    "    X_train_tfidf_transformed = tfidf_pipeline.transform(cate_train_data['text'])\n",
    "    \n",
    "    # Clasificador multinomial de naive bayes\n",
    "    nb_estimator = MultinomialNB(alpha=1.0)\n",
    "\n",
    "    cate_nb = nb_estimator.fit(X_train_tfidf_transformed, cate_train_data['label'])\n",
    "    \n",
    "    ## Probar el modelo y obtener las metricas\n",
    "    X_test_transformed_tfidf = tfidf_pipeline.transform(cate_test_data['text'])\n",
    "    y_pred = cate_nb.predict(X_test_transformed_tfidf)\n",
    "    \n",
    "    print(f'************* {cate} *************')\n",
    "    print(classification_report(cate_test_data['label'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa un resultado postivo para cada uno de las categorias pues en todos la precision es mayor al 80% para ambos clasificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF\n",
    "\n",
    "Para los siguientes clasificadores se utiliza la frecuencia de los terminos para vectorizar el texto para usar como entrada a los modelos\n",
    "\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* kitchen *************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.86      2991\n",
      "    positive       0.85      0.86      0.86      2954\n",
      "\n",
      "    accuracy                           0.86      5945\n",
      "   macro avg       0.86      0.86      0.86      5945\n",
      "weighted avg       0.86      0.86      0.86      5945\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:08<00:09,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* electronics *************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.86      2824\n",
      "    positive       0.86      0.87      0.86      2857\n",
      "\n",
      "    accuracy                           0.86      5681\n",
      "   macro avg       0.86      0.86      0.86      5681\n",
      "weighted avg       0.86      0.86      0.86      5681\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:15<00:05,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* books *************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.81      0.82      2201\n",
      "    positive       0.82      0.84      0.83      2264\n",
      "\n",
      "    accuracy                           0.83      4465\n",
      "   macro avg       0.83      0.83      0.83      4465\n",
      "weighted avg       0.83      0.83      0.83      4465\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:21<00:00,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* dvd *************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.77      0.80      1779\n",
      "    positive       0.79      0.85      0.82      1807\n",
      "\n",
      "    accuracy                           0.81      3586\n",
      "   macro avg       0.81      0.81      0.81      3586\n",
      "weighted avg       0.81      0.81      0.81      3586\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Por cada categoria se crea un modelo\n",
    "for cate in tqdm(train_data['folder'].unique()):\n",
    "    \n",
    "    cate_train_data = train_data[train_data['folder']==cate]\n",
    "    cate_test_data = test_data[test_data['folder']==cate]\n",
    "    \n",
    "    # Pipeline de preprocesamiento de datos usado tambien para el notebook de 20N\n",
    "    cnt_pipeline = build_preprocess_pipeline('count').fit(cate_train_data['text'])\n",
    "    X_train_cnt_transformed = cnt_pipeline.transform(cate_train_data['text'])\n",
    "    \n",
    "    # Clasificador de regresion logistica\n",
    "    logistic_estimator = LogisticRegression(n_jobs=-1, random_state=42, \n",
    "                                            class_weight=None, solver='saga',\n",
    "                                            max_iter=1000, penalty='l2',\n",
    "                                            tol=1e-2, C=1\n",
    "                                            )\n",
    "\n",
    "    cate_lr = logistic_estimator.fit(X_train_cnt_transformed, cate_train_data['label'])\n",
    "    \n",
    "    ## Probar el modelo usando el conjunto de pruebas\n",
    "    X_test_transformed_cnt = cnt_pipeline.transform(cate_test_data['text'])\n",
    "    y_pred = cate_lr.predict(X_test_transformed_cnt)\n",
    "    \n",
    "    print(f'************* {cate} *************')\n",
    "    print(classification_report(cate_test_data['label'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* kitchen *************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.51      0.45      0.48      2991\n",
      "    positive       0.50      0.57      0.53      2954\n",
      "\n",
      "    accuracy                           0.51      5945\n",
      "   macro avg       0.51      0.51      0.51      5945\n",
      "weighted avg       0.51      0.51      0.51      5945\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:08<00:08,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* electronics *************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.51      0.42      0.46      2824\n",
      "    positive       0.51      0.61      0.56      2857\n",
      "\n",
      "    accuracy                           0.51      5681\n",
      "   macro avg       0.51      0.51      0.51      5681\n",
      "weighted avg       0.51      0.51      0.51      5681\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:14<00:05,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* books *************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.49      0.48      0.48      2201\n",
      "    positive       0.50      0.50      0.50      2264\n",
      "\n",
      "    accuracy                           0.49      4465\n",
      "   macro avg       0.49      0.49      0.49      4465\n",
      "weighted avg       0.49      0.49      0.49      4465\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:20<00:00,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* dvd *************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.85      0.83      1779\n",
      "    positive       0.84      0.79      0.82      1807\n",
      "\n",
      "    accuracy                           0.82      3586\n",
      "   macro avg       0.82      0.82      0.82      3586\n",
      "weighted avg       0.82      0.82      0.82      3586\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Por cada categoria se crea un modelo\n",
    "for cate in tqdm(train_data['folder'].unique()):\n",
    "    \n",
    "    cate_train_data = train_data[train_data['folder']==cate]\n",
    "    cate_test_data = test_data[test_data['folder']==cate]\n",
    "    \n",
    "    # Pipeline de preprocesamiento de datos usado tambien para el notebook de 20N\n",
    "    cnt_pipeline = build_preprocess_pipeline('count').fit(cate_train_data['text'])\n",
    "    X_train_cnt_transformed = cnt_pipeline.transform(cate_train_data['text'])\n",
    "\n",
    "    # Clasificador de Naive Bayes multinomial\n",
    "    nb_estimator = MultinomialNB(alpha=1.0)\n",
    "\n",
    "    cate_nb = nb_estimator.fit(X_train_tfidf_transformed, cate_train_data['label'])\n",
    "    \n",
    "    ## Probar el modelo con el conjunto de pruebas\n",
    "    \n",
    "    X_test_transformed_cnt = cnt_pipeline.transform(cate_test_data['text'])\n",
    "    y_pred = cate_nb.predict(X_test_transformed_cnt)\n",
    "    \n",
    "    print(f'************* {cate} *************')\n",
    "    print(classification_report(cate_test_data['label'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa un peor rendimiento usando `tf` especialmente usando Naive Bayes para la categoria de electronics y dvd. Lo que podria explicarse porque la terminologia usada para las resenas de estos productos no logra ser suficiente para el analisis de sentimientos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los modelos siguientes se utiliza una representacion usando un puntaje de positivo/negativo a partir de un lexicon y en base al texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresion lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:02<00:06,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* kitchen *************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.67      0.65      2991\n",
      "    positive       0.65      0.62      0.63      2954\n",
      "\n",
      "    accuracy                           0.64      5945\n",
      "   macro avg       0.64      0.64      0.64      5945\n",
      "weighted avg       0.64      0.64      0.64      5945\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:04,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* electronics *************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.66      0.62      2824\n",
      "    positive       0.62      0.56      0.59      2857\n",
      "\n",
      "    accuracy                           0.61      5681\n",
      "   macro avg       0.61      0.61      0.61      5681\n",
      "weighted avg       0.61      0.61      0.61      5681\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:07<00:02,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* books *************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.64      0.62      2201\n",
      "    positive       0.62      0.57      0.60      2264\n",
      "\n",
      "    accuracy                           0.61      4465\n",
      "   macro avg       0.61      0.61      0.61      4465\n",
      "weighted avg       0.61      0.61      0.61      4465\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:10<00:00,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* dvd *************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.62      0.61      1779\n",
      "    positive       0.62      0.59      0.60      1807\n",
      "\n",
      "    accuracy                           0.61      3586\n",
      "   macro avg       0.61      0.61      0.61      3586\n",
      "weighted avg       0.61      0.61      0.61      3586\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Por cada categorÃ­a se crea un modelo\n",
    "for cate in tqdm(train_data['folder'].unique()):\n",
    "    \n",
    "    cate_train_data = train_data[train_data['folder'] == cate]\n",
    "    cate_test_data = test_data[test_data['folder'] == cate]\n",
    "    \n",
    "    # Construir y ajustar el pipeline de preprocesamiento\n",
    "    pipeline = build_preprocess_pipeline_lexicon('data/lexicon/SentiWordNet_3.0.0.txt')\n",
    "    X_train_sentiment = pipeline.fit_transform(cate_train_data['text'])\n",
    "\n",
    "    # Clasificador de regresion logistica\n",
    "    logistic_estimator = LogisticRegression()\n",
    "    cate_lr = logistic_estimator.fit(X_train_sentiment, cate_train_data['label'])\n",
    "    \n",
    "    # Probar el modelo con el conjunto de pruebas\n",
    "    X_test_sentiment = pipeline.transform(cate_test_data['text'])\n",
    "    y_pred = cate_lr.predict(X_test_sentiment)\n",
    "    \n",
    "    print(f'************* {cate} *************')\n",
    "    print(classification_report(cate_test_data['label'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Clasificador para todas las categorias\n",
    "\n",
    "Ahora construimos un solo clasificador para todas las categorias donde se determina si el review es positivo o negativo unicamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se construye el pipeline de procesamiento para todo el conjunto de datos de entrenamiento\n",
    "tfidf_pipeline = build_preprocess_pipeline('tfidf').fit(train_data['text'])\n",
    "X_train_tfidf_transformed = tfidf_pipeline.transform(train_data['text'])\n",
    "\n",
    "cnt_pipeline = build_preprocess_pipeline('count').fit(train_data['text'])\n",
    "X_train_cnt_transformed = cnt_pipeline.transform(train_data['text'])\n",
    "\n",
    "lex_pipeline = build_preprocess_pipeline_lexicon('data/lexicon/SentiWordNet_3.0.0.txt')\n",
    "X_train_lex_transformed = lex_pipeline.fit_transform(train_data['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF - IDF\n",
    "\n",
    "En esta seccion usamos `tf-idf` como metodo de vectorizacion del texto\n",
    "\n",
    "### Regresion Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85      9795\n",
      "    positive       0.85      0.85      0.85      9882\n",
      "\n",
      "    accuracy                           0.85     19677\n",
      "   macro avg       0.85      0.85      0.85     19677\n",
      "weighted avg       0.85      0.85      0.85     19677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se utiliza clasificador de regresion logistica\n",
    "logistic_estimator = LogisticRegression(n_jobs=-1, random_state=42, \n",
    "                                        class_weight=None, solver='saga',\n",
    "                                        max_iter=1000, penalty='l2',\n",
    "                                        tol=1e-2, C=1\n",
    "                                        )\n",
    "\n",
    "cate_lr = logistic_estimator.fit(X_train_tfidf_transformed, train_data['label'])\n",
    "\n",
    "## Se prueba el modelo y arrojan los resultados \n",
    "X_test_transformed_tfidf = tfidf_pipeline.transform(test_data['text'])\n",
    "y_pred = cate_lr.predict(X_test_transformed_tfidf)\n",
    "\n",
    "print(classification_report(test_data['label'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85      9795\n",
      "    positive       0.85      0.85      0.85      9882\n",
      "\n",
      "    accuracy                           0.85     19677\n",
      "   macro avg       0.85      0.85      0.85     19677\n",
      "weighted avg       0.85      0.85      0.85     19677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clasificador de Naive Bayes multinomial\n",
    "nb_estimator = MultinomialNB(alpha=1.0)\n",
    "\n",
    "cate_nb = nb_estimator.fit(X_train_tfidf_transformed, train_data['label'])\n",
    "\n",
    "## Se prueba el modelo y se imprimen los resultados\n",
    "y_pred = cate_lr.predict(X_test_transformed_tfidf)\n",
    "\n",
    "print(classification_report(test_data['label'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambos modelos arrojan modelos muy buenos donde la precision es del `0.85`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF\n",
    "\n",
    "Ahora se utiliza una matriz con la frecuencia de los terminos como entrada de los modelos\n",
    "\n",
    "### Regresion Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85      9795\n",
      "    positive       0.84      0.86      0.85      9882\n",
      "\n",
      "    accuracy                           0.85     19677\n",
      "   macro avg       0.85      0.85      0.85     19677\n",
      "weighted avg       0.85      0.85      0.85     19677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clasificador de regresion logistica\n",
    "logistic_estimator = LogisticRegression(n_jobs=-1, random_state=42, \n",
    "                                        class_weight=None, solver='saga',\n",
    "                                        max_iter=1000, penalty='l2',\n",
    "                                        tol=1e-2, C=1\n",
    "                                        )\n",
    "\n",
    "cate_lr = logistic_estimator.fit(X_train_cnt_transformed, train_data['label'])\n",
    "\n",
    "## Probar el modelo\n",
    "X_test_transformed_cnt = cnt_pipeline.transform(test_data['text'])\n",
    "y_pred = cate_lr.predict(X_test_transformed_cnt)\n",
    "\n",
    "print(classification_report(test_data['label'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.83      0.82      9795\n",
      "    positive       0.83      0.83      0.83      9882\n",
      "\n",
      "    accuracy                           0.83     19677\n",
      "   macro avg       0.83      0.83      0.83     19677\n",
      "weighted avg       0.83      0.83      0.83     19677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clasificador de Naive Bayes multinomial\n",
    "logistic_estimator = MultinomialNB(alpha=1.0)\n",
    "\n",
    "cate_lr = logistic_estimator.fit(X_train_cnt_transformed, train_data['label'])\n",
    "\n",
    "## Test the model\n",
    "y_pred = cate_lr.predict(X_test_transformed_cnt)\n",
    "\n",
    "print(classification_report(test_data['label'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con Naive Bayes se obtiene un resultado ligeramente peor comparado con el resto de los modelos, aunque no se evidencia la misma dificultad que al clasificar por categoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexicons\n",
    "\n",
    "Ahora usamos caracteristicas extraidas del lexicon que corresponden a un puntaje de positivo/negativo para cada review.\n",
    "\n",
    "### Regresion logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.66      0.63      9795\n",
      "    positive       0.63      0.58      0.60      9882\n",
      "\n",
      "    accuracy                           0.62     19677\n",
      "   macro avg       0.62      0.62      0.61     19677\n",
      "weighted avg       0.62      0.62      0.61     19677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clasificador de regresion logistica\n",
    "logistic_estimator = LogisticRegression(n_jobs=-1, random_state=42, \n",
    "                                        class_weight=None, solver='saga',\n",
    "                                        max_iter=1000, penalty='l2',\n",
    "                                        tol=1e-2, C=1\n",
    "                                        )\n",
    "\n",
    "cate_lr = logistic_estimator.fit(X_train_lex_transformed, train_data['label'])\n",
    "\n",
    "## Probar el modelo\n",
    "X_test_transformed_lex = lex_pipeline.transform(test_data['text'])\n",
    "y_pred = cate_lr.predict(X_test_transformed_lex)\n",
    "\n",
    "print(classification_report(test_data['label'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que el feature de score que se extrae del texto a partir del lexicon es bastante sencillo, no se obtiene los mismos resultados que usando bolsa de palabras, pero si existe la posibilidad de mejorar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
